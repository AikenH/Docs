{"./":{"url":"./","title":"Introduction","keywords":"","body":"1. RULES1.1. 文档整理规范1.2. 文件命名规范1.3. 工程文档整理规范1. RULES 1.1. 文档整理规范 基本的目的是便于管理以及便于搜索两点，当然如果是数量特别大的文件的话，还是要进行文件夹的分层或者说是分级的。 减少文件夹的分层，特别是近似类别之间不要进一步细分 尽量将markdown文件放在同一个地方，通过不同的命名来便于查找 1.2. 文件命名规范 将后面遇到类别定下一个固定的名称（前缀和后缀）然后通过这样的规范表进行命名的搜索和查找， prefix(type)-name-（optional）Author&ver(初步定义为作者+版本) 命名只针对文档，特殊的文件就用特定的名称即可，然后以后md的图像要放到统一的文件夹中（除了上传的那种） prefix Meaning origin Usage 工具的使用说明 usage SuD 杂物（装机笔记） sundries Key 安全码之类的 key ConF 配置文件/文档 Configuration file Paper 论文阅读 Paper Notes Module 模块解读 Module Survey 综述阅读 Survey CodNote 代码笔记(好像还是直接用语言名称可能好点) Code Env 环境下的配置和使用说明 Environment Usage Dataset 数据集 ... Exper 实验记录或者项目笔记或者实验操作 Experiment record IntView 面试准备 Interview preparation 1.3. 工程文档整理规范 按照一下的几点规则来记录每次实验的内容，方便后序的文章撰写等等的工作： BackGround：相关的研究内容（Paper or Method）；使用的数据集；超参数等等的记录（这一点考虑使用Tensorboard或者MLVisual记录）； Motivation：针对的问题（研究背景）、假设；基于什么改进或者什么想法的实现； Support：支撑改进的相关理论依据（超链接，知道写在哪就行） Outline： WorkFlow的整体框架，算法的流程图，之类的，就是毕设画的那种。 在以下的部分，针对于每个不同的改进，对应不同的Support，循环利用下面的Module Detail： 每个dir存放的代码文件实现的是什么类型的功能， 同时一些重要的代码的功能要进行记录 并记录该部分的关键改进的内容在什么地方 其他的就交给注释来进行记录 Result：实验结果的图片，以及实验结果的内容分析（好，不好） 统一的可视化和分析规范：MLvisual或者Tensorboard 可以编写一个HeatMap的可视化界面来对特征和问题进行分析 Problem：实验中遇到的问题；希望基于什么手段去解决。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-04-10 19:47:11 "},"Algorithms/":{"url":"Algorithms/","title":"INTRO","keywords":"","body":"1. Algorithms1. Algorithms @Aikenhong 2021 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 17:29:32 "},"Algorithms/Astar.html":{"url":"Algorithms/Astar.html","title":"Astar寻路算法","keywords":"","body":"1. A* 算法1.1. 基本思想1.1.1. 相关类别定义1.1.2. 具体代码实现1. A* 算法 Created by: Aiken H Detail: algorithm Tags: Code URL1: https://zh.wikipedia.org/wiki/A*%E6%90%9C%E5%B0%8B%E6%BC%94%E7%AE%97%E6%B3%95 URL2: https://medium.com/@nicholas.w.swift/easy-a-star-pathfinding-7e6689c7f7b2 URL3: https://www.pythonf.cn/read/123915 A* 是一种在平面图形上计算最优路径的方法，通常用来做2D游戏的最短寻路，该算法是一种Dijkstra算法的变体，使用启发式的策略来提高算法的搜索效率。 1.1. 基本思想 基于启发式的方法，基于BFS去做最短路径搜索，借助类似Manhattan距离作为启发，每次加入后续的多个点，然后按照后续点的属性去排序，不断的加入close的区间，直到第一次遍历到终点就是最短的路径。 f(n) = g(n) + h(n) f代表的是经过当前点，从起点到最终点的距离，g代表的是从起点到当前节点的距离，h代表的是启发式方法到终点的距离。 维护三个list：open(候选列表)、close（状态确定的列表）、children（等待操作的列表） 首先用bfs的方法，找到当前节点的可达后续节点，将这些节点加入children，确定child不在close_list中后，若在open中则判断哪个是最优解，然后更新openlist，并将这些都加入open。 每次遍历的当前节点都从open中总距离最小的选，然后放入close。直到openlist为空。 1.1.1. 相关类别定义 class node(): def __init__(self, parent=None, position=None): self.parent = parent self.position = position self.g = 0 self.h = 0 self.f = 0 def __eq__(self, o: object) -> bool: return o.position == self.position 1.1.2. 具体代码实现 def asterS(map,slope,start,end): # 在astar算法的基础上，我们需要加入的是高度的约束 # 阻碍的条件是高度不同同时没有slope的存在，这种就是wall # 其余的和Astar算法应该是一样的 # init the start and end node start_node = node(None,start) end_node = node(None,end) # init the open and closed lists open_list = [] close_list = [] # add the start node to the open list open_list.append(start_node) # loop util find the end_node while len(open_list)>0: # make the best node as current_node # init 1 current_node = open_list[0] current_index = 0 for index, nod in enumerate(open_list): if nod.f= map.shape[0] or node_pos[1] = map.shape[1]: continue # mkae sure walkab mapflag = map[current_node.position[0], current_node.position[1]] != map[node_pos[0], node_pos[1]] slopeflag1 = slope[node_pos[0], node_pos[1]] == 0 or slope[current_node.position[0], current_node.position[1]] == 0 slpopeflag2 = slope[node_pos[0], node_pos[1]] != slope[current_node.position[0], current_node.position[1]] if mapflag and (slopeflag1 or slpopeflag2): continue # we need creat node first to find out if it is in the openlist or closed list new_node = node(current_node, node_pos) children.append(new_node) # loop those children # using the __eq__ to judge if it's already traveled. for child in children: if child in close_list: continue # create f,g,h for the legal child child.g = current_node.g + 1 child.h = manhattan(child.position, end_node.position) child.f = child.g + child.f # if the child is already in the open list, compare it if child in open_list: open_index = open_list.index(child) open_node = open_list[open_index] if child.g > open_node.g: continue open_list.pop(open_index) # if it is not in the open/closelist or better than that in open list, we add it. open_list.append(child) © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Envs/SSH.html":{"url":"Envs/SSH.html","title":"C0:SSH","keywords":"","body":"1. SSH 系列相关操作1.1. ssh-key1.2. Git&Github1.3. VSCODE） 远程免密登录1. SSH 系列相关操作 @Aiken 2021 主要介绍ssh服务在以下的几个方面（windows，linux）的使用情况：远程服务器连接（22），git&github（gitee），vscode免密登录。 1.1. ssh-key GITHUB关于SSH的教程 &#x1F448;可以直接切换成中文模式的 查看是否已存在 $ ls -al ~/.ssh 初始化 / 生成 ssh key // github 推荐，优先度从上到下递减 $ ssh-keygen -t ed25519 -C \"your_email@example.com\" // if not support $ ssh-keygen -t rsa -b 4096 -C \"your_email@example.com\" // tradition $ ssh-keygen -t rsa -C \"chenlangl@outlook.com\" 将ssh添加到github的个人权限界面中 免密登录 在github的教程中也有另一种方式来实现免密登录，好像是ssh-agent的方式安全的保存密码。 1.2. Git&Github 官方文档介绍的一些权限错误的地址：https://docs.github.com/en/github/authenticating-to-github/error-permission-denied-publickey 初始化git的用户配置，可以按照电脑id来进行命名其实区分起来还是好弄一些。 $ git config --global user.name \"YOURNAME\" $ git config --global user.email YOUEMAILADRESS // 查看相关的配置信息 $ git config --list 将本机的ssh公钥(public)放到GITHUB账户下的ssh管理地址，执行测试 $ ssh -T git@github.com 没有问题的话就可以直接进行clone，之类的git操作了 // 小trick，不拉取历史的commit $ git clone --depth=1 REPO_ADRESS 1.3. VSCODE） 远程免密登录 windows(Local) - Linux(Services) :Link1 Pro 实际上不光是VsCode，可以在本机上通过ssh服务免密登录服务器了，这一块好像可以通过公钥和私钥两种方式来做，在这里我们首先使用公钥来测试成功。 具体的操作如下： $ cd /root/.ssh // 创建authorized_kes $ touch authorized_kes // 在其中填入我们需要远程登录的服务器的ssh pub key，在这里就是windows本机的。 // 修改权限 $ sudo) chmod 600 authorized_kes $ sudo) chmod 700 ~/.ssh/ 然后检查密钥登录的功能是否开启 // 修改相应的ssh配置文件 $ code ./etc/ssh/ssh_config 查看其中的这两项配置是否打开： RSAAuthentication yes PubkeyAuthentication yes 可以禁用密码登录，但是这样的方式可能会导致后面挂了以后直接GG，所以慎重。 重启服务 $ service ssh restart © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Envs/GitGithub.html":{"url":"Envs/GitGithub.html","title":"C1:GitGithub","keywords":"","body":"1. Git Workflow1.1. Init Git1.1.1. Git&Github1.1.2. Gitignore1.2. Git 常用命令1.2.1. 远程操作1.2.2. 暂存区处理1.2.3. commit 处理1.3. Commit Standard1.3.1. Git Rebase1.4. Bug Fixed1.4.1. 大文件1.4.2. openssl error 100541.4.3. time out port4431. Git Workflow @Aiken 2020(2021) 1.1. Init Git 包含ssh的详细指令在ssh的文档中，这边只介绍设置完这一系列操作之后的git初始化，主要是初始化ssh，并将私钥放到github或者gitee的账户中。 建议用Pc的名字来做标识 git config --global user.name \"YOURNAME\" git config --global user.email YOUEMAILADRESS # 查看相关的配置信息 git config --list 1.1.1. Git&Github 官方文档介绍的一些权限错误的地址：https://docs.github.com/en/github/authenticating-to-github/error-permission-denied-publickey 将本机的ssh公钥(public)放到GITHUB账户下的ssh管理地址，执行测试 ssh -T git@github.com 没有问题的话就可以直接进行clone，之类的git操作了 # 小trick，不拉取历史的commit git clone --depth=1 REPO_ADRESS 1.1.2. Gitignore 对文档创建相应的忽略文件，然后在里面编写要忽略的文件，文件夹就可以了，特殊的通配符多了解。 通过VsCode的插件或GitHub的Doc对不同语言进行初始化配置 touch.gitignore Git忽略提交规则 - .gitignore配置运维总结 1.2. Git 常用命令 普通 command 分支 command 创建本地repo git init 创建/显示分支 git branch 工作区状态 git status 切换分支 git checkout 添加到暂存区 git add /. 创建&切换 git checkout -b 暂存区到本地 git commit -m ‘mesg’ 合并分支 git merge 日志 git log (–oneline) 删除分支 git branch -d 拉取远程库 git pull 推送本地分支 git push origin 克隆远程库 git clone 撤销 标签 撤销工作区修改 git checkout – 创建标签 git tag 撤销暂存区修改 git reset HEAD 显示所有标签 git tag 撤销本地库修改 git reset –hard 删除标签 git tag -d 远程 储藏 · 同步本地库和 git remote add origin xx@y 保存现场 git stash 远程库 git push -u origin master 恢复现场 git stash pop 1.2.1. 远程操作 推送本地的分支到远程的指定分支 git push origin local:remote # 冒号前本地，冒号后远程 git pull origin remote:local git fetch: 实际上pull = fetch + merge git fetch git log -p FETCH_HEAD git merge FETCH_HEAD 1.2.2. 暂存区处理 清除暂存区某个文件的指令（通常是为了修改.gitignore）的时候执行 git rm -r --cache filename 看暂存区有什么文件 git ls-files 1.2.3. commit 处理 撤销commit git reset --soft HEAD^ # 撤销当前commit git commit --amend # 重写当前commit 合并commit rebase： # 查看多个commit的hash值 git log # 找到需要合并的最早commit的上一个的ID git rebase -i # 修改pick squre状态合并commit 1.3. Commit Standard commit message 格式： \r Type(scope):subject\r Type：说明git commit的类别，限定标记类型 Scope：用于说明影响的范围，非必须 Subject：简短描述，建议使用中文可以更清楚 Type类型限定表格 TYPE 描述 TYPE 描述 feat 新功能 Fix/to 修复bug（to只产生diff） docs 文档 style 样式（不影响代码运行） refactor 重构 perf 优化（性能和体验） test 增加测试模块 chore 工具变动 revert 返回到上个版本 merge 代码合并 sync 同步主线或分支的bug 1.3.1. Git Rebase 通过rebase命令来进行merge，保持remote和local的commit整洁有效 1.4. Bug Fixed 1.4.1. 大文件 这一部分写的有点小瑕疵，到时候就看超链接 郑宇；主要是要将大文件排除追踪，在commit之前都还是比较好解决的，但是如果已经提交上去了就稍微比较麻烦，尝试将其中的大文件删掉。 # 1. 运行gc，生成pack文件`–prune = now` 表示对所有的文件都做修剪 git gc --prune=now # 2. 找出最大的k个文件，以3为例 git verify -pack -v .git/objects/pack/*.idx |sort -k -3 -n |tail -3 # bug: cannot open ///bad .. # 可能是由于地址出错了，修改地址，如下是查看地址的代码 find .git/objects/ -type -f # 3. 查看那些大文件究竟是谁，按照上一步输出的hash value 进行搜索，（不用全长） git rev-list --objects --all |grep # 4. 移除对该文件的追踪引用 git filter-branch --force --index-filter \"git rm --cache --ignore-unmatch ''\" --prune-empty --tag-name-filter cat -- --all # 5. 进行repack git for-each-ref --format='delete %(refname)' refs/original | git update-ref --stdin git reflog expire --expire=now --all git gc --prune=now # 6. 查看pack的空间使用情况 git count-objects -v # 7. 强制推送重构大文件 git push origin local-b:remote-b --force 1.4.2. openssl error 10054 git config --global http.postBuffer 524288000 1.4.3. time out port443 just wait for some time，应该是代理的问题，不行就使用国行版github把 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 17:44:40 "},"Envs/Docker.html":{"url":"Envs/Docker.html","title":"C2:Docker","keywords":"","body":"1. Docker笔记1.1. 进行本机离线阅读1.2. 笔记目录（TODO）1.3. WSL2以及Docker（win）的存储位置迁移1.3.1. 默认的存储位置（用来确认迁移状态）1.3.2. 存储位置迁移1.4. 镜像获取和运行1.5. Portainer 的安装设置1.6. 常用端口映射1.6.1. 需要被映射的端口1.6.2. 可用端口1.7. 基本镜像定制1.8. Portainer 相关操作（需要更新）1.8.1. 物理机资源介绍1.8.2. 使用Portainer管理1.9. Docker BASH 美化1.9.1. 切换主题部分1.9.2. 出现的问题1.10. Connect refused1. Docker笔记 @ Aiken 2020 同时本文章将包含在windows的wsl2环境下搭建docker以及将wsl2和docker的存储位置迁移到数据盘上的问题。（后续可以将一些数据挂载到其他的盘中，比如一些实验的空间之类的，等不用了在传入原本的盘中） 参考资料：docker从入门到实践;docker volume讲解 1.1. 进行本机离线阅读 gitbook形式阅读为例： 启动：拉取镜像和运行容器. 启动服务之后再浏览器输入localhost:4000 / 127.0.0.1:4000，进行阅读即可。 停止：再CMD ctrl+c或者再Docker终端关闭容器把。 # 为了保持内容最新,建议在每次阅读之前pull镜像 # 安装完镜像以后就可以在hub中进行pull等操作了 $ docker pull ccr.ccs.tencentyun.com/dockerpracticesig/docker_practice # 国内仓库 $ docker run -it --rm -p 4000:80 ccr.ccs.tencentyun.com/dockerpracticesig/docker_practice # docker hub # $ docker run -it --rm -p 4000:80 dockerpracticesig/docker_practice 基于镜像阅读服务下载PDF 安装 gitbook：npm install -g gitbook-cli 查看是否安装成功： gitbook -V 上一步中可能会出现BUG： cb is not a function 解决方案 打开gitbook的目录并在GITHUB项目的目录中执行 gitbook serve . 之后同样可以在localhost4000 访问 gitbook pdf . 在文件目录保存pdf BUG：not such file 暂未解决，先在网上看吧 1.2. 笔记目录（TODO） 从目录开始正式做一些整理，也就是一些重要的信息，操作，以及理解。普通的一些就没必要再记录了。 定制镜像的操作，添加ssh 账号密码passwd命令之类的操作 相关参考资料，初步尝试是失败了 以及使用portainer去构建一个简单的容器的操作，让我们试一试； SSH链接的原理和实现； wsl2下docker中cuda 装pytorch的操作 https://zhuanlan.zhihu.com/p/149517344 https://zhuanlan.zhihu.com/p/337758917 https://blog.csdn.net/fleaxin/article/details/108911522 https://blog.csdn.net/weixin_42882838/article/details/106976430 https://www.cnblogs.com/dadream/p/13640143.html https://docs.nvidia.com/cuda/wsl-user-guide/index.html#getting-started 摘抄师兄的笔记中有用的部分； 1.3. WSL2以及Docker（win）的存储位置迁移 docker；WSL2； 首先建议先在docker-desktop中设置好绑定的WSL version，然后在一次shut down 过程中完成两者的迁移操作，避免不必要的重复操作； 1.3.1. 默认的存储位置（用来确认迁移状态） docker：%LOCALAPPDATA%/Docker/wsl wsl2: %LOCALAPPDATA%/packages/c......./local_state 1.3.2. 存储位置迁移 # 关闭wsl服务 wsl --shutdown # 查看关闭状态 wsl -l -v # 导出wsl2 system； docker-desktop & docker-desktop-data # 导出系统 wsl --export wsl --export Ubuntu-20.04 E:\\WSLWorkspace\\ubuntu.tar wsl --export docker-desktop E:\\WSLWorkspace\\docker-desktop\\docker-desktop.tar wsl --export docker-desktop-data E:\\WSLWorkspace\\docker-desktop-data\\docker-desktop-data.tar # 删除（注销）系统 wsl --unregister Ubuntu-20.04 wsl --unregister docker-desktop wsl --unregister docker-desktop-data # 导入系统到指定的新位置(使用新路径导入新系统) wsl --import Ubuntu-20.04 E:\\WSLWorkspace E:\\WSLWorkspace\\ubuntu.tar wsl --import docker-desktop E:\\WSLWorkspace\\docker-desktop E:\\WSLWorkspace\\docker-desktop\\docker-desktop.tar wsl --import docker-desktop-data E:\\WSLWorkspace\\docker-desktop-data E:\\WSLWorkspace\\docker-desktop-data\\docker-desktop-data.tar # 启动docker-desktop服务 # 启动WSL2服务（这里在terminal中会出现两个ubuntu的unid，把原本的第一个给注释掉才行） # 设置默认wsl2用户 ubuntu2004.exe config --default-user xxx # 删除多余的所有tar，over 1.4. 镜像获取和运行 Docker Hub 上有很多高质量的镜像，这是主要的镜像获取途径 找到需要的镜像以后执行相关操作拉取镜像 $ docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] #查看选项&#x1F447;，是一些比较特殊的一般情况下用不到的操作 $ docker pull -help #如果是从dockerhub中获取镜像的话一般是不需要地址和端口号的 在拥有镜像以后就可以基于镜像运行容器（本质是作为进程存在的） 如果我们希望启动bash并进行交互式操作： $ docker run -it --rm ubuntu:18.04 bash # 参考上面运行reading的步骤也可以设置local端口吧 -it：这是两个参数，一个是 -i：交互式操作，一个是 -t 终端。我们这里打算进入 bash 执行一些命令并查看返回结果，因此我们需要交互式终端。 --rm：这个参数是说容器退出后随之将其删除。默认情况下，为了排障需求，退出的容器并不会立即删除，除非手动 docker rm。我们这里只是随便执行个命令，看看结果，不需要排障和保留结果，因此使用 --rm 可以避免浪费空间。 ubuntu:18.04：这是指用 ubuntu:18.04 镜像为基础来启动容器。 bash：放在镜像名后的是 命令，这里我们希望有个交互式 Shell，因此用的是 bash。 -d : 后台模式 --name: 指定 容器的名字 --restart=always # docker重启后容器也一起重启 -p: #端口映射指令 -v: -v 本地目录:容器目录 或 -v 容器目录 其他的一些常用指令 # 查看所有镜像 （过滤器操作参见文档） docker image ls [可选参数：1仓库名：2标签] # ID和...的前面要加. docker image ls --format \": \" # 查看镜像的体积 docker system df # 虚悬镜像的查看和删除 docker image ls -f dangling=true docker image prune # 删除镜像（不需要完整的ID只需要能区分就行） 基于ID：$ docker image rm [选项] [ ...] 基于镜像名： $ docker image rm ： 比如，我们需要删除所有仓库名为 redis 的镜像： $ docker image rm $(docker image ls -q redis) 1.5. Portainer 的安装设置 首先列出portainer的一些相关参考资料： 基本上是基于这些参考资料进行的学习 docker管理工具portainer介绍安装和使用 | Docker管理面板 | Portainer简明使用教程 Docker镜像部署与运维指南 Portainer for Win10 数据卷 | PART 1 Download And Install Image # 查询镜像 $ docker search portainer # 下载镜像（官方那个） $ docker pull portainer/portainer PART 2 单机版运行 如果我们使用的是单docker宿主主机，就直接单机运行portainer服务器，不需要进行联网操作，Just Do it： 需要注意的是，启动了WSL的windows单机实际上也要执行linux的命令才能正确的启动。 # 这样已经可以了但是还可以考虑指定数据挂载路径，下面这个是Linux的情况 $ docker volume create portainer_data $ docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce # Windows $ docker run -d -p 9000:9000 --name portainer --restart=always -v //./pipe/docker_engine://./pipe/docker_engine portainer/portainer 通过LocalHost或者指定ip以及Port(9000)登录Portainer 1.6. 常用端口映射 Container中有一些指令或者文件是需要一个端口的，所以我们需要将虚拟的端口映射到物理端口上，方便后续的远程链接，比如说ssh，所以我们需要，在启动镜像之前，进行物理端口的映射。 1.6.1. 需要被映射的端口 ssh：默认扫描 22 端口 tensorboard: 默认 6006端口，常用8008 端口 # 启动的时候可以指定端口 $tensorboard --logdir=/tmp --port=8008 jupyterlab：默认8888端口 备用和常用 9999 之类的 1.6.2. 可用端口 windows端口号相关操作：(0-65535) 建议使用5000以外的端口， # 查看所有被打开的端口（不知道是不是只能使用这些。） $netstat -an # 查看电脑端口的占用 $netstat -ano # 在相关指令下查找某个端口 for example $netstat -an0 | findstr \"80\" 1.7. 基本镜像定制 该部分主要介绍最基本的ssh开启和passwd建立的操作，设定ssh和建议指定的root账户，从而对container进行更好的管理，这样的操作可以方便环境的配置。但是实际上也可以在安装完基本docker之后在进行一个个的安装吧，我觉得这应该是可以的。 :star:至关重要师兄的文档 Pytorch Based 我们基于 pytorch官方镜像，进行Pytorch工程环境的构建，其中默认的python环境是通过conda控制的，已经集成在其中了，在下载镜像的时候我们需要明确cuda和nvdia环境. pull 镜像之后，我们采取portainer进行镜像的启动管理， 端口映射 Volume 设置物理存储卷设置 启动模式 dockerfile的构建 Dockerfile 下面是一些需要写在dockerfiles中的操作，对于命令的一些解读，我们之后还是需要进一步的了解。指令的写法和详细的作用 open ssh、passwd、git之类的安装 设置bash、root、软连接、 暴露ssh端口 设置一些依赖包 清楚copy的安装文件 基本的dockerfiles模板如下所示。如果是tensorflow的话我觉得差别也不会太大，之后补充。 # BASE IMAGE FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu16.04 # LABEL MAINTAINER LABEL maintainer=\"ltobenull@gmail.com\" SHELL [\"/bin/bash\",\"-c\"] WORKDIR /tmp # copy安装文件 COPY Python-3.6.9.tar.xz /tmp # 设置 root 密码 RUN echo 'root:password' | chpasswd \\ # 安装openssh-server 并配置 && apt-get update && apt-get -y install openssh-server \\ && sed -i 's/UsePAM yes/UsePAM no/g' /etc/ssh/sshd_config \\ && sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/g' /etc/ssh/sshd_config \\ && mkdir /var/run/sshd \\ # 安装python依赖包 && apt-get -y install build-essential python-dev python-setuptools python-pip python-smbus \\ && apt-get -y install build-essential libncursesw5-dev libgdbm-dev libc6-dev \\ && apt-get -y install zlib1g-dev libsqlite3-dev tk-dev \\ && apt-get -y install libssl-dev openssl \\ && apt-get -y install libffi-dev \\ # 安装python 3.6.9 && mkdir -p /usr/local/python3.6 \\ && tar xvf Python-3.6.9.tar.xz \\ && cd Python-3.6.9 \\ && ./configure --prefix=/usr/local/python3.6 \\ && make altinstall \\ # 建立软链接 && ln -snf /usr/local/python3.6/bin/python3.6 /usr/bin/python3 \\ && ln -snf /usr/local/python3.6/bin/pip3.6 /usr/bin/pip3\\ # 安装pytorch && mkdir ~/.pip && echo -e '[global] \\nindex-url = https://mirrors.aliyun.com/pypi/simple/' >> ~/.pip/pip.conf \\ && pip3 install torch===1.2.0 torchvision===0.4.0 -f https://download.pytorch.org/whl/torch_stable.html \\ # 清理copy的安装文件 && apt-get clean \\ && rm -rf /tmp/* /var/tmp/* EXPOSE 22 # 每次启动docker的时候都自启动ssh CMD [\"/usr/sbin/sshd\", \"-D\"] 1.8. Portainer 相关操作（需要更新） @ 基于196的实验室docker管理作为instance，然后基于自己的安装操作来写这一部分的介绍。 :star:重中之重基于3090的portainer管理 1.8.1. 物理机资源介绍 物理机的账户用于在物理机上创建自己的目录，进行管理和维护，除此之外请尽量避免直接使用物理机进行操作，避免误操作风险。 196的FS（file system）结构如下： 在物理机上进行操作的时候： 在/opt/data3/developers下创建自己名字命名的文件夹作为自己的workspace（这也是后面物理机挂载的时候的重要指标） NOTE：创建新容器或者需要较大存储空间的操作的时候要检查硬盘的余量$df-h是否足够 1.8.2. 使用Portainer管理 在这种高度可视化的界面下，已有的Image的使用，从dockerhub pull等的操作就不多说了（优先使用本地的）， 通常登录的端口都是9000：202.117.43.196:9000 My Account（密码同）：hongzx 新容器的创建注意事项 记得勾选auto remove 端口设置（也就是旁边的端口转发） 具体需要设置的参见上面的常见端口的安排 196的端口占用表（我的部分）： user Occupy hongzhenxin 23600-23699 数据卷挂载&GPU设置 包括将存储数据挂载到物理机上的指定盘点，以及开放CUDA的使用 绑定路径设置（主要的文件要传到挂载的路径下面） GPU设置： 1.9. Docker BASH 美化 基于zsh和oh my zsh对命令行主题进行美化 # 安装zsh $ sudo apt-get install zsh # 修改默认shell为zsh $ chsh -s /bin/zsh # 安装oh-my-zsh $ sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" # 或者使用wget $ sh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\" 如果我们需要将默认终端恢复bash： $ chsh -s /bin/bash root # h或者尝试直接输入bash https://traceme.space/blog/page/6/zshoh-my-zshtmuxvimdocker/ 配置教程 1.9.1. 切换主题部分 除了第一个命令其他的都在文档中修改/添加 https://github.com/ohmyzsh/ohmyzsh/wiki/Themes 主题预览 # 切换主题等 $ code ~/.zshrc $ZSH_THEME=\"tonotdo\" # （笔者比较喜欢这套主题，可自行选择，或者随机使用） $ setopt no_nomatch # （在文档末尾添加，解决zsh语法与bash语法不太兼容的问题，更多请参考[1]） $ export TERM=xterm-256color #（设置终端色彩模式，vim使用airline增强状态栏，需要此模式） 1.9.2. 出现的问题 conda activate消失 解决办法： # 保守方法，已测试 workflow如下 # 先将主题切换为bash # 在vscode的默认启动项中将启动的terminal切换回bash $ chsh -s /bin/bash # 卸载oh_my_zsh, and zsh $ sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/uninstall.sh)\" $ apt-get remove zsh # 进入portainer，在portainer的bash中执行 $ conda init # 之后在所有环境中都不需要再执行这个activate的操作了 但是好像在mobaxterm中还是需要手动激活一下，但是至少activate回来了 1.10. Connect refused 首先检查Linux Host 的SSH 是否启动，如果没有启动的话，手动启动，特别注意再重新run container的时候，要注意执行以下命令启动ssh service： $ service ssh start # 通过ps 查看sshd的服务是否运行 $ ps -aux | grep ssh # finished © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 17:31:54 "},"Envs/GoogleColab.html":{"url":"Envs/GoogleColab.html","title":"C3:GoogleColab","keywords":"","body":"1. Google Colab 免费羊毛GPU 使用时候遇到的一些问题总结1. Google Colab 免费羊毛GPU 使用时候遇到的一些问题总结 @Aiken 2020 在使用Google Colab的时候会有一些常见的使用错误，然后我们记录一些常见的错误的解决方案，方便后续使用。 INDEX： 命令行参数的输入问题 tensorboard的执行方法 # 在colab中写的时候要把前面的符号也写上 %load_ext tensorboard %tensorboard --logdir './runs' command命令的使用：包括库安装和卸载之类的。 主要就是在命令前+！ !/opt/bin/nvidia-smi # 下面顺便解决了一下 # ImportError: cannot import name 'PILLOW_VERSION'(版本问题) !pip uninstall pillow !pip install pillow==5.2.0 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Envs/VSCode.html":{"url":"Envs/VSCode.html","title":"C4:VSCode","keywords":"","body":"1. VsCode Python Debug Launch.json 编写1.1. Debug Launch json1.2. 特殊参数1.3. BTW TODO-Tree Setting Json1. VsCode Python Debug Launch.json 编写 @Aiken 2020 配置Launch.json 能够帮助我们更好的进行debug的操作。 有一些一些比较特别的文件名和相关编码。 1.1. Debug Launch json 找到launch文件并打开 自定义JSON：执行工作文件夹下的main.py进行调试 { \"name\": \"experiment\", \"type\": \"python\", \"request\": \"launch\", \"program\": \"${workspaceFolder}/main.py\", \"console\": \"integratedTerminal\", \"args\": [\"--data_path\",\"${workspaceFolder}/data\", \"--mode\",\"0\",\"--resume\",\"false\"] }, 默认 JSON：执行当前文件 { \"name\": \"current file\", \"type\": \"python\", \"request\": \"launch\", \"program\": \"${file}\", \"console\": \"integratedTerminal\" } 1.2. 特殊参数 ${workspaceFolder} :指代当前运行目录 ${file}:指代当前文件 1.3. BTW TODO-Tree Setting Json 打开设置-打开json文件（设置右上角） 添加如下内容：（颜色和关键词可自定义） \"todo-tree.tree.showScanModeButton\": true, \"todo-tree.highlights.enabled\": true, \"todo-tree.highlights.defaultHighlight\": { \"type\": \"text and comment\", }, \"todo-tree.highlights.customHighlight\": { \"TODO\": { \"foreground\": \"#2f3542\", \"background\": \"#f6b93b\", \"iconColour\": \"#f39c12\", \"icon\": \"issue-opened\", \"type\": \"line\" }, \"FIXME\": { \"foreground\": \"#2f3542\", \"background\": \"#e55039\", \"iconColour\": \"#e55039\", \"icon\": \"flame\", \"type\": \"line\" }, \"NOTE\": { \"foreground\": \"#2f3542\", \"background\": \"#9980FA\", \"iconColour\": \"#6c5ce7\", \"icon\": \"eye\", \"type\": \"line\" }, \"RECORD\": { \"foreground\": \"#2f3542\", \"background\": \"#7bed9f\", \"iconColour\": \"#2ed573\", \"icon\": \"info\", \"type\": \"line\" } }, \"todo-tree.general.tags\": [ \"TODO\", \"FIXME\", \"NOTE\", \"RECORD\" ], © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Experiment/MLFlow.html":{"url":"Experiment/MLFlow.html","title":"C5:MLFlow","keywords":"","body":"1. MLFlow 机器学习系统的使用1.1. 基本部署1.2. Tracking 实验版本跟踪1.3. Reference1. MLFlow 机器学习系统的使用 @Aiken 2020 基于Python开发的DAG数据工作流系统，面向机器学习，支持Spark并行环境和K8S容器集群； MLFlow主要解决了三个问题，也就是三个我们可能会需要使用的功能： Tracking：跟踪实验训练结果，记录算法参数，模型结果和运行效果等等； Projects：对所有的算法项目有一套标准的projects概念，记录下代码版本，参数和运行环境这些东西，并且projects是可以拟合所有的算法框架的； Models：解决的是打包和部署模型的这样一个行为，提供json接口给后续的flsk框架等等进行使用 1.1. 基本部署 INSTALL： DEPLOY： 1.2. Tracking 实验版本跟踪 Tracking为本次描述的重点，来做一个训练过程中的版本管理，记录每一次训练的参数和变量信息等等，这样便于后续的恢复和实验信息的整理。便于统计和管理。使用的时候好像也是需要代码嵌入的部分，就是需要在代码中调用MLFlow的API。 但是在Tracking的时候有一个比较重要的点在于，这个方法和Tensorboard对原模型的参数的嵌入和Logging记录中会不会产生冲突，同时两个方法之间是不是有什么overlap；关键的问题： 这两个API能不能进行混合使用 怎么统一和区分两个方法的应用情景 1.3. Reference https://mlflow.org/docs/latest/tracking.html https://mlflow.org/docs/latest/projects.html https://github.com/mlflow/mlflow https://blog.csdn.net/chenhuipin1173/article/details/100913909 https://my.oschina.net/u/2306127/blog/1825638 https://www.zhihu.com/question/280162556 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Envs/Gitbook.html":{"url":"Envs/Gitbook.html","title":"环境部署：Gitbook","keywords":"","body":"1. Gitbook Notebook1.1. Chapter1 Install1.1.1. 安装Gitbook插件1.2. Chapter2 Configure1.3. Chapter3 Deploy1.3.1. 初始化1.3.2. 构建1.3.3. Debugging1.3.4. 启动服务1.4. Chapter4 Publish1.4.1. 托管到Github Pages1.5. Reference1. Gitbook Notebook @aikenhong 2021 Gitbook命令行工具，基于Markdown编写文档，后续基于Github发布该Blog 1.1. Chapter1 Install 安装Gitbook之前我们需要安装node.js和npm的依赖，使用npm安装gitbook 首先安装Install Nodejs，Npm Windows：Node.js (nodejs.org) Linux: # add & update apt source before install nodejs. curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - sudo apt-get update # install nodejs after that. sudo apt-get install -y nodejs 然后安装gitbook npm install gitbook-cli -g gitbook fetch beta # 安装历史版本 gitbook ls-remote # 列举可以下载的版本 检查Gitbook版本 gitbook -V 1.1.1. 安装Gitbook插件 安装插件主要有两种方式：一种是直接通过book和gitbook的安装来实现，另一种是基于Npm预先安装 npm install gitbook-plugin-PACKAGE 基于book的安装方式 插件和相关的配置在book.json中指定，关键词plugins & pluginsConfig为对应的插件的配置信息 添加插件通过修改book.json如下： { \"plugins\":[ \"summary\",\"mathjax-pro\", \"-katex\",\"anchor-navigation-ex-toc\",\"search-plus\",\"-lunr\", \"-search\",\"splitter\",\"github\",\"theme-comscore\" ] } 添加完新的插件配置之后，运行gitbook install ./来安装新的插件 gitbook-plugin-mathjax-pro - npm (npmjs.com) # gitbook-plugin-mathjax-pro 安装方式 npm install mathjax@2.7.7 npm install gitbook-plugin-mathjax-pro # and editor the book.json as below { \"plugins\":[\"mathjax-pro\"] } { \"pluginsConfig\": { \"insert-logo\":{ \"url\": \"https://gitee.com/Aiken97/markdown-image/raw/master/img/20210927180958.png\", \"style\": \"background: none; max-height: 120px; min-height: 120px\" }, \"github\":{ \"url\": \"https://github.com/AikenH\" } } } 1.2. Chapter2 Configure gitbook init会初始化文件目录，文件夹会包含如下的结构：目录中的文件对应有如下的作用 . ├── _book # 自动生成的html ├── book.json # 配置文件 ├── README.md # 电子书的前言或者简介 ├── SUMMARY.md # 电子书的目录 ├── chapter-1/ | ├── README.md # 章节的描述 | └── something.md └── chapter-2/ ├── README.md # 章节的描述 └── something.md 编辑对应的SUMMARY同时可以按照文件夹结构进行组织，基本的组织结构可以按照下面的来进行部署 # 概要 * [卷 I](part1/README.md) * [写作很棒](part1/writing.md) * [GitBook很酷](part1/gitbook.md) * [卷 II](part2/README.md) * [期待反馈](part2/feedback_please.md) * [更好的写作工具](part2/better_tools.md) 1.3. Chapter3 Deploy 在本地部署和运行一个样本书，设置gitbook的配置文件 1.3.1. 初始化 将书籍创建到当前的目录或者指定的目录中 gitbook init gitbook init ./directory # 在指定的目录中生成 1.3.2. 构建 使用下面的命令会在当前目录下或者指定目录里生成_book目录，里面的内容是静态站点的资源文件： gitbook build 1.3.3. Debugging 您可以使用选项 --log=debug 和 --debug 来获取更好的错误消息（使用堆栈跟踪）。例如： gitbook build ./ --log=debug --debug 1.3.4. 启动服务 使用下列服务在LocalHost可以预览我们的的本地书籍 gitbook serve 1.4. Chapter4 Publish 希望可以不借助gitbook服务来可视化界面，全靠git & cmd & github来进行一系列操作，这样就能通过我的onedrive来进行比较好的统一管理 1.4.1. 托管到Github Pages optional: 创建username.github.io的个人repo,可以通过jekyll来init该githubpage 创建note's repo, 用来存储自己的所有Liture 调用gitbook serve之后将_book的文件推送到repo的gh-pages分支 就可以在下列的url中看到自己的文档：aikenh.github.io/REPONAME/ 1.5. Reference 集成GitHub | GitBook文档（中文版） (gitbooks.io) GitBook插件整理 - book.json配置 gitbook-notes (gitbooks.io) 内含github部署资料 Katex 测试验证 Gitbook-plugin-summary 实用配置及插件介绍 gitbook 入门教程之主题插件 Gitbook插件和主题 GitBook相关配置及优化 打造完美写作系统：Gitbook+Github Pages+Github Actions - phyger - 博客园 (cnblogs.com) © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-28 12:14:51 "},"Envs/Vimtutor.html":{"url":"Envs/Vimtutor.html","title":"Chapter1：Vimtutor","keywords":"","body":"1. Vim Tutor Notebook1.1. delete command1.2. skip words and lines1.3. undo and resume1.4. replace and change1.5. location and file status1.5.1. search command1.5.2. find the matched parentheses 找到对应的括号1.5.3. substitute command 替换命令1.6. EXECUTE AN ECTERNAL COMMAND1.7. THE OPEN COMMAND1.8. COPY AND PASTE1.9. SET OPTION1.10. KEYSHORT1. Vim Tutor Notebook this is the Note record the vimtutor (the basic usage of vim.) @Aiken 2021 write some word and we can use shift+a to insert in the end. the doc with Chinese delete command skip words and lines undo and resume replace and change location and file status search command find the matched parentheses 找到对应的括号 substitute command 替换命令 EXECUTE AN ECTERNAL COMMAND THE OPEN COMMAND COPY AND PASTE SET OPTION KEYSHORT 1.1. delete command Most of the command can use NUM to repeat it. d num command means delete num times with args below: w delete next num words e delete cur word d delete this line $ delete to the end of the line x means delete this cur 1.2. skip words and lines e means jump the end of the word 3e: means skip 3word distance 2w: means skip 2word the num can be decide by ourself.(in the most commands) 1.3. undo and resume u means undo. U undo the line. ctrl+r means resume which is contrast undo. 1.4. replace and change r replace char with new input R become replace mode, replace word by input util we press esc c means change operator: using it like c number [motion] $ delete to the end of the line and change mode to insert. e delete current word and change to insert mode 1.5. location and file status ctrl+g will show the location in file and the file status. gg: move to the head of the file. G: move to the end of the file. idx + G: jump 2 the line. shift+6: jump 2 the head of the line. 1.5.1. search command typing: / to search it. if we want to search same word, just type n, in another order N using ctrl+o to go back the cursor location, ctrl+i to go next using ? instand of / if we want search in the inverse order. 1.5.2. find the matched parentheses 找到对应的括号 typing % near the ( { [, it'll jump to another. this is very useful in debugging a program 1.5.3. substitute command 替换命令 :idx0,idx1s/old/new/g replace old with new in the line between [idx0,idx1] :%s/old/new/g replace all the old with new in whold file :%s/old/new/gc find out all old and we willdecide change it or not manually. 1.6. EXECUTE AN ECTERNAL COMMAND how to execute an command like shell command? using :![command] -[args] :w [filename] can save this file in this position or save change or it. :!rm [filename] :v choose those text or code we want to save(not all this file, just what we selected) and :w [filename] to save it :r [filename] will resume the txt of the file in this cursor. :r !dir will read the command output and puts it below the cursor 1.7. THE OPEN COMMAND o means will insert a line UNDER the cursor O will insert ABOVE the cursor 1.8. COPY AND PASTE y copy command. yw copy a word p paste(put) command v visual mode, select those char we want. $ jump to the end of the line 1.9. SET OPTION set an option so a search or subsititute ignore case after type in ':/ignore' then type in ::set ic will ignore case :set is 部分显示匹配的搜索短语 :set hls 高亮显示所有匹配的短语 :set no+ 前置no可以关闭选项 1.10. KEYSHORT Ctrl + f/b : 往下/上翻页 Ctrl + e/y : 往下/上滚动 V: 列选择模式 U/u: 选中的单词变成大/小写 Ctrl + w: 光标窗口切换 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Envs/Spacevim.html":{"url":"Envs/Spacevim.html","title":"Chapter2：Spacevim","keywords":"","body":"1. Spacevim Configuration1.1. INSTALL SPACEVIM AND CONFIG IT1.2. INSTALL LANGs'1.2.1. COCNVIM1.3. KEYSHORT and special USAGE1.3.1. SPLIT WINDOWS and CHECKOUT1.4. Plugins1. Spacevim Configuration @Aiken 2021 this file is use to record how to config out vim' by spacevim.I'll write this doc with three Parts: Install and envs, Plugins(including the LSP), KeyShort Attention: we have much to do if we want to install some other plugins. maybe it not a good way to set the vim. INSTALL SPACEVIM AND CONFIG IT INSTALL LANGs' COCNVIM KEYSHORT and special USAGE SPLIT WINDOWS and CHECKOUT Plugins 1.1. INSTALL SPACEVIM AND CONFIG IT Install: SpaceVim via the offical websize: spacevim layers colorscheme The COMMAND is like: curl -sLf https://spacevim.org/cn/install.sh | bash After that, the spacevim will install for the vim and neovim. Basic Configuration: modify the spacevim configuration in the file below ~/.SpaceVim.d/init.toml And enable some layers we need: which can select from spc + h + l after enable those layer, DEIN will install those plugins we need use GLOBAL VPN to download plugins. something like set: wrap will be add in ~/.SpaceVim/vimrc (end of it) 1.2. INSTALL LANGs' This is the most important part for coding: lint,autocomplete,warning..At the same time, this part is hardest to install, because the coc.nvim which is not design for spacevim. FIRST OF ALL: enable those langs' layer: python(first), markdown, c++;We can install those module according to the Docs, then install sth like pynvim(pip), node js, yarn, neovim, make...THEN: run :CheckHealth after install coc to check the env status.NEXT: try install debug, c++, c, for the future dev. 1.2.1. COCNVIM Using Python As a example to show how to install this.Hardest Part here: CPP with Coc, Coc Offical Coc_issues Install nodejs and yarn: # add & update apt source before install nodejs. curl -sL https://deb.nodesource.com/setup_14.x | sudo -E bash - sudo apt-get update # install nodejs after that. sudo apt-get install -y nodejs # install yarn in shell refer to the hint like: curl --compressed -o- -L https://yarnpkg.com/install.sh | bash Install Coc in SpaceVim by dein in init.toml: [options] autocomplete_method = 'coc' [[layers]] name = 'lsp' filetype = [ 'c', 'cpp', 'dart'] [layers.override_cmd] c = ['ccls'] cpp = ['ccls'] python = ['pyls'] [[cusiom_plugins]] repo = \"neoclide/coc.nvim\" merge = 0 rev = 'release' after install using :checkhealth 'CocInfo' to comfirm. Install some basic part(jedi): conda install jedi :CocInstall coc-jedi coc-python coc-snippets :CocInstall coc-python :CocInstall coc-clangd coc_keyword: some basic coc command we may use often CocInstall [PackageName] CocUninstall [PackageName] 1.3. KEYSHORT and special USAGE reinstall some plugins can use: SPReinstall coc.nvim. running/debug info will record in SPDebugInfo to_tree will show in spc a o after we save the modify of file 1.3.1. SPLIT WINDOWS and CHECKOUT split windows to show more info and make it easily to code. sp [filename] to splite windows with new files. u-d vsp [filename] to splite windows with new files. l-r spc [num] checkout cursor in diff windows g t checkout from tag to tag 1.4. Plugins This part is depending the DEIN, so we can reference this plugins. Many useful plugins had been add in those layers, learn it from offical website. recommand1 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Envs/Vimnote.html":{"url":"Envs/Vimnote.html","title":"Chapter3：Vimnote","keywords":"","body":"1. Vim Chapter 0-11. Vim Chapter 0-1 @Aikenhong 2021 Help me to be familier with vim, © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Envs/PicBed.html":{"url":"Envs/PicBed.html","title":"图床：PicBed","keywords":"","body":"1. PicBed1.1. Github1.1.1. 基本部署1.1.2. 存在问题1.2. Gitee1.2.1. gitee基本部署1.2.2. 配置Gitee Repo1.2.3. 设置配置文件路漫漫其修远兮，吾将上下而求索The road ahead will be long ,Our climb will be steep. 1. PicBed @Aiken 2020 first write，2021 modify Mainly using picgo-core(command line) to setting picbed，and we can update the setting method 1.1. Github 使用PicGo-Core（command line）设置github图床，自动转义url 插入自动复制图片，使用git上传github 1.1.1. 基本部署 在偏好设置中的图像，进行如下设置&#x1F447;： 下载或更新PicGo-Cord(command line) 接着去Github中建立一个Repo：UserName/RepoName，用以存放图片（Public），简单的用readme初始建立即可。 在Github的setting - developer setting-personal access tokens中新建token，指定简单的repo权限，并记录个人的token（只显示一次） Attention： 忘记记录的话，在token中也是通过update token（好像是这个名，获取新的值的） 用Typora打开配置文件设置，或者使用命令行进行配置 { \"picBed\": { \"github\": { \"repo\": \"UserName/RepoName\", \"token\": \"your github token here\", \"path\": \"img/\", \"customUrl\": \"https://raw.githubusercontent.com/UserName/RepoName/master\", \"branch\": \"master\" }, \"current\": \"github\", \"uploader\": \"github\" }, \"picgoPlugins\": {} } 点击验证图片上传选项，进行测试，成功即可 1.1.2. 存在问题 用Github做图床的话，上传不是十分的稳定（可能需要依赖科学上网技术。请八仙过海，各显神通）。可以用其他的服务器作图床，大体过程应该也差不多，后续个人有更换的话在进行补充。 在其他的pc上可以使用相同的token进行复用，但是在进行测试的时候要记得将repo中的两张测试图片删除，不然可能会导致验证失败的问题。 1.2. Gitee 因为gitee是国内的github，服务器比较稳定，所以我们也可以使用gitee作为我们更为稳定的图床； 两个链接合起来才是好用的，都有一些冗余： Typora+picgo-core+gitee PicGo-core+Gitee+Typora 1.2.1. gitee基本部署 安装Node，npm； 安装picgo-core的命令行命令： npm install picgo -g 安装gitee的插件： picgo install super-prefix picgo install gitee-uploader 1.2.2. 配置Gitee Repo 初始化一个repo，保存URL中的User/repo，不要轻信标题，因为有昵称机制。 在个人资料中初始化个人的Token，勾选projects选项即可; 1.2.3. 设置配置文件 基于picgo的命令，会自动的更新Json文件，我们不许需要 picgo set uploader # up to the command hint, we input those messages 1.按上下键找到gitee，回车 2.repo：用户名/仓库名 （打开自己的仓库，浏览器里的网址username/reponame） 3.token：刚才生成的token 4.path:路径，写仓库的名字就是reponame 5.custompath:不用填，回车 6.customURL:不用填，回车 # finish setting process picgo use uploader © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Envs/Linux.html":{"url":"Envs/Linux.html","title":"Linux","keywords":"","body":"1. Linux 常用操作1.1. Readme1.2. 各种类型的指令1.2.1. 压缩、解压缩文件操作1.2.2. 文件操作相关1.2.3. 进程操作1.2.4. 下载安装相关操作1.2.5. grep 命令行输出查找1.2.6. 显示GPU信息和使用情况1.3. 非特定的系统指令1.3.1. WATCH1.3.2. HISTORY1.3.3. ln -s1.3.4. HEAD、TAIL1.4. 远程操作1.4.1. 启动ssh服务1.4.2. 避免远程终端执行的代码中断1.4.3. SCP：linux之间传文件（好像也支持和Windows互传）1.4.4. SZ、RZ命令1.5. 环境配置1.5.1. Install Vim/NVim/SpaceVim1.5.2. Install Monitor1.5.3. Zsh and OhMyZsh 终端设置1.6. Anaconda 安装1.7. 注意事项1.7.1. python环境无法识别1.7.2. 删除Zsh后远程无法连接1.7.3. apt-get 找不到包1.7.4. chsh: PAM: Authentication failure1. Linux 常用操作 @aiken 2020 1.1. Readme 这篇文章主要是基于Ubuntu来进行编写的，其他的一些发行版的操作，暂不考虑； 记录一些基本的常用操作，方便后续使用和查找之类的 ⚡https://www.runoob.com/w3cnote/linux-common-command-2.html ⚡LINUX shell百科：https://www.explainshell.com/explain/1/ps Linux资源汇总 收录一些Linux的工具书以及相关的OnLine-Doc，方便后续进行学习和查阅： 先从3开始看吧，其他的慢慢看，我觉得一天看一点点就差不多了，不要为难自己。 鸟哥的Linux私房菜：相对全面一点但是内容有点太多了 Linux就该这么学：从开始到结束的流程挺完善的，但是这个网站做的事纯傻逼 Linux Tools Quick Tutorial：简单入门教程好像是 Linux命令行于Shell脚本编程大全：本地PDF，在当前文件夹下面进行查看 1.2. 各种类型的指令 按照使用场景对各种指令进行分类整理，对各种命令有一个更好的理解。 1.2.1. 压缩、解压缩文件操作 各种压缩指令对应不同的命令和设置，其中压缩文件可以包含一下的几种： tar.gz, zip 7z zip files ==== zip and unzip .zip files ========== # we need to install the package for .zip sudo apt-get install zip # r means recurrent（递归的遍历） zip -r newpackage.zip dir1 # unzip files to target dir unzip zipfiles.zip -d dir/* -m: 压缩文件删除源文件 -o: 将压缩文件的最新变动时间设置为压缩的时间 -r: 递归压缩，目录下的所有子级目录一并压缩 -x: “文件列表”，压缩时排除文件列表中的文件 tar.gz files tar压缩解压缩命令详解 # 压缩文件 tar -zcvf files.tar.gz dir tar -zcvf files.tar.gz *.md # .tar文件 tar -xvf file.tar -C 指定目录 tar -xvf file.tar dir/ # .gz文件 gzip -d 批量解压tar到相应的文件夹中 有几种不同的写法，这里看一下bash的相应手册，看看我们到底需要采用哪一种来执行 一下实现相应的bash脚本来执行对应的操作： 这里有需要注意的是单引号和相应的顿号要进行区分不然会发生不对的问题 # version 1 ez2understrand for i in `ls *.tar.gz` do mkdir /dir/${i/.tar.gz//} tar zxvf $i -C /dir/${i/.tar.gz//} done # version 2 try to use assignment method # 可以发现基本的操作是一样的，就是对应的定义的地方 # 可以考虑一下是如何使用echo和cut以及对应的-d 和 -f1是什么意思 for file in `ls *.tar` do todir=`echo $file | cut -d\".\" -f1` mkdir $todir && tar -xvf $file -C $todir done 1.2.2. 文件操作相关 建立文件夹： mkdir foldername 删除文件/文件夹： $ rm -[option] filename $ rm -[option] foldername [option]: \"rm -f\" 强行删除，忽略不存在的文件，不提示确认。(f为force的意思) \"rm -i\" 进行交互式删除，即删除时会提示确认。(i为interactive的意思) \"rm -r\" 将参数中列出的全部目录和子目录进行递归删除。(r为recursive的意思) \"rm -v\" 详细显示删除操作进行的步骤。(v为verbose的意思) ​ 删除文件夹中的文件不删除文件夹 $ rm -rf /test/* 查看某个文件夹下文件或者文件夹的个数： 参考链接：https://blog.csdn.net/niguang09/article/details/6445778 # 查看某个文件夹下文件的个数 # 2.包括了子文件夹下的文件 3.之查看文件夹 4. 包括子文件夹中的文件夹 $ ls [dirname] -l|grep \"^-\"| wc -l $ ls [dirname] -lR|grep \"^-\"| wc -l $ ls [dirname] -l|grep \"^d\"| wc -l $ ls [dirname]-lR|grep \"^d\"| wc -l # 通过管道查看 $ ll | wc -l 查看文件夹和磁盘的空间占用 explain_shell du df 命令可以显示目前所有文件系统的可用空间和使用情形 # 参数 -h 表示使用「Human-readable」的输出，也就是在档案系统大小使用 GB、MB 等易读的格式。 $ df -h :zap: du:查询文件或者当前文件夹的磁盘使用空 # 查询当前文件夹下面各个文件夹的大小： # 将深度改成n应该可以改变递归到子文件夹下的深度 $ du -h --max-depth=1 * # *代表的是当前文件目录 $ du -h --max-depth=1 [path] 移动或者重命名文件(mv) # 将文件A重命名为文件B mv nameA nameB # 移动文件到指定目录下 mv files dir/ 拷贝文件(cp) # using cp to copy file cp dir1/filea dir2/filea.bak 1.2.3. 进程操作 一些常用的进程操作命令，罗列如下，由于远程的链接常常中断，我们会需要手动终止一些进程，避免多余的内存、chache和性能占用。 TODO： 如果我们中断了远程链接，如何避免进程被kill，（也可以参考mobaxterm） 同时在下次链接的时候，切换到该bash中。 解决方案1 解决方案2 # 常用命令如下 # 搜先列出包含所有其他使用者的进程 $ ps -aux $ htop # 针对进程的PID进行关闭 $ kill PID # 如何执行批量的进程操作 更多相关ps的可选操作可以参考https://www.explainshell.com/explain/1/ps 1.2.4. 下载安装相关操作 安装没安装完成的包： sudo apt-get install package --fix-missing 更新源： 很多情况下Ubuntu的Source是被屏蔽的，所以我们需要使用国内源进行替代，来提升我们的下载和安装的速度 # backup the source files in cases that sth wrong sudo cp /etc/apt/sources.list /etc/apt/source.list.bak # using sudo to modify or recreate the source.list files sudo nvim /etc/apt/source.list # replace the content of it === TSINGHUA SOURCE === # update the source info sudo apt update # update the files to varify the speed. sudo apt upgrade All the source list；清华源更新地址 ==================== aliyun source =================== deb http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ focal-backports main restricted universe multiverse 1.2.5. grep 命令行输出查找 通过grep在命令行中筛选输出显示，只显示grep指定的部分。 # 只显示其中包括str的部分 $ command | grep 'str' 1.2.6. 显示GPU信息和使用情况 Linux查看显卡信息： lspci | grep -i vga # 如果是nvidia还可以 lspci | grep -i nvidia # 最常用：或者使用nvidia的自带命令 nvidia-smi 监视GPU使用情况 watch nvidia-smi # or gpustat --watch 显示CUDA版本 cat /usr/local/cuda/version.txt 1.3. 非特定的系统指令 一些特殊的通用命令 1.3.1. WATCH 将watch加在前面可以监控一些信息的实时变化 watch ps -aux watch nvidia-smi 1.3.2. HISTORY HISTORY主要针对如何找到历史指令，如何重复执行某一行指令； # show the history command idx history $ 1262 btm # resume this command idx, it'll get command by the idx !1262 $ btm 如果我们希望通过关键词搜索指令，然后进行重新调用： + 选择命令 1.3.3. ln -s Linux 软连接，类似windows系统中做快捷方式 # 在target地址建立一个名为linkname的软连接，链接到source_dir ln -s source_dir target_dir/linkname 1.3.4. HEAD、TAIL 只显示命令行输出的前几条或者后面几条 history | head -i histo | tail -i 1.4. 远程操作 1.4.1. 启动ssh服务 service ssh start 1.4.2. 避免远程终端执行的代码中断 我们希望再退出窗口的时候没有退出终端执行中的代码的话，我们实际上可以使用一种叫做session的设置来进行操作，如果要支持session的功能，这里主要可以有两种工具： tmux (zhihu.com) screen 我们这里主要选择使用tmux，功能相对于screen来说更全面一些，分屏功能也更好用 配置文件设置 在~目录下生成配置文件，然后写入我们希望的配置 vim ~/.tmux.conf 主要包含相关的按键映射以及页面主题等等操作 # use alt+arrpw to switch panes bind -n M-Left select-pane -L bind -n M-Right select-pane -R bind -n M-Up select-pane -U bind -n M-Down select-pane -D # mouse mode set -g mouse on # set easier window split keys bind-key v split-window -h bind-key h split-window -v #Enable oh my zsh in tmux set -g default-command /usr/bin/zsh #################################### config color ###################################### set -g default-terminal \"screen-256color\" ## COLORSCHEME: gruvbox dark set-option -g status \"on\" # default statusbar color set-option -g status-style bg=colour237,fg=colour223 # bg=bg1, fg=fg1 # default window title colors set-window-option -g window-status-style bg=colour214,fg=colour237 # bg=yellow, fg=bg1 # default window with an activity alert set-window-option -g window-status-activity-style bg=colour237,fg=colour248 # bg=bg1, fg=fg3 # active window title colors set-window-option -g window-status-current-style bg=red,fg=colour237 # fg=bg1 # pane border set-option -g pane-active-border-style fg=colour214 #fg2 set-option -g pane-border-style fg=colour237 #bg1 # message infos set-option -g message-style bg=colour239,fg=colour223 # bg=bg2, fg=fg1 # writing commands inactive set-option -g message-command-style bg=colour239,fg=colour223 # bg=fg3, fg=bg1 # pane number display set-option -g display-panes-active-colour colour214 #fg2 set-option -g display-panes-colour colour237 #bg1 # clock #set-window-option -g clock-mode-colour colour109 #blue set-window-option -g clock-mode-colour colour239 #blue # bell set-window-option -g window-status-bell-style bg=colour167,fg=colour235 # bg=red, fg=bg ## Theme settings mixed with colors (unfortunately, but there is no cleaner way) set-option -g status-justify \"left\" set-option -g status-left-style none set-option -g status-left-length \"80\" set-option -g status-right-style none set-option -g status-right-length \"80\" set-window-option -g window-status-separator \"\" #################################### config status ###################################### set-option -g status-left \"#[fg=colour248, bg=colour241] #S #[fg=colour241, bg=colour237, nobold, noitalics, nounderscore]\" set-option -g status-right \"#{prefix_highlight}#[fg=colour239, bg=colour237, nobold, nounderscore, noitalics]#[fg=colour246,bg=colour239] %Y-%m-%d %H:%M #[fg=colour248, bg=colour239, nobold, noitalics, nounderscore]#[fg=colour237, bg=colour248] #h\" set-window-option -g window-status-current-format \"#[fg=colour237, bg=colour214, nobold, noitalics, nounderscore] #[fg=colour239, bg=colour214] #I #[fg=colour239, bg=colour214, bold] #W #[fg=colour214, bg=colour237, nobold, noitalics, nounderscore]\" set-window-option -g window-status-format \"#[fg=colour237,bg=colour239,noitalics]#[fg=colour223,bg=colour239] #I#[fg=colour223, bg=colour239] #W #[fg=colour239, bg=colour237, noitalics]\" 基本的常用操作 tmux 前缀按键：ctrl+b # tmux 新建，离开，重连，关闭，列表，重命名 tmux new -s tmux detach # 或者prefixKey + d tmux attach -t tmux kill-session -t # 或者直接exit tmux ls tmux rename-session -t # prefixkey + b $ 1.4.3. SCP：linux之间传文件（好像也支持和Windows互传） 使用指令scp -P localfile username@ip remotepath 出现问题：permission denied：使用chmod 修改远程文件夹权限，774 or 777 具体指令Google it 1.4.4. SZ、RZ命令 sz、rz命令是Linux、Unix与Windows进行ZModem文件传输的命令； sz： sent zmodern 从服务器传输文件到的本地 rz：reveice 从windows传递文件到Linux服务器 if we want use this we need to inster 'lrzsz' first： 1.5. 环境配置 基础命令：修改密码$ passwd 1.5.1. Install Vim/NVim/SpaceVim # install vim sudo apt-get install vim # install nvim # sudo apt-add-repository ppa:neovim-ppa/stable # sudo apt-get update sudo apt-get install neovim # install the spacevim jump to the spaceVim doc 1.5.2. Install Monitor Install Resource Monitor for Linux Sys.Including: Htop, Bottom, Zeniththen we will describe the usage and install method of it. reference: Top Terminal Based Monitoring Tools for Linux | ComputingForGeeks Zenith (reposhub.com) ClementTsang/bottom (github.com) bvaisvil/zenith (github.com) Htop this is the easiest one, we can download it by default command. sudo apt-get install htop usage htop Bottom we need to use curl download the packages, then install it like below: ubuntu/debian: curl -s https://api.github.com/repos/ClementTsang/bottom/releases/latest | grep browser_download_url | grep amd64.deb | cut -d '\"' -f 4 | wget -qi - sudo apt install ./bottom*.deb usage:btm Zenith we need to install cargo/rust first, then we can download Zenith like Bottom, but acturally we only need one of it. ubuntu/debian:This way is not supposed nvidia-GPUs. # install the rust first sudo apt-get install rustc # download the package of Zenith curl -s https://api.github.com/repos/bvaisvil/zenith/releases/latest | grep browser_download_url | grep linux | cut -d '\"' -f 4 | wget -qi - # unzip it and install tar xvf zenith.linux.tgz # change the mode of shell chmod +x zenith sudo mv zenith /usr/local/bin If we want zenith show GPU infomation, we need to build it from the source code. And we will discuss this later.(learn about build/make first) placeholder usage:zenith 1.5.3. Zsh and OhMyZsh 终端设置 0xFFFF zsh & oh-my-zsh 的配置与使用 zsh、oh-my-zsh、tmux、vim 基于zsh和oh my zsh对命令行主题进行美化 # 安装zsh $ sudo apt-get install zsh # 修改默认shell为zsh $ chsh -s /bin/zsh # 安装oh-my-zsh $ sh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" # 或者使用wget $ sh -c \"$(wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\" 如果我们需要将默认终端恢复bash： $ chsh -s /bin/bash root # h或者尝试直接输入bash 切换主题部分 除了第一个命令其他的都在文档中修改/添加 https://github.com/ohmyzsh/ohmyzsh/wiki/Themes 主题预览 # 切换主题等 $ code ~/.zshrc $ZSH_THEME=\"tonotdo\" # （笔者比较喜欢这套主题，可自行选择，或者随机使用） $ setopt no_nomatch # （在文档末尾添加，解决zsh语法与bash语法不太兼容的问题，更多请参考[1]） $ export TERM=xterm-256color #（设置终端色彩模式，vim使用airline增强状态栏，需要此模式） zsh-syntax-highlighting zsh-autosuggestions 出现的问题 没有conda指令 # 换用别的终端 conda init zsh conda activate消失 解决办法： # 保守方法，已测试 workflow如下 # 先将主题切换为bash # 在vscode的默认启动项中将启动的terminal切换回bash $ chsh -s /bin/bash # 卸载oh_my_zsh, and zsh $ sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/uninstall.sh)\" $ apt-get remove zsh # 进入portainer，在portainer的bash中执行 $ conda init # 之后在所有环境中都不需要再执行这个activate的操作了 但是好像在mobaxterm中还是需要手动激活一下，但是至少activate回来了 1.6. Anaconda 安装 如何在 Ubuntu 20.04 上安装 Anaconda oh-my-zsh主题支持conda虚拟环境 oh-my-zsh主题显示conda环境名称_嘿芝麻的树洞-CSDN博客 1.7. 注意事项 @Aiken 2020 本文档主要记录一些Linux下面遇到的问题解决方法： 1.7.1. python环境无法识别 安装完linux以后在bash没法执行conda命令，以及识别不出conda中安装的环境，而从portainer中可以直接启动python的非对等偏差问题。 source /opt/conda/bin/activate conda activate base 应该是由于没有将conda的自启动加入docker中的自动运作中，所以需要自行对conda 命令进行启动。 solve update： 直接在portainer的terminal中执行如下命令即可一劳永逸 $ conda init 1.7.2. 删除Zsh后远程无法连接 由于设置zsh作为基本bash，导致问题的原因可能是接受ssh启动的bash 换成zsh了，而我们zsh已经卸载了，就无法修改。 解决方法，尝试从potainer控制台的console ，root登录基本的bash，在基本bash中将login shell 改成zsh。 参考链接：LINK $ vi /etc/passwd # passwd文件中把shell 改回bin/bash 即可 1.7.3. apt-get 找不到包 # 首先执行apt-get的更新 $ sudo apt-get update 1.7.4. chsh: PAM: Authentication failure code /etc/passwd # 里面可能有一些配置出现了问题，包括 bin/bash 漏了前面的斜杠这种 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Envs/Windows.html":{"url":"Envs/Windows.html","title":"Windows","keywords":"","body":"1. windows 操作技巧1.1. Abstract1.2. Filter the Filter the Result of Common carrying out1.3. GUID1.4. PANBAIDU1.5. Office AutoSave1. windows 操作技巧 1.1. Abstract written by Aiken, 2020this document is about windows tips Contents: CMD输出结果筛选 生成新GUID 倍速播放百度网盘 office 自动保存的恢复 shift+右键，在此处打开powershell； 1.2. Filter the Filter the Result of Common carrying out Common-u-want-to-carry-out | findStr \"String\" # for example conda list | Select-String (\"matplot\" , \"pillow\", \"scipy\", \"tensorboard\") 1.3. GUID new-guid 1.4. PANBAIDU 百度网盘的网页版倍速播放的技巧： videojs.getPlayers(\"video-player\").html5player.tech_.setPlaybackRate(2) 1.5. Office AutoSave 首先通过设置（选项）界面找到自动保存的asd文件的地址 在信息-管理文档中选择ASD进行对文档的恢复 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Experiment/NerualNetworkTraining.html":{"url":"Experiment/NerualNetworkTraining.html","title":"C1:NerualNetworkTraining","keywords":"","body":"1. 训练策略调整1.1. 基于问题分析1.1.1. 学习率的设置1.1.2. 限制网络的输出范围1. 训练策略调整 @Aiken 2020， 主要针对神经网络的训练过程中的一些基础策略的调整，比如当训练的曲线出现一定的问题的时候，我们应该怎么去调整我们训练过程中的策略。 1.1. 基于问题分析 针对在训练过程中会出现的一些基本问题进行超参数或者训练步骤的调整，以及可能导致问题出现的原因。 1.1.1. 学习率的设置 学习率的基本概念 $\\omega^{n} \\leftarrow \\omega^{n}-\\eta \\frac{\\partial L}{\\partial \\omega^{n}}$ 其中的权重就是学习率lr， 学习率大 学习率小 学习速度 快 慢 使用情景 刚开始训练时 一定的次数过后 副作用 1. Loss爆炸 2.振荡 1.过拟合 2.收敛速度慢 学习率的下降机制 详细理解pytorch的六种学习率pytorch 轮数减缓 指数减缓 分数减缓 英文名 step decay exponential decay 1/t1/t decay 方法 每N轮学习率减半 学习率按训练轮数增长指数插值递减 lrt=lr0/(1+kt)，k 控制减缓幅度，t 为训练轮数 学习率的基本设置 在训练过程中，一般根据训练轮数设置动态变化的学习率。 刚开始训练时：学习率以 0.01 ~ 0.001 为宜。 一定轮数过后：逐渐减缓。 接近训练结束：学习速率的衰减应该在100倍以上。 Note： 如果是 迁移学习 ，由于模型已在原始数据上收敛，此时应设置较小学习率 (≤10−4≤10−4) 在新数据上进行 微调 。 学习率调整策略 在训练过程中可视化Loss下降曲线是相当重要的，那么针对Loss出现异常的情况我们应该怎么样去调整使得Loss逐步趋于正常呢？ 曲线 初始时 上扬 [红线]：（直接起飞梯度爆炸） Solution：初始 学习率过大 导致 振荡，应减小学习率，并 从头开始训练 。 曲线 初始时 强势下降 没多久 归于水平 [紫线]： Solution：后期 学习率过大 导致 无法拟合，应减小学习率，并 重新训练 后几轮 。 曲线 全程缓慢 [黄线]： Solution：初始 学习率过小 导致 收敛慢，应增大学习率，并 从头 开始训练 。 1.1.2. 限制网络的输出范围 实际上，这一部分的应用就属于激活函数的数学理念问题了，我们倘若需要将网络的输出限制在一定的范围内，除了自己编写相关的数据处理手段之外，激活函数实际上有一部分原因就是为了这点设置的。 神经网络基于对非线性运算的需要，引入了激活函数，强化了网络的学习能力； 同时神经网络对于输出有所要求（很多时候是以一种概率表达的方式输出的）所以就会需要softmax（0，1同时sum==1）之类的函数，可以将分类器的原始输出映射为概率。 Sigmoid tanh之类的将输出限制在（0，1），但是并没有对加和有要求，这里可以做一个区分https://www.cnblogs.com/jins-note/p/12528412.html区分sigmoid（多分类）和Softmax（单分类） Softmax和tanh可能会出现梯度消失的问题，ReLU将输出限制在（0，1） 一部分激活函数的特点 所以很显然，我们可以通过对于相应的激活函数的应用，来限制我们的网络输出范围。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Experiment/Hyper_Resolution.html":{"url":"Experiment/Hyper_Resolution.html","title":"C2:Hyper Resolution","keywords":"","body":"1. 图像恢复技术在表情识别中的应用1.1. 超分辨率在表情识别中的应用1.2. 图像恢复技术、图像增强技术、人脸增强技术在表情识别中的应用1.3. 针对光，姿势变化，噪声和遮挡的人脸识别？AND 其他1. 图像恢复技术在表情识别中的应用 说明：重点针对超分辨率技术日期：2020-03-06 备注： 超分辨率在人脸识别上的多，但是表情识别上的确实不多，不过很多都会引用一波 1.1. 超分辨率在表情识别中的应用 KEY WORDs ： 1. (\"super resolution\" OR \"image restore\") AND (\"facial expression recognition\" OR \"emotion recognition\") 2. (\"super resolution\") AND (\"expression recognition\") 针对于低带宽传输的分辨率不足和比率低的应用场景 基于facial expression recognition 的 emotion recognition 在解码器进行视频下采样的时候，联合SR和识别 通过层次卷积神经网络(HCNN)来实现有校的SR 在facial expression recognition 中案例研究发现增强后的图像有助于提高识别性能 有点擦边吧，就是基于超分辨率算法的多分辨率图像，对面部进行识别从而判断疼痛程度 也可能妹啥用，你可以考虑一下 摘要中没有明确的提到Super-Resolution， 但是感觉低分辨率这个问题前缀，可能和SR有关系来着 好像是什么比赛，过程中有一部分是面部表情检测 在识别之前采取了超分辨率的查询增强 针对分辨率低和部分遮挡的面部表情识别 GAN IGCN RRMB 修复和超分辨率面部表情 1.2. 图像恢复技术、图像增强技术、人脸增强技术在表情识别中的应用 KEY WORDs： 1. (\"super resolution\" OR \"image restore\") AND (\"facial expression recognition\" OR \"emotion recognition\") 2. (\"image restore\") AND (\"expression recognition\") ——NONE 3. (\"Image enhancement\") AND (\"facial expression recognition\") 4. (\"face enhancement\") AND (\"facial expression recognition\") 5. (\"Image restoration\") AND (\"facial expression recognition\") 离散小波变换正则化和快速盲恢复模型来重建红外光谱。。。。来帮助面部表情识别 1.3. 针对光，姿势变化，噪声和遮挡的人脸识别？AND 其他 没有提到超分辨率或是图像重建 但是有提到标题那几个，结合局部和全局特征... 是对表情识别的增强但是好像不是图像增强..... 基于特征提取的增强把 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Experiment/Survey_2019.html":{"url":"Experiment/Survey_2019.html","title":"C3:Survey2019","keywords":"","body":"this SURVEY is about my Personal work & research mainly aboout some mathod、database、paper work 通过这个页面我就能随时随地的查阅我的调查资料此外，将这个页面设置在onedrive上，我也想知道，在两台使用相同git账号的电脑上会发生什么事情。 LOG： 人机交互的数据集快速构建调研 2019/11/4： init the repository & collect the infos my paper writing may need. 2019/11/5:Supplement the Origin Research ContentSearching for Additional key word : data programing few samples label propagation the same day later: Add the new key word searching: few-shot inspire: 从最新的顶会看起（搜起），避免被一些垃圾论文浪费时间之类的。 时效性和valuable是很重要的 搜综述（知乎）、survey、report（google） 2019/11/7：Reselect the reference of Li’s Paper and take some note about it. 2019/11/11：对那些github上有paper的algorithm进行了研究。？ 后续可能要对这些方法进行进一步的筛选，是否对于video的情况存在一定的用处。需要的话要进行细读。 finish reading the part about： limited labels on google scholar；finish reading the part about： few samples on google scholar： 2019/11/12：finish reading the part abut： labels propagationwhile discussing this part，we should find a Appropriate model (such as SOTA algorithm) (in the future) compare those method.(to be contiune) embedding layer we should know how to pre-train it, [zhihu] read half few-shot 2019/11/13：finish the rest reading abot：few-shot (in the future)some paper need to read carefully,but not now.Besides, after reading those paper,we need write down our plan for our recoding plan. 规划算法的努力方向和实现过程，主要要做一个框架还是要做一个，适应算法。我觉得这是一个值得思考的问题。首先要补充的是决策树的编程方式。然后开始规划和复现。 2019/11/15：何凯明大佬的无监督表征学习的东西。 2019/11/27：update the importance of those paper 2019 /12 :re-understand the two problems of few-shot learning(semi-supervised) & weakly-supervised : 前者是用少量的全标注样本 后者则是使用的标签强度不足（可能用别的类型的标签对直接标注进行了一个替代） FUTURE WORK : Searching for the Localization Method and choose the environment we need in our Work,At first we should do a short review to pick up those paper we had already readed.For example: Autoloc Step-by-Step BSN WILDCAT UntrimmedNet © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Experiment/Using_Judgment_Instead_of_Annotation.html":{"url":"Experiment/Using_Judgment_Instead_of_Annotation.html","title":"E1:Using Judgment Instead Of Annotation","keywords":"","body":"1. Using Judgment Instead of Annotation1.1. Overall1.2. Think it again1.2.1. 假如使用模板匹配1.3. Localization1.4. Classification1.5. Analyze the effectiveness of algorithms1.6. Some Problem1.7. Experiment Detail v1：GCN FSL version1.7.1. 算法的一些修改细节1.7.2. :zap: Something we should pay attention to1.7.3. ®DEBUG和TEST 安排1.7.4. 实验结果1.7.5. Summary1. Using Judgment Instead of Annotation 为了解决数据集的标注过程中工作量过大，在实际情境下难以完成需要的数据集构建，或者成本过高的问题，参考了AL，FSL的一些思路，主要的思路分析如下。 在证实可行性之前，先简要分析一下主要的思路即可。 1.1. Overall 基于reinforcement learning(人类参与)和self-learning(机器自学习)为主体框架，以各种FSL算法作为backbone，然后再不断的迭代中，提升辨别和分类能力。 人类参与的形式：把Annotation的过程，转化成Judge的形式：分类的化好说，定位的话，judge可以不只是一个True or False。 尽量做成一个项数有限的多选的离散情况。Full correct-smaller-biger-need to pan -completely loss 之类的，同时也可以将2-3歌epoch作为一次iteration的周期，然后对迭代次数本身进行考察 把这样的Judge作为RL中的reward，或者说是作为一种对prior knowledge的补充，帮助算法学习到最佳的H。 对Judge的利用上也可以参考weakly-supervised的方法，当成一个弱标签 给出Judge的同时，在扩充数据集，完成后续的增量自学习的同时，是否能做一个BP，对现有网络进行一个初步的修正方向指示。 算法的核心仍然在于FSL的算法部分： 但是算法的meta-learner的边际增益在下降的话，有没有办法使得这个增益曲线，后移，让我们在可以容忍的地方，已经获取了足够的数据标注 for example： 一开始的few-shot 得到了50%的正确率，我们通过Judge能快速的建立50%的数据集，然后再兵分两路feed 正确和错误的数据进入网络，进行类似Label propagation的方法，然后就能从方法增益上获取更多的标注收益，然后在效益进一步下降之前，已经构建了一个足够大的数据集？ solve problem：边际增益递减 根据不同FSL算法的P特性，结合Full supervised的ML算法的特性，在不同的data situation下，采用不同的整合算法，从而取得我们需要的辅助数据标记效果？针对不同阶段适应不同网络。 3. 1.2. Think it again 1.2.1. 假如使用模板匹配 基本思路 训练一个分类上较好的embedding，然后通过聚类算法，（同时要参考slide windows）算法，减少需要匹配的模板（snips），然后基于Network（Embeding）的输出去匹配：（平移 伸缩，切分组合的相似性应该保持），匹配完输出类别结果，让人为的去判断。 Few-shot的情况，扩充完以后针对性的对各类的模板进行更新（META？）（增量学习？）好像有点Learning with External Memory的味道 将人为判断的模型，以强化学习的方式：reward，进行网络的输入，对网络进行改造：对embedding进行改造，得到一个具有更好性质（泛化能力，准确率）的embedding。 仍需思考 在视频分割层面怎么去做匹配之类的操作什么的 1.3. Localization localization的部分离不开聚类的理论，比如oic loss，就是从判别度之类的来切分出最具识别度（类内和类间的间距较大的embedding function）的片段？ “类内间距小，类间间最大”，对snip进行初次的切片，然后在对这些进行分类 聚类或模板匹配，在定位这样的层面，模板匹配是不是会表现得更好。 1.4. Classification 1.5. Analyze the effectiveness of algorithms 通过判断的方法，是否能以低于纯标注的工作量，有效的在指定的轮次（RL+Self Learning一次为一轮），也就是有限的人工干预次数后，达到令人满意的效果。 总结：bias 是否能够通过这样Judge(RL)+FSL的方法，After Limited Epochs，能够快速构建数据集。 实际上如果只是针对Classification本身，那么这样的方法应该改成：FSL +Self-learning的效益提升改进。用Meta-Learning的思路来看的话：关键就在于效益曲线，如果进一步提升效益需要的数据量随之增长的速度超过一定的Threshold，那么就没有必要做下去了。 如果是Video维度的时间定位~~图像维度的图像分割，那么在这个时候，把Label行为本身，转换成一个Judge的操作，才在Workload减少本身，有一定的意义。 1.6. Some Problem 倘若我们使用FSL的时候，N-way K-shot中N若大了，问题的复杂程度会上升，那么是不是算法的效果，会不够好，此时是不是应该从N比较小的时候，通过N-K扩充数据量，然后再逐渐的上升N，最后转化为full supervised 当我们的Judge为error的时候，如何对negative的pseudo-label在网络中进行利用 如何更好的结合localization和classification，可能要参考一下two-stream之类的，但是他们都是在用weight比较生硬的对Loss进行结合，那么有没有更有机的结合方式？ 1.7. Experiment Detail v1：GCN FSL version 1.7.1. 算法的一些修改细节 def ✅modify_eval(*parameterlist): '''在验证过程中增长正确识别的dict，或者同时构建识别错误的dict''' '''在不同的epoch训练的时候需要重新读取数据，但是对同一批数据集，我们不能进行简单的单次训练 要么通过实验效果的边际效益/算法稳定来进行选择，要么通过指定hyperparameter确定固定训练伦次''' # 应该是一开始进行普通的FSL，等算法效果稳定以后再执行人工干预操作 or 边际效益降低到一定程度的时候来做这个操作 pass # 通过对类的实例中的dict进行修改在进行调用 # 定义方法修改dict def ✅early_stop(*parameterlist): # 通过early stop来对dict进行reload和改进，可以在argument设置一个参数来控制early_stop的执行模式 # 添加一个状态值，然后通过状态值在eval中执行操作，例如如下的两种方式 MaxNum = len(singleclass) Judgement = len(dict1[class1])/MaxNum pass def ✅modify_dataloader(*parameterlist): '''尽量使用自己的数据模型，这样在后续进行开发的时候能够更方便的拓展到其他的算法 1. dataloader需要进行重构：因为需要阶段性的生成datalist 2. 可能需要直接对datalist进行操作，可能需要直接对该值进行操作，后面看看怎么做''' pass # ✅ 或者此中关键在于load_tr_batch()，但是问题在于，这个函数对数据的读取是随机进行的，有没有办法让函数读取到的是固定的list？ '''我觉得应该是可以的，现在是随机选择图片，所以我只需要让每个类别中的初始图片是固定的index就可以执行这样的操作，在获取数据的时候进行shuffle，然后再后续选择训练的时候不在随机选择即可，然后给每个class一个list包含他们所拥有的shot，然后基于这样的shot来设置训练中获取的shot参数''' # ❌是不是应该换个New项目来做 '''暂时先对之前的想法进行一个实现试试''' A = self_dataloader(*args) 1.7.2. :zap: Something we should pay attention to [x] 在改变训练模式后怎么做checkpoint？ 有没有办法保存已有的list的情况：可能没有必要，我们只需要保证模型继承，然后根据迭代的情况快速的对数据集进行更替就可以了。 [x] 训练指标：(不能使用本数据集的pretrain，会破坏实验的验证性) 所以需要删除原本使用预训练的模型，禁用预训练module，以及freeze_cnn [x] 首先我们需要使用修改过后的数据集来进行一次测试，看算法的效果是否能够保持在一个较高的水平，如果算法的效果切实可行的话，在执行加入了数据填充部分的代码测试 [x] positive class是指定每个batch中的正类把，然后将其他的样本作为该episode中的Negative，也就是负例，通过这样的设定去模拟一个完整的类别样本。这样需要重构之前编写的部分 1.7.3. ®DEBUG和TEST 安排 记录train和test两个阶段的实验结果 [x] 首先记录原训练结果:colab 上的元模型 记得删除预训练和freeze_cnn模块 记录几种情况下的效果 [x] 接着 修改成data_v2的数据读取，检测数据算法是否编写正确 算法的准确率与原本是否有区别 改写数据模块的正确性与否 这一部分&#x1F446;的第一次实验，在data_v2的编写上存在一定的问题，进行修改并重新实验查看结果。 [x] 最后将整体算法嵌入进去，看看效果 先debug，将算法调试到可以正常运行的情况下 然后根据表现调整具体算法的逻辑错误 比较算法表现 1.7.4. 实验结果 phase\\indicator(no pretrain)(no freeze cnn) Nway Nshot iter ACC Tr ACCTe origin GNN Few-shot learning(k80) 5 5 50000 58.69% 57% GNN Few-shot learning v2（modify the data loading）❌ 5 5 18000 48.52% 22.96-23.52% V2 改（没有意义，从loss和acc的表现来看，算法由于训练数据过少，后续的训练过拟合了，算法的效果根据数据的浮动很大） 5 5 16000 20%-62% ❌ V3：eval中的positive-shot随机 5 5 5 5 Mydemo 5 5 应该补充个指标，就是最终的数据情况 phase\\indicator(no pretrain)(no freeze cnn) Tr T/F Te T/F loss Tr loss Te origin GNN Few-shot learning 2871/4992 285/500 1.132 :negative_squared_cross_mark: GNN Few-shot learning v2（modify the data loading） 574/2500 2.692 :negative_squared_cross_mark: ❌ ❌ ❌ ❌ Mydemo 1064/4662 1.714 1.7.5. Summary 不该使用第三方重构的代码，去理解，破坏了原作者的逻辑 对fewshotlearning的理解和positive class的理解需要进一步分析 对meta-learning 的问题设置有初步的了解 如何去编写数据 positive class，就是只识别positive class 其他的都当成负类，所以每个episode都只输出一个预测结果 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Experiment/UniversalFramework.html":{"url":"Experiment/UniversalFramework.html","title":"E2:UniversalFramework","keywords":"","body":"1. Universal Framework Readme1.1. Abstract1.2. Quick Start1.3. Framework Design1.4. DevLog1.4.1. RoadMap1.4.2. Swin-T1.5. Reference1.6. Project Management1. Universal Framework Readme @aiken 2021 Framework for CV 1.1. Abstract Try To make structure universal，编写一个自己的通用的架构，框架化，满足通过不同的model文件和特殊配置文件就能实现不同的模型的一个架构。 只是一个初步的框架集成，还有很多没有完善的地方，目前测试了ResNet18 跑Cifar10，没有什么问题，如果有什么可以改进的地方，或者你实现了一些Feature，\\欢迎进行交流**！（私下联系我最好啦！） 感谢帮助 > P.S 一些备注 > 1. 还有一些可以参数化或者可视化的地方，由于时间关系目前还没有修改，有兴趣的可以自己先添加一下 > 2. 暂时只集成了分类的模块，后续可能会随缘扩展 1.2. Quick Start 本框架主要希望实现的是：易读性，可拓展性，以及简洁； 希望将重要的，可变的参数都尽量的分离出来，通过配置文件和命令行参数去定义和运行我们的网络，在这种情况下实现一个较好的 1.3. Framework Design PURPOSE：新类发现和模型自主更新；同时希望能够解决长尾分布的数据情景； ANALYSIS：为了实现这种模型的自主更新过程，将整体的流程分成两个部分 启动（start）： self supervissed 等方法无监督的学习特征提取网络（这种方式是否会对Unbalance产生增益） 初始化预测模型： 基于Unbalance的数据训练一个基础的分类模型，在输出分类结果的同时需要输出对应的预测置信度，这两个其实都是一些简单的Trick，而最重要的是Backbone的分类效果需要得到保证，同时Backbone需要支撑后续的模型蒸馏更新。 模型的自主更新和迭代： Online：在线运行推断模型，通过置信度输出筛选出新类样本，将样本在样本池中收集 Offline：基于样本池的规模和评估触发离线更新：伪标签生成模型；模型蒸馏和更新 创新点：自主新类发现和学习 Unbalance： Strategy Status Desc Two Stage Todo 可以作为一个Baseline策略 Causla Analysis Doing 基于TwoStage做出的偏差校正 Rebalance TBD 作为数据增强的辅助策略 置信度生成方法： 置信度生成的方法可以从Active Learning等领域的文章中作为参考 Strategy Status pros and cons Evidential Learning Doing pros：有坚实的数学基础；cons：增加模型复杂度和训练的难度 Least Confident Done pros：实现简单，不影响原有复杂度cons：原理上简单，不是特别靠谱 Entropy and... TBD 同上，可以随时取代测试 置信度准确率输出： 使用下面的指标去做置信度输出的准确率评估 ac = NumNew/NumLowconfi recall = NumOld/NumLowconfi 伪标签生成模型： 在进行新的模型训练，之前，要将数据集混合现有的已知数据，生成的方式主要可以分成两种，网络或者聚类 聚类：通过现有类别的聚类结果，还能判断聚类的质量 网络：切分Mini-Batch进行Meta-Like的Training，训练FSL或者Unsupervised的模型，输出伪标签预测（一致性原则） 创新点： 在做伪标签生成之前，我们基于原本特征特征提取器，组合数据特征作为后续的数据基础 通过混合的数据集中的伪标签生成，和标签的双指标，定义损失，去更新原有的特征提取架构同时赋予新类伪标签。这是由于我们知道部分数据集的真实标签，我们就可以通过这一部分的信息去做一个对应的标准。 这样就可以通过生成的伪标签对原特征提取器进行一定的更新，这种更新应该是交替进行的，因为我们不知道哪个Coder是更为可靠的一个label generator。（除非我们使用的是有终点的聚类） 模型更新： 参考蒸馏学习的思想，使用原有网络和pseudo generator作为Teacher 进行模型的更新，Duplicate Feature Extractor，Modify FC（num_class），考虑使用双重循环去freeze，利用不同的lr training网络的两部分。 在这里参考其他蒸馏学习的方法，去设计这种Teacher给予Label或者Parms的机制 考虑基于prototype的方法，是否会和聚类的方法更加的匹配，但是prototype 的方法和我们之前设想的实验过程应该是一个区分度比较大的情况 创新点： double teacher to generate a new siamese model which train in two diff phase for feature extractor and classifier 1.4. DevLog 开发中的一些疑问和细节会放在这个地方，包括开发的RoadMap，实现中遇到的问题，FrameWork设计中的主要矛盾和问题； 1.4.1. RoadMap 开发路线图部分，主要分为基本的模块，和不同的训练方式两个阶段，用来集成完整的Framework. Data 数据集收集和初始数据的采样处理： Function Stage Desc New Class（Larget version） todo like mini-imagenet，mv some cls to other dir Unbalance todo sampling data in differ rate Few Shot done testing the model only have few data Model Functional Part Stage KeyWord/Method Basic Training abjust ImageNet Backbone done Swin（abjust params and train on ImageNet） LT and Confidence todo two-stagerebalancecausal analysis FSL doing Self-SuperviseCluster Cluster todo New-DescoverK-MeansSelf-Supervised + linear Framework Training Process Stage KeyWord/Method Meta Training todo Multi-Stage Training todo Distill Training todo Incremental learning Unsupervised todo Clustering todo 1.4.2. Swin-T 问题描述：在cifar10，或者ImageNet数据集上训练的时候，损失曲线过早收敛，识别准确率很低； 问题分析： [x] LR过高，没有办法学到好的解 框架中学习率设置的问题，同理可以分析其他的和config中的冲突 [ ] 数据集标签的问题 [ ] 模型定义的问题 1.5. Reference Confidental 主动学习(Active learning)算法的原理 ResNet Pytorch.org、官方实现解读 、ResNet详解与分析、Pytorch手工实现 Mini ImageNet 用Mini-ImageNet训练分类网络 Swin Transformer 1.6. Project Management Universal_Framwork Project Tree 项目文件夹管理，文件架构 ├─ config 配置文件和命令行读取 │ ├─ argparser.py 读取命令行参数 │ ├─ cifar10_effnet.yaml 配置文件 │ └─ template.yaml 文件模板 ├─ data 数据获取和数据增强 │ ├─ GetData.py │ ├─ dataAugment.py │ ├─ dataUtils.py │ └─ unzipImageNet.sh ├─ layers 网络层定义和设计 │ ├─ Classifier_L.py │ ├─ clusters.py │ ├─ convolution.py │ ├─ ezConfidence.py │ └─ new_activation.py ├─ loss 损失函数 │ ├─ common_loss.py 基本的损失函数 │ └─ evidential_loss.py 置信度损失函数 ├─ util 运行脚本可视化脚本 │ ├─ Visualize.py │ ├─ metric.py │ ├─ runningScript.py 训练和整体框架 │ └─ utils.py ├─ model 骨架模型 │ ├─ EfficientNet.py │ ├─ ResNet.py │ └─ ViTs.py ├─ save_model模型保存 ├─ log 输出记录 ├─ run.sh 命令行运行指令 ├─ main.py 程序入口 ├─ .gitignore └─ README.md © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 17:49:11 "},"Datas/Emotion_dataset.html":{"url":"Datas/Emotion_dataset.html","title":"D1:Emotion","keywords":"","body":"1. 数据集搜集整理文档1.1. 主要针对CV这边的任务1.2. PART1 \"表情数据集\"1.2.1. 搜索方式以及相应的搜索结果：1. 数据集搜集整理文档 1.1. 主要针对CV这边的任务 根据这次需要搜集的表情的数据集，整理一下搜索数据集的网站和思路等 1.2. PART1 \"表情数据集\" 下列是对数据搜集的要求： 是否开源 图片的大小和数量 图片的采集方式 eg：ck+ 1.2.1. 搜索方式以及相应的搜索结果： 谷歌数据集搜索导航60个人脸识别的数据集汇总cv方面的好几百个数据集汇总另一个cv方向的数据集汇总wiki cv page github-CV汇总帖 1.EmotioNet好像是一个什么挑战赛的数据集要博士后或者相应教员才能申请使用申请页面没有具体的用于表情识别的数据子集的信息（好像数据很多，但是不知道在哪下，除了那个博士后申请的）2.RAFreal-world Affective Face数据量29672个图像，7种基本情绪，12种复合情绪，（包含种族年龄范围性别属性，5个准确定位和37个自动生成的定位）数据收集方式：来源网络，大小应该很杂 （由40个人独立标定）email onenote中标记的和google 数据集搜索 FaceTracer Database basic info：（有图片的原始url）（wild）(网上收集的)姿势、环境、照明、质量 等等参差不齐，大小不固定 (针对**非商业用途开放**) (**表情只有笑容**) 故而不在详细收集，其他的标注信息，文中有详细讲解。 Tencent ML-Images 可能会有表情吧，是一个很大规模的多标签数据集。。。 ND-2006 Dataset 06年貌似 13450张图片 6种基本情感 888个对象 Google facial expression comparison dataset 没有对数据集的基本信息介绍 百度/CSDN搜索 https://blog.csdn.net/mathlxj/article/details/87920084 https://blog.csdn.net/computerme/article/details/49469767 JAFFE 只有219张，标签为分散离散值。 划分六种情感指标 256*256 中科大的NVIE 其中正面光照103人，左侧光照99人，右侧光照103人。每种光照下，每人有六种表情（喜悦、愤怒、哀 伤、恐惧、厌恶、惊奇）中的三种以上 平静帧、最大帧都已挑出 下载协议然后发给他们，才能下载 AFEW database 数据来源：电影片段的剪辑。情绪类型：“六类基本表情”+中性 SFEW database 数据来源：从AFEW中抽取出来的表情的静态帧。标注都在xml中 LIRIS-ACCEDE database 同样也是基于电影抽取的，有三种数据集，包含离散的情感数据和基于维度的情感数据 BU-3DFE database 3D的人脸表情数据集 数据来源：找人来做实验采集，按照要求的情绪做出表情 数据量：2500个3d面部模型（来自100个人） 还有同类的一些包含序列的等等的数据集，估计差别不大。 同样需要email获取 Oulu-CASIA database 数据来源：让80个受试者做出相应的表情并用不同相机采集（红外可见光正常光和弱光） 情绪类型：快乐、悲伤、惊讶、愤怒、恐惧、厌恶 email RAFD 数据来源：让67个受试者做出相应的表情在不同注视点和不同角度采集 情绪类型：8种情感类型 email KDEF database 数据来源：柔和、均匀的光线，多角度拍摄表情，使用统一的T恤颜色，在拍摄过程中使用网格将参与者面部居中，以及在扫描过程中将眼睛和嘴巴定位在固定的图像坐标中。 数据量：4900张 (70个人，一个7个情感) 页面底端超链接（没进去成功。。） ExpW 9w张左右，图片差不多8G AffectNet 百万量级数据（Emotion Net好像也是） 获取方式：从互联网获取 7类情感，首页有各种情感的数据量，最少的也有4k张 填写申请表email下载 Multi-PIE Face Database 收钱给数据集 获取方式：记录会话 数据量：75w图片 一些视频数据集(具体的在CSDN站上)（这些我就没有去详细看了） HUMAINE Database 应为带表情标签的视频数据集（CSDN用户表示下载后没有标签）(我翻墙也进不去很奇怪) Recola database MMI RU-FACS database-未公开 Belfast naturalistic database-主要是演讲时候的情感识别 VAM corpus也是演讲的 AVEC系列数据集 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Datas/Facial expression and Emotion.html":{"url":"Datas/Facial expression and Emotion.html","title":"D2:Facial Expression","keywords":"","body":"1. facial expression and Emotion Reference1.1. 疑似1.2. 确信1. facial expression and Emotion Reference 主要由两个程度来整理，一个是疑似，另一个是确信。 1.1. 疑似 M. Suwa, N. Sugie and K. Fujimora, \"A Preliminary Note on Pattern Recognition of Human Emotional Expression\", Proc. Int'l Joint Conf. Pattern Recognition, pp. 408-410, 1978. K. Scherer and P. Ekman, Handbook of Methods in Nonverbal Behavior Research., 1982. J.M. Carroll and J. Russell, \"Facial Expression in Hollywood's Portrayal of Emotion\", J. Personality and Social Psychology, vol. 72, pp. 164-176, 1997. Standardization and Assessment of College Students' Facial Expression of Emotion. 好像是评估表情标注的， Universals and cultural differences in the judgments of facial expressions of emotion 不同文化下的表情对应情感的认知 Classifying Emotion based on Facial Expression Analysis using Gabor Filter: A Basis for Adaptive Effective Teaching Strategy 1.2. 确信 Facial Expression Analysis 这篇的introduction里面有好几篇 Ekman P. Facial expression and emotion[J]. American psychologist, 1993, 48(4): 384. Keltner D, Ekman P, Gonzaga G C, et al. Facial expression of emotion[J]. 2003. 上面这两篇的引用里应该能找到特别多 Xu R, Chen J, Han J, et al. Towards emotion-sensitive learning cognitive state analysis of big data in education: deep learning-based facial expression analysis using ordinal information[J]. Computing, 2019: 1-16. 估计是类似的研究，看标题感觉就是类似的 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Datas/FashionDataset.html":{"url":"Datas/FashionDataset.html","title":"D3:Fashion","keywords":"","body":"1. Fashion Design 服装标注标准1. Fashion Design 服装标注标准 @Aiken 2021 需要标注的内容规定和规范，以及照片收集的教程； 标注规则的设立 服装的款式（大类） 小类别？但是这种标注标准该怎么确立 boundingbox 需要的数据 首先实际上直接就是在相应文件夹下的相应衣服先拿来用就行，后面再用部分的数据来训练相应的分类器的部分。 收集的格式 最好还是用压缩文件的格式来进行，将同个类别中的图片放到同个文件夹中。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Datas/ImageCaptionRequirement.html":{"url":"Datas/ImageCaptionRequirement.html","title":"D4:ImageCaption","keywords":"","body":"1. ImageCaption Database Requirements1.1. Goals：1.2. Microsoft COCO Captions:1.2.1. 一些其他信息：(Caption Evaluation Server):1.2.2. 数据规模：1.3. T: (82,782-413,915) V: (40,504-202,520) Testing: (40,775-200,060)1.3.1. 数据集搭建：1.3.2. 标注格式：2. 范例：2.1. ---2.2. (NOT Caption)Microsoft COCO dataset:2.2.1. 一些其他信息：2.2.2. 标注格式：2.2.3. 数据规模：2.2.4. 数据集搭建：2.3. ---1. ImageCaption Database Requirements 1.1. Goals： 1.数据量要求2.标注的标准3.标注的手段 1.2. Microsoft COCO Captions: 使用Amazon的Mechanical Turk(AMT)收集数据，再对数据进行标注。“Each of our captions are also generated using human subjects on AMT.” 1.2.1. 一些其他信息：(Caption Evaluation Server): 好像是可以评价caption的生成质量，但是应该是仅仅针对于使用COCO数据进行的，所以这一部分就不分析了。文中（section 3）包含了几种不同评价方法的介绍： BLEUROUGEMETEORCIDEr 在进行Evaluation之前的 Tokenization and preprocessing中：使用了工具来添加caption标记： Stanford PTBTokenizer in Stanford CoreNLP tools (version 3.4.1) 这个工具是模仿的是peen treebank3.其参考文献和相关链接如下：“The Stanford CoreNLP natural language processing toolkit,” in Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, 2014, pp. 55–60. related-link 1.2.2. 数据规模： （平均1-5）330k image - >1.5m captions;训练&验证image : 每张照片的caption 由5个独立的人分别给出;对于Testing Image，收集额外的标题用来比较 人类标题的和机器生成的标题的表现。 (MS COCO c5): 5 referenc captions for every image on MS COCO traning/ validation/ testing dataset.T: (82,782-413,915) V: (40,504-202,520) Testing: (40,775-179,189) (MS COCO c40): 40 reference sentences for a randomly chosen 5,000 images from the MS COCO testing dataset.给出更多对应的句子，许多评估指标可能与人类判断，有更高的相关性。 1.3. T: (82,782-413,915) V: (40,504-202,520) Testing: (40,775-200,060) 1.3.1. 数据集搭建： none 1.3.2. 标注格式： 2. 范例： Describtion原则：尽量短，只包含准确且重要的现况，不包含任何推理的部分。 Describe all the important parts of the scene. Do not start the sentences with “There is. Do not describe unimportant details. Do not describe things that might have happened in the future or past. Do not describe what a person might say. Do not give people proper names. The sentences should contain at least 8 words. 2.1. --- 2.2. (NOT Caption)Microsoft COCO dataset: 2.2.1. 一些其他信息： “the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation” “认为以往的数据集对于background信息过于忽视，除了主要的object 作为background的object很难识别” 应该是设计了一个便于标注的用户界面 2.2.2. 标注格式： (Image-对应Question)为一组，按照实例分割对对象进行标记对每个对象main.backgroud都留存实例级别的分割掩膜(比bounding box精确的完全分割) 1.标注存在的类别： 采用分层方法，先判断大类，这样逐层往下分，比较快结果如图a 2.Instance Spotting： 第一步的时候，在找到的类别上画个x，这一轮，就找更多的类别，在新类上画新x 结果图图b 3.分割实例 修改了Bell等人的软件？用来标注OpenSurfaces: A richly annotated catalog of surface appearance. SIGGRAPH 32(4) (2013) 2.2.3. 数据规模： 91 objects， 328k image， 250w instances类别少,实例多。避免long tail COCO: 1 image - 7.7 object instanceimagenet: 3SUN: 2.3 2.2.4. 数据集搭建： （COCO）基于Amazon Mechanical Turk收集数据，基于Image2text、SUNdatabase来查询图像对，从而收集。分层标记方法：将每个图像标记为特定的对象类别。 选择类别：只要那些thing（人，椅子，汽车），不要专注于stuff（天空街道草地）（没有精确的边界的） non-iconic & iconic图像： （举个例子，比如证件照和乱拍的生活照？）是否是中心大对象之类的。 都有，但是大部分用non- 2.3. --- © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Langs/Cpp.html":{"url":"Langs/Cpp.html","title":"Cpp","keywords":"","body":"1. C++ NoteBook（Cherno）1.1. Introduction About C++1.2. Part 1 编译器基本工作原理1.2.1. 基本信息1.2.2. Build ：Compiler + linker的基本原理1.2.3. Build： 头文件（Header Files）1.2.4. Build：代码存储的文件结构1.2.5. Build: 宏（Macros）2. define: 实际上就是在代码中搜索指定的文本进行替换2.1. Part 2 “变量”的使用和定义2.1.1. 变量（Variables）2.1.2. 数组、多维变量（Array）2.1.3. 字符串（String）2.1.4. 枚举类型（ENUMS）2.1.5. 自动类别指定（Auto Keyword）2.1.6. 模板（Templates）2.1.7. 操作符与操作符重载（Operators and operator overloading）2.1.8. 命名空间（Namespace）2.1.9. 左值与右值（lvalue and rvalue）2.1.10. 移动语义（move semantics）2.1.11. 可选数据（Optional Data）（new in C++17）2.1.12. 多类型变量（MultiType Variable）（new in C++ 17）2.1.13. 任意类型数据的存储（store any type）（new in C++17）2.1.14. 多维矩阵（2D+Array）2.1.15. 隐式转换和显式转换（Implicit Conversion and the Explicit Keyword）2.1.16. 类型转换（Type Casting）2.1.17. 类型双关（Type Punning）2.2. Part 3 Poniter & References指针与引用2.2.1. 指针基础（pointer）2.2.2. 引用基础（references）2.2.3. 指针的->操作符(Arrow Operator )2.2.4. 函数指针（Function Pointer）2.2.5. 智能指针（Smart Pointer）2.3. Part 4 Class & Struct 面向对象2.3.1. 类（Class）2.3.2. “This” 指针2.3.3. 复制构造函数以及浅拷贝深拷贝2.3.4. 单例（singleton）2.3.5. 结构体（Structure）2.3.6. 公用体（Unions）2.3.7. 结构体绑定（Structured binding）2.4. Part 5 WorkFlow&逻辑控制2.4.1. Func： 基本的函数定义（Functions）2.4.2. Func： 匿名函数（Lambdas）2.4.3. Func：三元运算符（Ternary Operator）2.4.4. Func: 多值输出 (Multiple Return)2.4.5. Threads：线程操作2.4.6. Threads：多线程管理2.4.7. Benchmark：基准测试2.4.8. Switch：case 分支2.4.9. Workflow：Conditions and Branches 条件和分支2.4.10. Loops: For and While 循环定义2.4.11. Workflow: Control Flow (contiune, break , return) 循环控制2.4.12. Workflow： Iterators迭代器2.4.13. Workflow: Continuous Integration CI （持续集成）2.4.14. Workflow: Static Analysis(静态代码分析)2.5. Part 6 Memory 资源管理2.5.1. Stack vs Heap: C++中的内存栈与堆2.5.2. New：Keyword For Mem内存关键词2.5.3. Safety：使用智能指针的情景2.5.4. Track Memory Allocation：内存申请跟踪2.6. Part 7 How to make C++ run Faster2.6.1. run string faster 优化string的运行速度2.7. Somthing Else 无题2.7.1. Argument Evaluation Order 参数输入顺序（面试？）1. C++ NoteBook（Cherno） @Aiken 2020 this notebook is based on Cherno‘s Video Class in YouTube； if there is sth get confused，I can recheck the video which talk about it, or just google it. this is not totally for newbie, so some basic information we should search it And this is a important websize to tell us basic info about C++. ToDo: using c++ and Python to finish the leetcode. review data structure when we code. reorganize the notebook by onenote and leetcode. 后续可能会添加Effetive C++中的相关内容 C++ Switch语句 Attention： 为了防止一些遗漏，或者搜索上的困难，虽然我们会尽量避免内容的overlap，但是如果和两者都特别相关的话，可能会在两个地方出现完全一致的内容。 后续补充：如果是confused的内容（不确信的话）就加入:question: 或者 still in puzzle: 内容的格式添加把 Typora常用快捷键 1.1. Introduction About C++ C++是一种强类型的语言，也就是我们需要实现指定数据的类型，同时我们没法随意的改变类型或者混杂类型把。（其实也是可以的就是需要执行特定的代码，相对而言没有那么方便而已。） 有疑惑就去查cppreference，永远的神； 此外当我们对某个不知道什么时候用的时候就google xxx when why how 1.2. Part 1 编译器基本工作原理 This Chapter 主要介绍Visual Studio中C++的compiler，linker的基本工作原理；以及在Visual Studio中一些相关工作环境的设置，比如输入输出配置，debugging环境之类的；此外建议使用VsCode的键盘映射，对于自己来说比较熟悉）；同时也会介绍一些和编译器原理相关的预处理模块；以及Library 1.2.1. 基本信息 STD：standard library C++中的标准库，包含了一些最基础的标准操作，包括cin; cout; #\\:hash tag（预处理符号）+预处理语句（基本的就是include，define之类的） = 预处理器 1.2.2. Build ：Compiler + linker的基本原理 编译和连接的规则： 原则1：.Cpp都会被编译，但是.h不会被编译，他是以#后接的指定模式(include被嵌入(copy)到指定的.Cpp中的指定位置再进行编译。（下面是一些预处理指令） include：直接复制粘贴到指定的位置，所以你也可以定义}之类的进入h。 define：搜索并替换 可以用做简单的函数定义 也可以使用成定义pi的值之类的，指定一个名称 #if 0/1 … #endif:中间的内容将根据if后的true or false 来决定是否存在。（是否编译） 上述的三种操作都是文本级别的操作，也就是针对编码文本进行处理后再送入编译器进行编译的。 原则2：每个cpp都会被编译成.obj文件然后由Linker，将这些obj连接起来成为一个.exe THIS IS IMPORTANT：如果我们想要将功能和主题main（entrypoint）分离开来，除了用header的方式，我们也可以写在另外的.cpp中，然后再主要文件中进行declaration（定义函数名和指定的传入参数即可），也就是声明该函数是存在的， 而不用具体定义（具体定义在另外的cpp中）， 这样在build的过程中，linker就会在我们的工程项目文件夹中搜索其他cpp中的指定function （we just declaration in the main cpp）。这样也能成功的编译。 所以如果我们一个函数在多个cpp中定义（多重定义），或者由于header中的include h，这样可能会导致compile的时候出现代码（链接？）混淆的问题（bug），再不济也是个冗余的编译操作。 如果需要多次使用.h 我们可以将其中的函数定义成static的方式，这样在每个cpp中都会有自己版本的.h中的函数，就不会有重复编写导致模棱两可的问题了。 inline前缀也能解决同样的问题：内联函数 inline：内联标识符适用于结构简单的小型函数。 增加了 inline 关键字的函数称为“内联函数”。内联函数和普通函数的区别在于：当编译器处理调用内联函数的语句时，不会将该语句编译成函数调用的指令，而是直接将整个函数体的代码插人调用语句处，就像整个函数体在调用处被重写了一遍一样。 所以在这里我们推荐在header中只实现Declaration，而具体的Definition就只在某一个cpp中进行编写。 机器码：Visual Studio中可以将输出的obj之类的，包括代码中转化成汇编代码去看，就能知道我器的实际运行逻辑，在VisualStudio中我们也可以设置针对汇编的自动优化来提升算法的运行速度。（一般是在release中会自动优化，而Debug中便于定位问题就没有优化） Debug标识符： C：Compile Error；LINK：Linker Error Static标识符：在变量的部分细讲，实际上对于编译过程也是一个很重要的关键词 1.2.3. Build： 头文件（Header Files） 一般在header 中写入declaration，然后把definition写在Cpp files里面。 #Include 命令 \"\" 或 <> \"[content]\" : content是文件的相对路径，可以使用类似..去索引 <>:一般用来索引标准库之类的，用\"\"来存储.h之类的文件 有.h后缀的导入一般是C，Cpp的就没有后缀 #Pragma once 这个hash tag的作用是让预处理仅仅只编译头文件一次，就是多次import也不会重复编译把，这个东西不要删除它。 原理上是取代了原本的ifnder；实际上也是一个宏 #ifndef Tag1_H void functionA(int var1); #endif 基本概念：使用通用的header文件，将一些include放入header中，然后对这些header进行预编译，生成二进制文件。这样的话， 我们就不需要每个cpp中的#include .h 都对其中的所有的include在进行copy paste然后进行编译，这样的话，加入了很多不必要的编译过程。 也不用每次修改代码进行编译测试的时候，都有繁重的编译工作要去做了。 使用情景： 在大型工程或者文件的时候使用头文件的预编译器是非常重要的。用它 对于一些通用的常用的操作或者文件可以放进去，但是频繁更改的那些内容就不要放进去了，每次进行重新的预编译是浪费时间的。 主要是一些include，declaration就别放在这了把？ 预编译的header可以对project中的所有cpp负责吗？还是需要include 但是那些特定的依赖项，对于专门操作或者环境的，我们还是放到特定的cpp中，这样会使得代码更加易读，也不会增加负担。实际上就是两方面的考量，特定的和通用的两种处理方式。实际上取决于依赖程度； Visual Studio中的使用方法 创建需要预编译的头文件pch.h;创建pch.cpp 包含#include \"pch.h\" 右键pch.cpp属性：c/c++ ->预编译头->预编译头（使用） 右键项目属性： c/c++ ->预编译头->预编译头（使用/create） c/c++ ->预编译头->预编译头文件（pch.h） 试一下把，不对的话，再回来检查视频。（可以在vscode的设置里，project c++中设置编译时间输出） 1.2.4. Build：代码存储的文件结构 补充说明：VS侧栏的文件夹实际上只是分组，不是真实文件夹，所以我们在哪创建h和cpp都一样 Rule1: 推荐在header中只实现Declaration，而具体的Definition就只在某一个cpp中进行编写。 Relu2：在大型或者规范的Project中建议修改Vscode 的文件保存设置，当然我们也可以根据自己的需求去修改。 输出目录：$(SolutionDir)bin$(Platform)$(Configuration)\\ 中间目录：$(SolutionDir)bin\\intermediate$(Platform)$(Configuration)\\ 1.2.5. Build: 宏（Macros） #define的各种用法；实际上就是通过预处理器对某些操作进行宏处理，“我不喜欢过度使用宏，这样可能比较不方便阅读”这点上其实和template是一样的道理。 2. define: 实际上就是在代码中搜索指定的文本进行替换 是一种文本级别的操作 推荐的使用方法： 约定俗称的名称或者表达，或者一些简单的函数（但是实际上为了便于阅读，并不是太推荐，见仁见智把） #define pi=3.14159265:类似的一种约定俗称的value #define LOG(x) std::cout Debug：条件与动作断点 基本操作： 设置breakpoint 内存信息读取：从debug-windows中可以调出各种窗口，从变量名或者&para找到内存地址也可以 条件与动作断点： 当然我们可以在代码中嵌入循环来使用普通断点来实现这些，简单的就是在断点的地方使用右键。主要的优势在于，我们无需暂停我们正在运行的程序，就可以执行这样的Break. Conditional：条件断点就不说了。 Action：就是不需要stop我们的运行，我们添加了以后，就能在执行我们断点的操作的时候，在terminal输出，我们设置的action（简单的来说就是用于监控运行过程中的参数变化） Lib： Using Libraries 外部依赖的使用 Static Linking and Dynamic Linking静态与动态链接库 基本思想：希望在C++中不需要进行Package Manage 也就是不需要自己再去一个个的下载依赖项，也就是希望能pull下来就能用。 以GLFW为例，我们下载的时候可以下载2进制文件也可以下载源代码；下载的时候是x86还是x64与编写的目标代码有关，和OS无关。 动态静态连接的基本概念 静态链接在编译的时候实现，而动态链接是在运行的时候才操作； 静态链接，意味着这个库直接放到可执行文件中（比如说exe） 静态链接在一些情况下会更快，而且我们可以进行各种优化，所以这个作者比较喜欢静态优化。 静态链接可以实现更多的优化操作，实际上是你exe中的一部分 动态链接，在运行的时候加载DLL（动态链接库）之类的。 询问dll载入调用到的函数，静态lib就是一次性把所有的都载入了 它实现在运行过程中，linking一个外部文件，而不是可执行文件的一部分。 当然也可以在你启动电脑的时候就启动，也可以设置为require，就是没链接就会完全报错。 静态和动态连接的具体实现 静态链接的具体实现：Head File，Include file的形式 创建dependency文件夹然后->libraries子文件夹(归属关系) Copy include 和相关vs版本的lib文件夹进去 如果我们使用静态链接就和lib有关，如果我们使用动态链接就和DLL有关。 在VS 设置中c++ general +额外包含文件夹+相对文件夹（${SolutionDir} ->include文件夹）的路径 如果需要我们也能在这看到其他的指代路径的意思 然后include (其实使用双引号也没问题) 这个头文件实际上支持动态链接和静态链接（include中的） 这里提供了declaration，但是没有实际的definition，所以我们还需要 VS设置Linker/general/ Addition Libraries设置相对路径(Lib-vsxxx)和刚刚类似 VS设置Linker/Input/Additional Dependencies设置具体lib文件的地址 Over 第二种静态链接的方法(不推荐) 在前面的库设置好了以后，我们也可以不include，但是我们要声明（declaration）这个函数存在，注意类型不能错（这就好麻烦） 需要注意的是，我们链接的有的函数实际上是c而不是c++，这种时候就要添加前缀： Extern \"C\" 动态链接的具体实现：基于静态的实现来分析 dll和dll.liB需要同时使用，lib提供了一堆指向dll文件中函数的指针，两者直接相关。 也就是相对于静态链接改变dependency中lib文件为dll.lib 然后要把dll放在我们需要运行的exe的同一个文件夹下。 Lib：Multiple Project 编写自己的Lib或Dll 在解决方案Title下可以添加项目，一个解决方案下多个project 将主project的属性中配置类型设置为exe 将依赖文件设置为lib 或者dll，所有的配置和平台 同样的在h中下写declaration在cpp中definition，然后在include的时候，由于路径不在一个文件夹下，所以我们可以用相对路径的方式设置，但是这样就比较傻，正确的做法：&#x1F447; 属性，c++通用，额外的包含目录，把该目录放进去就行了 但是这样其实我们没link，所以我们可以通过再主项目中右键添加引用，把我们要的引用添加进去，就可以了。（当然我们也可以生成lib再用） 但是这种情况好像只适用于同一个项目文件夹的时候。 这种自动处理同时会自动执行engineer的build 在这里使用了namespace的写法，也许就是和类中的函数是特别像的把，也就是std那样的双冒号 Lib：Timing 计时器 C++中的计时器功能：主要用于统计程序运行时间和控制进程等等的操作。 具体还有timer的cast还有一些单位转化的工作，去cpp中查找或者看benchmark那课的视频 主要使用的库：#include // 还有一个暂时不知道起什么作用的namespace using namespace std::literals::chrono_literals; // 获取当前的时间 auto start = std::chrono::high_resolution_clock::now(); // 获取时间间隔的方式，这里的type比较特别 std::chrono::duration duration = end - start; 上面这个方式,如果每次都要调用的话，就写得比较麻烦，如果我们希望能够比较简单的得到比如某个function运行的时间，我们可以利用lifetime签署一个类别，在function开始的时候定义一个就可以了。 看下面的实例： struct Timer { std::chrono::time_point start, end; std::chrono::duration duration; Timer() { start = std::chrono::high_resolution_clock::now(); } ~Timer() { end = std::chrono::high_resolution_clock::now(); duration = end -start; // std::endl 实际上比较慢 std::cout Lib：Sort排序iterator std::sort need to include ；这是c++标准库中一个对Iterator进行排序的库。 复杂度 O(N·log(N))，其中N=std::distance(first,last) 参考网站：https://zh.cppreference.com/w/cpp/algorithm/sort //简单实例 #include #include #include //其中有一些分类的标准可以调用 int main(){ std::verctor values = {1,3,4,5,2,6} std::sort(values.bagin(),values.end()); //空载或者是基本的用法 //如果我们试图自定义函数的话 std::sort(values.bagin(),values.end(),[](int a, int b){ if (a==1) return False; //1放到其他所有的后面 if (b==1) return true; // 同上 return a 2.1. Part 2 “变量”的使用和定义 In this section we‘ll introduce variables（data structure） in C++，主要是变量的声明和使用方式和用途，生存周期，存储空间，各种Keyword，类型转换。 2.1.1. 变量（Variables） As we know all datatype in machine is different number 实际上就是给机器指定存储的空间和解析的类型。 Char 实际上只是内联了“数字到字符的转换”，所以我们可以用各种类型来输入字符或数字（主要是内存空间占用），但是最后表达的类型会根据我们预定义的类型相关，有内联的数字和字符的转换存在。 基本的数据类型 实际上就是预先定义了内存的分配了表达的类型，大小实际上取决于编译器。 可以用sizeof()查看各种类型占用的内存空间大小 Keyword： 整型： ​ char（1 byte）；shot；int（4 byte）；Long；Long long（8 btyte） ​ unsigned 非整型： ​ Float（4 byte）；double（8 byte） ​ 实际上是精度类型，比如再数据后面+f指定精度类型 BOOL： ​ bool （true， false == 0）；!0 即True Void： ​ 类型未指定 特殊类型 指针类型（Pointers）：再类型后面+ *: int* variables 引用类型和取值符号（reference）： 引用： 在类型后面+&:int& refer 取址：int* a = &variable; 变量的作用域（{}）和生命周期 作用域：在哪个范围内能访问到该变量 生命周期： 在内存中存在的范围（stack变量一般是活不过}） 需要跨越作用域的生存的话通常需要指定存储heap object“对象”的生命周期 （不使用New关键词的时候）生命周期只到栈或者说是大括号内（可以使用空的大括号组），是存在的 （使用new关键词的时候）如果我们不delete它，就只能在程序终止的时候才退出了。 :x: 下面这是一种十分错误的写法 int* CreateArray() { int array[50]; return array; } int main() { int array[50]; CreateArray(array); } //完全错误，在函数结束的时候这个指针会被完全销毁，所以指向的地址是没有值的， 如果我们希望延长声明周期，我们可以将数据分配到heap上，或者通过传入指针，对指针调用的地址的值进行修改。 编写一个会自己销毁的在heap上的指针（实际上和智能指针又异曲同工之妙） class ScopedPtr { // 该ScopedPtr的申明是存在stack上的，所以销毁的时候调用delete就直接。 private: Entity* m_ptr; public: ScopedPtr(Entity* ptr) :m_ptr(ptr){} ~ScopedPtr（） { delete m_ptr; } } int main() { { ScopedPtr e = new Entity(); //申明周期也只到内部的大括号，出不去。会顺便把实例也销毁了。这个还稍微有点疑问。:question } } const 常量修饰符 C++ const 关键字小结 | 菜鸟教程 (runoob.com) 语义含义：不可变，不可修改； 可以令值不可变，也可以令指针不可变；定义一些常量之类的东西 可以在函数传入值中定义，使得传入值不可被修改，或者防止传入的指针或者是引用被不正确的修改导致一些奇怪的问题。 要注意根据位置的不同是指针不可修改还是值不可修改的含义是不一样的。 本质含义：实际上是一种代码的可见性机制，只是个promise，用来简化我们的代码。所以我们应该遵守它：就是我们不去修改这个const。（避免使用强制类型转换去修改它） 几种基本的定义方式： 这种形式指的是我们没法修改地址的值，但是我们可以改变指针所指向的地址。 //这两种都是一样的，在指针*的前面 const int* a = new int ; int const* a = new int ; 这种形式指的是无法修改指针引用的那个地址，但是可以随意的修改值。 int* const a = new int 复用就是都不能改 在类中的public函数declaration的括号后面加 const，指的是我们没法在类内函数中修改类内的private的值。这样的操作会被定义为illegal。 类内指针的话就有意思了，要有三个const全用 :question:这一点后面慢慢补充，没搞清楚来着，记得太模糊了。 const Entity& e 指的是我们没法修改指向的地址。 实例说明： 对于传入函数的Instance（Entity）也是一样的，如果我们不希望进行内存上的copy，我们就加上&，如果我们不希望改变值就加入const。 用一些例子来说明一些其他情况的Const用法。 需要注意！ class Entity { private: int m_x, m_y; public: int GetX() const //需要保证函数不能修改类内的private的值 { return m_x; } } // 但是还是有一些问题 在这种情况下的const最前面的就是指的指针的地址不能变，但是其中的值能变。那么在这个时候，涉及到实体的那些函数，如果我们再类中没有加入const后缀的话，那么我们就不能使用这个get函数，因为编译器不能确保他不修改我们不能动的那些数据。 所以有时候会出现一个+const的定义和一个不加const的定义。 如果我们对一些private需要指定在一些const后缀的情况下可以改变，那么我们可以再声明的时候加入mutable前缀：允许的可变。 void PrintEntity(const Entity& e) { std::cout Mutable可变标识符 用途1：基本上对于一些private类，在有const后缀的情况下我们又希望修改其中的某个值，才会用到这个关键词。 class A { private: std::string m_name; mutable int m_DebugCount = 0; public: // 结合上面的范例可以看出这个返回类型为啥回事这个const+& const std::string& GetName() const { m_DebugCount++; return m_name; } } 用途2：使用lambda的时候。我们希望能够修改传入值本身，（但是lambda是不允许修改的所以需要） int x = 8; auto f = [=]() mutable { x++; std::cout Static静态标识符 静态标识符类型： class or struct 内部，外部，function 内 类外的static： 对于Linker起作用的修饰符，表示为局部的，也就是只对它本身的obj起作用，不会和别的文件连接起来，只对本身可见。 如果在function的前面添加Static 就表示该Function 只被该.cpp调用，也不会考虑外部的Link，所以当我们如果希望被外部调用的时候就不能加static标识符，在要调用的地方进行declaration. 实际上全局的参数定义，对于Linker来说也可以是跨文件的，所以如果我们定义全局参数的话，我们要考虑是否是通用的（需要重复include的常量），就可只在cpp定义一次。同时我们要在引用（另一个文件）的时候添加修饰符。（比如在头文件中用Extern Declaration参数） Extern（也是用于声明：在外部已经定义过了，定义参数独有的） https://www.cnblogs.com/lulululu/p/3693865.html 类内的static： 这部分*memory对于这个类别的所有实例是共享的，换句话说也就是，无论你定义了多少个instances，这个变量或者方法也是唯一的，对于所有的类别是通用的。你改变了一个，也就改变了所有。 所以，类内的静态方法可以在没有类实例的情况下被调用，而且在这种静态方法中不能refer to 一个具体的类实例。 也不能通过实例对静态变量进行调用处理，这样Linker会找不到我们实例对应的变量，因为那几个变量是类的变量而不是实例的变量。那么怎么去调用或者修改呢。 使用作用域(type ClassName:: x)的方式去声明,同样也以这样的方式去调用（ClassName（同样也能类比成namespace）:: x）才是真正正确的使用方法，类内的静态函数也是这样定义和操作的。但是不用像参数一样在类外声明 Function内的Static： 其实和类内的Static是一样的，当我们第一次调用这个function的时候就会存储这样一个对于所有的function的静态变量，后续调用的时候这个参数就不会被重新创建了。 也就是说这种参数对于函数来说是恒定的，在该参数上进行的变化会被继承下来，也就是会被迭代运作。 某种程度上来说也算是延长了参数的生命周期，通常来说需要&的return值的一些情况下就需要用static关键词定义的vars。(:question:这一点是啥意思来着） 2.1.2. 数组、多维变量（Array） 经典数组 数组实际上是一组连续的变量，在内存上存储指定长度的空间，本质是指针 定义方式：type var[n],定义n个连续的type内存空间，这里的var实际上是相应的指针 int example [5]; int* ptr = example; 用var[idx]去索引指针相应地址的值：（实际上就是在初始地址上加上相应的偏移） 默认在stack上：没有new就是在stack上，需要heap就＋new把 记得delete[] 同时也可以用New关键字去声明数组，同时这个数组就会被存储到Heap中，这样的话该数组的声明周期就能活过大括号了，需要我们手动调用delete命令去删除它，由于定义的形式是数组所以在delete的时候记得使用的是delete[] var 命令 int* another = new int[5]; for (int i ; i 和传统的array好像有一定的同质性；找到数组长度的方法： int count = sizeof(a) / sizeof(int); // 用std::array的会自己保存数据的array 静态数组（std::array） 数组的长度或者大小没办法自动（动态）改变的，我们应该用这种方式来代替传统的定义方式，有很多好处。 https://blog.csdn.net/thinkerleo1997/article/details/80415059 https://blog.csdn.net/fengbingchun/article/details/72809699 #include std::array data; 什么时候我们应该用这种array来取代传统的int array？ 现在这种方式有很多的集成函数：比如说size，sort，began好像还有iterator之类的方法。 因为传统的使用New，关键词是slow的，这种方法也会快一点，而且长度是不知道的。 verctor是heap上的，而array和传统的int，array都是存在在stack上的，（非new关键词） 有很多优化，同时这种方法有自动的边界检测？ 在函数传入array的时候，建议可以使用template的方法。 BTW：快不是标准库（STD）的基本目的和最求，所以很多时候需要资源最大化利用的情况下，很多project都会编写自己的数据类型：（可以从Cherno的最后两课去看看） 动态数组（std::vector） 更详细的一些操作指南可以google或者看HR的vector.svg(附件) 就是个不指定大小的Array，可以改变数组的大小，其实就是自动执行内存的重新分配（内存动态分配），牺牲性能来得到更好的便捷性。 虽然C++命名Vector，但是实际上是个动态的ArrayList，而不是向量。 vector移动数据而不是Copy的方式在很大程度上提升了效率（没超过默认大小的情况下），但是在超过了指定大小的时候，还是需要用到copying（内存的动态分配）这就不是一个非常理想的情况。 Vector：当append超过了现有的容量，找到一个足够大的内存位置，然后把原本的参数copy迁移过去，然后加上我们要添加的参数，然后删除原本占用的内存空间。 这样就会造成运行缓慢，那么我们如何避免这样的copy操作， https://blog.csdn.net/theonegis/article/details/50533770 基本的声明方式 #include std::vectorname; //type 也可以是自己定义的class；实际上存储的就是数据的内存顶点（起始点） // using vector = std::vector以后 vector a; vector b(a); //声明容器b, 用容器a初始化b vector b(a.begin(),a.begin()+3); //用0-2个元素来初始化 vector a(num); // vector a (num,value); 基本的一些method Push_back({v1,v2,v3}) 就相当于append；size（）获取长度；clear（）将长度设置为0 索引还是[]； eraser（）：需要在括号中设置一个迭代器，比如我们需要移除第二个参数 ​ ↑：vertices.begin() +1 使用示例： std::vector vertices; vertices.push_back({1,2,3}); vertices.push_back({4,5,6}); for (int i = 0; i 存储空间 默认应该是在heap上的，但是会自动删除的。 优化vector的使用 issue1：我们会先调用最原始的构造函数，在main function的栈中构造一个vectex，然后copy it to Vertor类所在的空间中，如何直接在指定的地方添加（或者说只进行一次构造）呢？ 解决方法：用emplace_back取代push_back,直接传入构造对象需要的参数即可 vetrices.emplace_back(1,2,3); vetrices.push_back(vetrices(4,5,6)); issue2:空间超过以后进行了复制和迁移操作，也就是我们每一次添加都需要把原本的空间进行resize（copy and move） 解决方法：直接在开始的时候指定可能的最大size，就是给定一个预留空间 std::vector Vertices; Vertices.reserve(3); 2.1.3. 字符串（String） String - stream of text 一组字符串 == array of characters 一些额外的信息：字符串相关的一些其他事项 实际上\"\"定义的就是固定（const）的type为char的指针，也就是 const char*；换句话说也就是占据固有长度的char array 实际上这是c中编写string的风格，为了熟悉基本的原理才这么编写的，现在就直接用string库了 原本定义的时候还需要在末尾指定ascii码终止符，但是在新的版本中不需要特地指定，也就是下述的两者是一样的。 char name2[7] = { 'A','i','k','e','n',0}; char name2[7] = { 'A','i','k','e','n' }; 基本信息: 使用string的基本注意事项 基本的定义方式也就是和int之类的没区别 string类别就可以使用find size append +=之类的操作了，所以拥抱string； 官方的参考链接地址（看看其中的function的作用）： \"\"定义的类别实际上就是const char[]，本身就是一个不可修改的指针了，各种意义上的不可修改 ''定义的才是像普通的123这样的char value string实际上也是std中的一部分: 同时include它包含了重载 +=不能再“”中执行，但是可以在string和“”中进行。 将string 传入函数的时候，也是不修改原值的，所以我们还是使用&的传入参数设置去使得不需要赋值一个新的，同时如果不希望修改的话，就在最前面加入const String Literals 实际上我们在上面说的“”定义的就是String Literals，字符常量，这种方式定义的后面会自带一个休止符的位置，再内存中也就是00；我们也可以手动定义休止符\\0 实际上我们修改string都是再内存中获取一个Copy去进行的。所以我们需要善用&符号 一些函数： Strlen（）:返回string长度，char array，要注意自己手写休止符的特殊情况 基本的“”实际上也是utf-8类型的。 const char* name = u8\"Aiken\"; //1 byte const wchar* name2 = L\"Aiken\"; // (2/4) byte const char16_t* name3 = u\"Aiken\"; // 2 byte const char32_t* name4 = U\"Aiken\"; //4 byte 可以使用 using namespace std::string_literals使得我们对 “” -> string的类型转换可以从 std::string(\"\")变成只需要\"\"s R\"\" 也很有用，:question:但是我忘了这个是用来干嘛的了 2.1.4. 枚举类型（ENUMS） 枚举类型：也就是set of value 根据第一个var = x; 后面每一项的默认值在前一项的基础上+1，自动匹配对应的value 本质上就是一组指定的别名和其对应的value class example { public: enum Level: unsigned char { L_error = 0,L_Warning,L_info }; //取代了下面这种表达其实 /* const int L_error = 0; const int L_warning = 1; const int L_info = 2; */ private: Level m_logLevel =L_info; } 2.1.5. 自动类别指定（Auto Keyword） 可以结合模板来使用 实际上就是根据我们键入的等式右边的内容，自动指定int float or any other type。 但是作者不是很推荐这种用途，很简单的情况，就很没必要，而且不利于阅读和维护auto a = 4; 比较推荐的用法： 调用函数时的返回值前缀： 在这种情况下我们修改function（API）的return type的时候就不需要重新在修复赋值的定义了，这种时候auto还是很有用的，或者返回类型不明确的时候。 // 比如function的type 我们可能经常会动，或者有几个相似的函数的情况 char* GetName() { return \"aiken\" } int main() { auto name = Getname(); } 缺点：但是这种方式的话实际上也会让我们是否修改了代码的指示比较不明确，比如有时候会发生隐式转换。 替代特别长的数据类型： 比如使用像vector这种的时候，参数名实在是太长了，就你懂的了，推荐使用（当然这种可以用using 来取代也是一样的。） // 使用 using的话就是。 using DeviceMap = std::unordered_map>; DeviceManager dm; // 话说下面这个应该是 值不可被修改的别名（因为&本来就无法修改地址，所以只有一种可能把） coust DeviceMap& devices = dm.GetDevices(); 2.1.6. 模板（Templates） 模板可以理解为一种指代，简单的例子就是通过这种模板的定义我们可以定义一个类别通用的函数； 模板实际上是在编译的时候就实现的一种机制，而不是到了具体的运行的时候才实现的。 简单使用场景： 当我们需要多种类型的输入，来进行相似的function操作，比如说Print的时候，这种时候我们定义一种TypeName的模板；然后我们就可以使用如下方式调用定义的函数了。 template void Print(T value) { std::cout(5); //其他类型的也可以，只要函数内部支持就行。 除了不确定的类别，我们也可以针对不确定的size去做（其实这里的int类型可以改成size_t） template class Array { private: T m_array[N]; public: int Getsize() const {return N;} }; //main Array array; 但是不要过度使用，因为可读性会比较差；但是更关键的是，模板在编译和执行的时候是两回事，这样会让我们很难定位问题。所以不要乱用。但是在编写loging的system之类的地方，就比较合适。 2.1.7. 操作符与操作符重载（Operators and operator overloading） 更多的表现是符号而不是函数，new ， + - ,之类的都是 括号 与或非： || && ！ 一些优先级设定： ++之类的运算符号的优先级> 取值，所以我们要*加入括号，使其首先解引用，防止改变的是地址的值而不是value。 重载的用途： 比如我们实现向量类别的时候，我们就可以重载+，来实现这个加号，就是不用写一个Add函数（麻烦），主要是比较大规模的情况下为了使用方便来写的吧。 Example： Vector2 Add(const Vector2& other) const { return Vector2(x + other.x,); } Vector2 operator+(const Vector2& other) const { return Add(other); } 为了更方便的cout重载 std::ostream& operator 对bool的判断进行重载： bool operator==(const Vector2& other) const { return x==other.x && y== other.y } bool operator!=(const Vector2& other) const { return !(*this == other); } 重载迭代器的索引 char& operator[](unsigned int index) { return m_buffer[index]; } 2.1.8. 命名空间（Namespace） Using namespace apple (导入apple中所有的定义) Using apple：：func1（只导入func1） Namespace a = 定义 类似的查看cppreference网页即可 2.1.9. 左值与右值（lvalue and rvalue） 其实就是赋值等式左边的变量和右边的常量的关系把？在这部分还会讲到相应的reference。 rvalue就是 i=10中的10，这种值不能被更改，是一种临时的变量值，没有location和space，我们会将它分配到i，也就是左值。才是可分配和可改变的。实际上就是这样的。 rvalue可以用来创建lvalue，lvalue才有reference，但是有特殊规则； int& a =10 // error,这样写是错的，rvalue没有直接的引用 const int& a =10; //right 了解这点的意义在于（为啥我们要使用const） std:string fName = \"H\"; std:string Lname = \"Aiken\"; std:string Fullname = \"Aiken\" + \"H\"; // 这个等式左边的全lvalue, 等式右边的（整体）都是rvalue，于是我们调用下面函数的时候，无法写输入值为\"Aiken\" + \"H\"，因为rvalue没有& void PrintFuc(std:string& name){} // 我们稍微修改一下，就能得到一个通用的Print,能够对临时变量rvalue进行传入。 void PrintFuc(const std:string& name){} 假如我们需要一个只能传入rvalue的函数，那么我们可以将表达修改为，这是一种特殊的方式 void PrintFuc(std:string&& name){} 这种方式有什么用呢？对于下面的移动语义很有用，因为临时的变量不需要考虑livetime或者memory之类的东西，同时我们可以简单的获取其中的值，不用担心他和很多其他的地方产生关联。 2.1.10. 移动语义（move semantics） Question：为什么&引用符号不能解决这个问题，好像是对传入object的情况进行处理的一种方法：就像string，我们在某个地方需要她的时候，我们可能需要重新构造它。 Ans：移动语义针对的对象实际上是Rvalue，也就是临时变量，临时变量的生命周期短，特别是像“”到string的情况，也是需要申请空间的，这样在我们将rvalue传入function或者class的时候，就会发生一次不必要的copy（因为rvalue没有&所以你懂的） Move Semantic： move objects around 为了避免类似的不必要copy的操作，我们就使用移动语义的编程思想来做。&#x1F447; move就是获取原本存储地址的指针，然后再将原本的指针赋值为nullptr（这样会使得其自动调用析构函数，也就不会有泄露等错误了）同时将size设置为0。 相比较于深拷贝实际上就是一种浅拷贝的操作。 具体的实现思路其实就是针对rvalue重构copy constructor //copy constructor 如下,以class string为例 //基础类别的部分 string(const String& other) { printf(\"Copird!\"); m_size = other.size; m_data = new_char[m_size]; memcpy(m_data, other.m_data,other.m_size); } //重构rvalue情况下的.. string(const String&& other) noexpect { printf(\"Move!\"); m_size = other.size; m_data = other.m_data; // 清除原本的指针 other.size = 0; other.m_data = nullptr; } // Entity部分，要添加一个针对rvalue的构造函数 Class Entity { public： Entity(const String& name) :m_name(name) {} // 这里注意要手动把转换写出来，不然还是会进行copy的情况(执行上面那个),move 或者(string&&) Entity(const String&& name) :m_name(std::move(name)) {} private： string m_name; } // main 部分 Entity entity(\"aiken\"); entity.print()// .... std::move()左右值转换 参考资料： 详细解析；Anthor one 2.1.11. 可选数据（Optional Data）（new in C++17） 基本设置：项目，设置，C++，语言，c++语言标准>17 针对那些我们可能会使用也可能不使用的可选数据。这也是一个c++ 17的内容：https://zh.cppreference.com/w/cpp/utility/optional 传统的就是通过引用传入一个bool flag，然后通过flag去判断是否存在之类的。但是有了optional我们就可以如下的方式去做 #include #include std::optional readfile(cosnt std::string& filepath) { std::ifstream stream(filepath); if(stream){return string1} return {}; //这种写法其实是空tuple？还是要学一下的。 } auto data = readfile(); //或者写那一长串optional string //然后就可以使用 if(data) 或者 if(data.have_value()) 还有另一种使用方式就是，用于设定不存在数据的默认值。 std::string value = data.value_or(\"sdsds\"); //如果data是空的救会取到这个，相当于默认值把。 //比如 std::optional count; int c = count.value_or(100); 2.1.12. 多类型变量（MultiType Variable）（new in C++ 17） 换句话说就是数据的类型是在指定的范围内可选的，依托于#include通过指定数据可能的Type，然后用特殊的方式取出来。 它实际上存储的是所有类型的长度相加的空间；虽然能实现和unions类似的功能，但是实际上是更安全的。就是存储空间的占用更大？两者相比推荐这个把。 std::get_if：对于这类型的数据很经常被拿来使用，我们可以参考这里的用法 std::variant data; data = \"Aiken\"; // 这种数值取出的方式只有在类型正确的时候才会起作用，不然会造成exception std::cout(data)(data)(&data); // and we could use it like that if(auto value = std::get_if(&data)) {} 针对Get_if的具体实例可以写成这样： #include #include int main() { std::variant v{12}; if(auto pval = std::get_if(&v)) std::cout 此外我们也可以通过这种类型来定义函数：这种的使用方式可以像这样看（对于可选的话，只是返回一个空值，这样可以更加具体的定义我们为什么访问不到文件），但是这种方式的话，不能用auto来代替吗 //因为我们要当成类型传入，所以需要class但是这里不用return值吗 enum class ErrorCode { None = 0, NotFound = 1, NoAccess =2 }; std:: variant ReadFileAsString () { return {}; //这里应该也是需要修改的把，改成ErrorCode类型 } 2.1.13. 任意类型数据的存储（store any type）（new in C++17） 我们也可以使用空指针来存储任意类型的数据；但是这不是这一块讨论的内容，这里讨论的是std::any 就是一个能存储任意类型的variable，实际上和variant很像，但是那个更安全，因为我们知道所有的可能类型；同时这样的方式也会避免any可能会带来的动态内存分配，这个我们知道是相当影响性能的。 #include std::any data; data = 2; data = \"aiken\"; // variant 指定string的时候实际上会发生const char * 到string的隐式转换，但是any是不会的。 //any 取出变量的方式如下,在这种情况下数据类型不匹配的话，是不会成功取出的，我们还是需要知道我们当前的any type 以及按照指定的方式取出，所以实际上variant是一种更为安全的方式 std::string string = std::any_cast(data); //但是这样的话我们还是会有一个copy的操作，我们是否能够直接返回一种引用&#x1F447;（别名） std::string& string = std::any_cast(data); 使用的情境： 实际上是存储空间是有默认的小规模存储空间和大规模存储空间(限制);超过了小规模（32byte？）的情况下会使用动态的内存分配的机制。 当我们需要用any存储类似struct之类的大数据的时候，any可能就会调用new来动态的内存分配了。 能用variant就用，不行，导致非要用void*（空指针）的情况下就用any；但是最好的话，我们是不需要这种东西的。 如何使用： 2.1.14. 多维矩阵（2D+Array） n维数组实际上就是n-1维数组的堆叠：array的array 也就是其实是指针机制：指针指向的地址存放一组指针，然后这组指针再指向各个Array，这就是2d array了。关键就是 指针的指针** 多维矩阵第一次取出的时候实际上是指针类型，多重取出的最层才是数据。 int main() { // 实际上就是用指针的指针的方式分配多维度的数组，更多维度也是一样的（星星更多了）。 int* array = new int[50]; // 分配50个存放int指针（int是返回的类型不是指针的类型）的空间 int** a2d = new int*[50]; //绑定了50个内存位置 ------------------------------------------------------------------------------------- //实际的定义多维数组的方式,更高维度的就要嵌入更深的循环。 int** a2d = new int*[50]; for(int i=0;i 问题来到了下一步如何删除多维度的数组？ 如果我们只delete最外层的指针，那么内部的所有指针地址，将会发生内存泄漏。 所以：我们需要像定义那样，反向的对每个指针都进行delete for(int i=0;i 这些50*k的存储空间实际上不一定是连续的，但可能是接近的，实际上是，再内存中随机的分配50个buffer来存放50个array，这种方式会越来越慢，（因为缓存的命中问题？），连续的存放可以使得缓存有更高的命中率来提升速度。 再某些情况使用1d array来代替2d array比如下（这不用看了，谁不会啊，手动换算行号呗），但是这样的代码在执行的时候，快很多 int* array = new int[5*5]; //我还以为，是类似的写法也可以，这样的话，谁不会啊。 for (int y=0;y 2.1.15. 隐式转换和显式转换（Implicit Conversion and the Explicit Keyword） 隐式转换和显式关键词 隐式：不用告诉他他究竟要做什么 很多时候由于类的构造函数实现，基于类的输入类型，我们可以将函数表示的初始化，转化为等号的。同时也能在一些特定的场景下执行内置的类型转换。 但是如果是我的话，我尽量不会这么去做&#x1F51C;，因为这样会增加阅读的负担。 显式关键词：不让执行隐式转换 Explicit 加在构造函数的最前方，这就是让构造函数只能被显式调用，不能执行隐式调用。 #include using String = std::string; class Entity { private: String m_name; int m_age; public: Entity(const String& name) :m_name(name){} Entity(int age) :m_age(age){} }; void PrintEntity(const String& name) { // print } int main() { // 在这一步中C++将根据构造函数进行隐式转换，前提是对应的类别要是正确的 Entity a = 22; Entity b = String(\"aiken\"); // 第二种自动进行隐式转换的场景，实际上和上面是完全一致的 printEntity(String('asdad')); std::cin.get(); } cast：类型转换从typeA-> type B int（22）之类的 所有的类名也能这么做（借助隐式调用这样的） 2.1.16. 类型转换（Type Casting） cast实际上会为我们检查类型是否正确等等 显式转换：显式的指定我们希望将当前类型强制转换成什么目标类型 double s = static_cast(value)+ 5.3 隐式转换：不需要我们显式的指定转换的数据类型，根据输入输出会自动转换 // 反过来也是可以的 double value = 5.25; int a = value; // 我们同样也可以显式的指定,但是这种转换不是强制的，只是显式的表达 double b = (int)value;//safe style csat的样式 double b = (int)value +5.2 //我们可以看看没有这个int的结果 实际上存在四种不同的Casting：static_cast，const_cast，dynamic_cast，reinterpret_cast ，这几种cast的使用请 GoogleIt来补充基本的含义，以及一些使用情况，（CPP reference是真的牛逼） 在一些情况下转换失败的话会return null，所以也可以用做派生类的检查。 const：用来从const到非const dynamic：用于从基类到子类的指针转换，（反过来可以，但是实际上不需要显式转换） 其实是一种function，实际上会有一些额外的操作。 如果这个转换是错误的，那么这个指针会返回null，所以实际上，这个指针可以用作类型之间继承关系的验证作用。 // 基本定义 class Entity {}; class Player : public Entity {}; class Enemy : public Entity{}; 实际上由于存储了运行的中间状态（runtime type infomation默认是启用的，关闭会报错），所以是可以知道该类到底是啥的，也就是支持从基类推导到该子类到底是啥。 Player* player = new Player(); Entity* e = player; //毫无问题 Entity* e1 = new Enemy(); Player* p0 = dynamic_cast(e1); //这种转换不可行，会return null Player* p1 = dynamic_cast(e); //从基类转换到子类 ok，但是这种情况下我们需要指定多态，也就是virtual 为了避免冲突，这其实是一个多态的用法 if(dynamic_cast(e1)){} //验证类型的用法 reinterpret:用于无关类型的转换，还是需要再搜索一下，不太常用，推荐的可以使用的情况，类型转换转换回原本类型的时候 这种类型转换实际上是更可靠的。 2.1.17. 类型双关（Type Punning） 实际上就是获取某种类型变量的指针，然后转化成另一种类型的指针的操作。 Google it 当然接下来我们也可以解引用,其他之类的。 首先看一串示例代码（double）实际上是为了让到double的隐式转换更加清晰，并没有真正的操作指令。 // 这样的操作实际上就是a-b的隐式转换，但是这样的话，内存空间实际上是没有公用的，b是用的另外赋值的双精度的5 int a = 5; double b = (double)a; // 反过来也是一样的道理 如果我们想要直接使用指针转换，将double指针转换到int指向的内存地址，这样的话，由于两种类型的长度不同，所以会导致输出错，严重的话还会导致崩溃。 但是实际上，这样的操作，我们可以通过同样长度的内存操作，来直接的对内存进行操作，但是正常人没有人这么干。 struct Entity { int x,y; int* GetPositions(){return &x;} }; int main() { Entity e = {5,8}; int* position = (int*)&e; //将struct的指针转化为int指针 std::cout 2.2. Part 3 Poniter & References指针与引用 从指针的含义出发，对各种不同指针的用法，引用场景，内在含义，进行分析，记录世界记录你。永远的神，指针。 指针实际上就是一个1byte的整型值，它就是一个地址，指示你在内存中存储该值的位置，和类型没有半毛钱关系，类型只是指示你可能放了个啥类型的数据在那个地址Void* ptr = &var; 引用和指针本质上是一回事，用法上会有所区别它实际上是基于指针的一种高级修饰，是对某个已经存在的var的引用。他并不是一个真正的变量。Int& ref = var。 引用能做的指针都能做，实际上是一种代码的优化和简化过程（moew clean），主要的用处就在将var而不是value传入function（达到能够直接修改var的作用） 2.2.1. 指针基础（pointer） ->的访问方式：实际上等同于(*e1).method，Arrow->只能在左边是指针的时候使用，而.调用的方式左边只能是实体。 Entity_virtual e1 = new Entity_virtual(); std::coutGetName() 基本的定义和使用方式： 用*定义一个指针类型（用来存放地址）= &var（用该符号取出后接变量存储所在的内存地址）var 然后我们可以在Debug Stage从windows的memory找到该变量在内存中的值。 实际上也可以用type* name = Value，这样的话name还是指的是value所在的地址。但是这种时候type就需要写好了。 在指针类型变量前加表示我们*访问该地址所存储的Var，我们可以对该var进行读取写入或者修改，但是在这个时候，我们写入的值就和之前所提到的类型有关了（指针本身是无关的） 因为类型会告诉内存，我们写入的数据要在内存中占用多少个字节，多少位之类的信息，而如果我们使用void，那当我们给该指针取到的数据赋值的时候，compiler就不知道怎么存储该数据，也就会导致error。 也可以用**定义指针的指针，也就是指针所在的内存空间的地址 BTW:从内存窗口看到的地址是逆序的 可以将指针定义为nullptr，后续再赋值，而引用必须马上引用一个已经存在的变量，他不是一个新的变量。 在同一行里定义多个指针变量的时候要在每一个前面+*千万别忘了 注意事项： ++之类的运算符号的优先级> 取值，所以我们要*加入括号，使其首先解引用，防止改变的是地址的值而不是value。 “0”不是一个有效的内存地址 指针偏移值实际上取决于指针前面的type：如下图就是加入了两个int长度的地址。 int example[5]; int* ptr = example; for (int i=0; i 2.2.2. 引用基础（references） 用type& ref = var定义一个对var的引用，不需要其他的操作符 实际上ref就是一个别称，他不是实际存在的，只是var的另一种表达形式。 需要立即赋值。 具体的用途除了创建别名方便读写以外：主要用于需要修改原值的参数引用定义上。 function中通常情况下，是传值，而不是传递变量的地址。所以会有额外的内存拷贝的操作发生；所以通过function中的value产生的变化实际上是不会影响传入的变量的，这时候我们需要使用引用将变量传入，而不是值传入。（if we need this operation，也就是我们需要影响原值的时候）那么实现的方法有下面的三种。 要这么做的话实际上就是，我们将内存地址传入，然后通过地址取值进行操作，而不是只将这个值copy一下传进去也就是def fun(int* var); func(&var);当然这种方式也适用于直接传入指针， def fun(int* var); func(&var); 对1进行修正，更优雅的写法，简洁，就是使用reference，接受传入的是别名，也就是具体的变量，而不是值。 def func(type& value); func(var); 当然我们也可以通过return来改变原值，但是这样会需要temp value来影响内存效率之类的东西，也比较傻逼。 无法改变引用的对象。 再func前面类型定义为Type&,那么我们正常的return就是返回一个原值的引用。 2.2.3. 指针的->操作符(Arrow Operator ) →用来取代解引用后取值，就是用于指针直接调用参数或者函数，免去用*解引用的过程。 但是所有的操作符都可以重载，我们可以在自己的类别中定义他：比如当我们用一个Class 装载别的Class的指针的时候（比如我们为了让他能自己delete），如果我们希望能够直接指向最底层的那个Class 的function的时候。 // ScopedPtr存放另一个class（Entity）的指针，和构造析构函数。 // 重载使得直接调用底层类别中的函数。 Entity* operator->() { return m_obj; } ScopedPtr entity = new Entity(); entity->Print(); 获取类中参数的内存偏移量（可能是特殊的用法把，和第一点最基础的代码完全不一样）： struct Vector3 { float x,y,z; } int main() { int offset = (int)&((Vector3*)nullptr)->x; std::count 2.2.4. 函数指针（Function Pointer） 主要目的就是：获取函数所在的内存空间的地址； https://zh.cppreference.com/w/cpp/language/pointer 函数指针的补充资料：link1，Link2，还需要通过编程来加深理解 实际上应该还有其他类型的表达； 定义和使用 记住这里1不加括号（有参数输入的时候才加入括号），这就等同于在HW卡面+& auto function = HelloWorld; //记住这里不加括号（有参数输入的时候才加入括号），这就等同于在HW卡面+& 下面这种定义方式便于我们理解： //等于下面这种方式 void(*cherno)() = HelloWorld; cherno(); // 调用函数。 // 通过4-5的参数对比，我们可以知道cherno就是一个函数的别名。 // 这种方式其实更规范的可以写成 :这里添加了参数的输入所以比较不一样 typedef void(*HelloWorldFunction)(int); HelloWorldFunction function = HelloWorld; function(8) 函数指针的使用场景： 主要用于把function传入function，和lambda匿名函数好像有比较好的结合 void PrintValue(int value) { //Print cout } void ForEach(const std::vector& values, void(*func)(int)) { for (int value : values) func(value); } int main() { std::vector values = {1,2,3,4,5}; ForEach(values, PrintValue); } 2.2.5. 智能指针（Smart Pointer） 非常重要，能用智能指针的情况下我们就不用传统的指针 作用域:{} 参考资料1；参考资料2 唯一指针，能够自动的在作用域外就进行销毁（最基本的智能指针） #include // 下面这个是错误的，给个范例 std::unique_ptr entity = new Entity(); // 这个是错误的！！！！！！！ //只能显式调用构造函数：正确↓ std::unique_ptr entity(new Entity()); //另一种 写法：推荐写法：最好就这么写 std::unique_ptr entity = std::make_unique(); 共享指针，另一种智能指针， 使用reference_count来进行引用指针的计数，对象的所有引用消除了以后（count=0），才进行销毁（delete） 主要功能： 管理动态创建的对象的销毁。它的基本原理就是记录对象被引用的次数，当引用次数为 0 的时候，也就是最后一个指向某对象的共享指针析构的时候，共享指针的析构函数就把指向的内存区域释放掉。就是一个对象可以有多个引用。 std::share_ptr sharedEntity = std::make_shared(); 弱指针weak_ptr: 是一种弱化的共享指针，不会进行reference count https://blog.csdn.net/albertsh/article/details/82286999 它不会等到全部的指针都被销毁了才销毁，它会在指针销毁的时候就对对象进行析构，所以可能会有部分指针指向没有分配值的地址。 总结一下：重要！！！ 所以只是当我们需要在一个heap上声明的对象，但是希望能在作用域外自动销毁的时候我们才应该使用智能指针。 也就是智能指针分配的数据空间是在heap上的，但是存储指针自身的空间是在stack上的 先思考使用unique point 在需要不同的地方共享的时候在考虑share pointer 避免使用new delete 实际上智智能指针就是对原生指针的一个高层封装，就是类似struct ，在struct 的destructor 调用指针指向地址的delete？ 看看视频中的代码。 2.3. Part 4 Class & Struct 面向对象 This Chapter 主要就是面向对象的编程逻辑，以及类和结构体中的一些知识点 面向对象编程：这是一种非常流行的编程思想，这是一种编码的风格。 jave所有的一切都应该是一个class. 2.3.1. 类（Class） Class：和python是一样的，是一种将数据和function（method）组织在一起的一种方式。 和namespace的区别是啥：namespace没有访问控制。 一些基础用法和信息 比如玩家的属性，和玩家的一些function，就可以使用class的instance来定义多个角色，而不必重复的定义类似的方法和属性值。 类中的function就被称为method 可以使用大括号的方式来初始化赋值 struct Vector2 { float x,y; }; int main() { Vector2 a = {2,3}; } 实际上可以在类内declaration函数，然后再类外用::namespace的方式进行定义 当我们想要将Class or Struct传入Function中的时候，我们最好是使用reference &和Const，这样可以防止传入的类之类的被修改，同时也节省了memory，不需要额外的生成一个copy。 建立一个Logging类：将warning Or Error 打印在控制台上，因为控制台永远不会出问题，对于debug很有帮助。 继承所有在Entity中不是private的都会被player继承。 访问控制（Visibility） public：可以在类外访问，也就是可以在类的外部随便定义，取出，或者修改。 private：只能通过类内的操作或者类内的函数，以及friends进行修改调用。 protect：类内或者继承类 friend的定义方式：在类内的public使用前置friend 去重载这个函数或者类别即可。就能访问私有变量了。 类的构造函数和析构函数 C++ 类构造函数 & 析构函数 | 菜鸟教程 (runoob.com) constructors**：构造函数（可重载）** 用于每个instance生成时候的初始化，我们可以通过不同的传入值来重载这个函数。 名称和类名一致，不需要type。 默认是存在constructor的（但是不初始化变量），如果我们不希望用户构建实例，我们可以将constructor写在private中，那么就无法使用该类别去生成一个实例。 函数构造的初始化列表： 构造函数初始化列表以一个冒号开始，接着是以逗号分隔的数据成员列表，每个数据成员后面跟一个放在括号中的初始化式。 但是这种方式，需要我们按照成员函数的顺序去编写，他是默认这样执行的。 类构造函数初始化列表。 这样假如我们成员中有类别实体，我们可以避免该类别实体进行重复的构造，浪费了性能。（可以用cout测试） 此外这样也可以分离初始化参数和一些其他的初始化指令操作（写在大括号里）。 Destructor**：析构函数** 用于destory我们生成的object或者说instance；清除变量。 在构造函数前面加~就是定义的方式。一般不需要显式编程 活到生命周期末尾（大括号之类的）会自动调用 如果New 就需要Delete才会调用 类的继承 继承的主要作用，是让我们拒绝duplicated，拒绝代码重复。所以我们就能在父类中放置通用功能，然后在子类中重载或者编写新功能。 在子类的定义的时候：[public] 父类，父类2 如果函数的输入是（父类* a），那么所有的子类都可以输入来着 ：实际上是多态的因素，就是所有的子类都属于父类把，所以父类的指针可以代表所有的子类。 虚函数Virtual Function 在父类中编写的virtual function就能在子类中选择覆盖重载 Virtual function可以避免在特殊情况下，我们在子类覆盖定义了父类函数的情况下，还是调用了夫类中的同名函数的情况：它加入了动态分配的机制，通过存档虚函数 所代表的各种虚函数映射情况，便于我们找到正确的函数。 实际上也就是在需要重载（override）函数前面加入一个virtual的关键字（在最前面）；同时可以在覆写（override）的地方加上override关键字（在声明的最后面，大括号的前面），但是这不是必须的，但是更具备可读性。 但是需要额外的内存空间：需要表需要基类指向虚函数表的指针； 需要额外的运行速度：因为每次调用虚函数，需要额外遍历虚函数； 一般情况损耗不会太大，除非对于嵌入式设备来说。 Virtual Destructors 和virtual一样，为了我们在使用子类进行多态操作的时候，不会发生没有调用destructor导致内存泄漏的情况。所以就要再析构函数的时候virtual一下。 Interface（PureVirtualFunction）纯虚函数 纯虚函数也可以理解为接口，就是需要后续被实现的一些 实际纯虚函数就是一种在基类中没有实现的函数：在Jave和C#这类语言中就被称作接口，也就是我们需要在子类中一定要重写的函数。（有时候我们需要每个子类都定义特殊的函数，基类的定义顶多就当作模板，不包含实现方法） 在基类中对虚函数的实现（{}）改成（=0；），就是纯虚函数了，如果我们想要使得子类能够实例化对象，我们就必须在子类中override这个纯虚函数。这种时候基类也不能被实例化了。 如果父类对祖父类的override了，那么我们可以直接继承父类就不用再覆写了。BTW：纯虚函数（和成员变量）组成的也叫做抽象类 类的多态 多态 https://www.runoob.com/cplusplus/cpp-polymorphism.html 其实就是用base的指针来指向子类的一种调用方式 2.3.2. “This” 指针 this是指指向当前对象的指针，索引到当前的instance； 用来调用当前类中的函数或者变量 class Entity { public: int x,y; Entity(int x, int y) { this.x = x; } }; 2.3.3. 复制构造函数以及浅拷贝深拷贝 基本概念 通常对Class进行复制或者等号赋值操作的时候，很多情况下会发生内存拷贝，这样会使用新的内存地址去存储新的相同数据，也就是建立一个副本，但是很多情况下是不需要的。（用等号的时候都是进行的copy） 这种方式就是建立副本： Vector2 a = {2,3}; Vector2 b = a; b.x = 5; //不改变a 可以使用指针建立指针的副本，数据空间不进行拷贝； Vector2* a = new Vector2(); Vector2* b = a; b->x 浅拷贝：以自定义的String为例 c++已经实现了，这就是个范例； memcpy是内存赋值（赋值内存块）：在这里就是取代for loop 去copy value class String { private: char* m_buffer; unsigned int m_size; public: String(const char* string) { m_size = strlen(string); m_buffer = new char[m_size + 1]; //假设包含终止符的情况，但是这样就会对于非普通string的类别不太安全（它们可能不包括终止符） memcpy(m_buffer, string, m_size); } friend std::ostream& operator 基于终止符的不同情况，我们可以修改成： memcpy(m_buffer, string, m_size); m_buffer[m_size] = 0; 但是实际上这样可能会发生内存泄漏，所以实际上我们不应该忘记析构函数： ~String() { delete[] m_buffer; } 但是如果我们在这种情况下定义的string进行复制的时候，我们会发现，我们实际上是对类中所有的value进行copy，所以我们实际上拷贝了一个指针，然后再最终程序结束的时候，我们对同一个地址调用了两次析构函数，于是程序崩溃了。这就是浅拷贝。 深拷贝：以自定义的String为例 我们想要的就是有一个指向新地址的新指针，然后指向的地址有一样的value。 于是复制构造函数就被需要了，就是实际上我们是重新调用了一次前面的构造函数，去构造了一个完全相同的变量，而不是只是浅拷贝。 C++实际上已经存在了一个默认了：我们可以直接声明，但是这实际上是浅拷贝，也就是默认的方式 String(const String& other); //这个实际上是浅拷贝 == 下面的 String(const String& other) :m_buffer(other.m_buffer), m_size(other.m_size) {} or if you want to be more exciting... // 也等同于下面这个，都是浅拷贝 String(const String& other) { memcpy(this, &other, sizeof(String)); } 那么如果我们想要完全禁用浅拷贝：我们可以在声明后面加上=delete 实际上就是通过构造函数的类型隐式转换（就是那个等号的重载来实现的），所以我们要弄一个深拷贝的话： String(const String& other) :m_size(other.m_size) { m_buffer = new char[m_size+1] memcpy(m_buffer, other.m_buffer, m_size+1); } 2.3.4. 单例（singleton） 单例模式(Singleton)及其C++实现_FBeetle的博客-CSDN博客 单例是面向对象里面的一种编程模式，也就是某些类别只有一个例子：比如班主任，一个班只需要一个班主任。 或者我们只是要提供一个通用的方法库这种情况下，可以使用这种编程模式。 这就是一种编程方法，我们把东西都放到类中。然后使用类变量来调用global set of function 或者data.我们不需要进行实例化或者其他的操作、 换句话说，我们就是把class 像namespace这样来用。 Singleton 就是组织大量全局变量和static function的方法，将这些组合成一个blob。 阻止实例化 可以通过把构造函数设置为私有来阻止实例化操作，但是还是会存在缺陷，还是可以通过下面的操作来类似的实例化； Singleton instance = Singleton::Get(); 但是这样的话会把我们singleton的数据都复制一次（每执行一次复制一次），所以我们需要去除复制构造函数来防止这种操作的实现。这样的话，我们最多就是使用&来使用一个别名进行这个singleton的调用（在上面那个定义加入& ->Singleton&） public: Singleton(const Singleton&) = delete; 标准的单例调用模式存在一定的麻烦（代码块1），如果我们希望去掉Get来优化调用的过程：可以在定义的时候修改成（代码块2） Random::Get().Float(); // 先获得单例，然后调用函数 // 或者使用下面的方式 auto& random = Random::Get(); float number = random.Float(); public: static float Float() {return Get().IFloat();} private: float IFloat() {return m_RandomGenerator;} 单例通常使用::在外面定义，就像下面大图的nullptr 但是如果我们不希望这样（不希望自己在外面进行一个初始化）我们可以写成（写在get里，那么初次调用的时候会生成类static的singleton）（这也是结合了后面修正的最终版）（分析一下这些static）第一次生成，后面全是singleton引用。 class Singleton_origin { private: // 构建一个通用的单例指针 static Singleton_origin* s_Instance; public: // 通过Get返回指针所指向的singleton对象 static Singleton_origin& Get() { return *s_Instance; } // 每个Singleton_origin class 的实例中的通用Function void hello() { } }; Singleton_origin* Singleton_origin::s_Instance = nullptr; // TYPE2: 实际构建一个singleton怎么去做 // 这一步还没有对复制的情况以及调用的麻烦的情况进行优化，结合下面的最终版。 class Singleton { public: static Singleton& Get() { // 这个静态的instance只会在初次调用这个GET的时候生成，后续的话就是直接return他了。所以这样写就行 // 需要注意的是，由于我们返回的类型设定为reference（&），所以如果我们去掉的了↓的static关键词，就会出错 // 因为reference返回的是别名，也就是需要这个值一直存在，不然在后续的使用中会出现问题，而不是返回一个copy，当然也可以去掉函数中的&。 // 所以我们需要借助static 关键词，来延长这个instance的声明周期，才会被正确的使用。 // 这种只有第一次起到作用的方法，就适用于很多需要初始化的场景。 static Singleton instance; return instance; } void hello() {} }; int main() { //Singleton_origin::Get().hello(); Singleton::Get().hello(); std::cin.get(); } 最终版 集成了上面的全部优点，简化了调用，不会进行复制，不需要在类外进行单例的初始化。 public: Random(const Random&) =delete; static Random& Get() { static Random instance; return instance; } static float Float() {return Get().IFloat();} private: float IFloat() {return m_RandomGenerator;} Random(){} float m_RandomGenerator = o.5f 2.3.5. 结构体（Structure） 实际上就是一个默认是Public的Class，Class是反过来的。 什么时候该用结构体什么时候该用类？ 默认情况下：class是私有的，类或属性（需要共有的时候要public）；而Struct是默认公有的（需要私有的时候要用private）； 这是唯一的区别，但是在代码实际使用的时候还是有所不同的：存在的原因 保持和c之间的兼容性 或者我们想要全都用public的时候。 自定义使用场景（规定编程风格） Plain old data（pod）的时候喜欢更多的用struct，就是仅仅只代表一堆变量的时候。比如说定义向量，这中类似的数据体的时候 “我将永远不会对struct使用继承” 2.3.6. 公用体（Unions） 是一种类似Struct的结构，但是同时只能存在一个member（变量），无论你声明了多少个，实际上都是共享内存空间（地址）的，所以如果我们declaration的Type不同，就可能会出现Type Punning的现象，实际上也可以理解为一个变量的多个别名？ 菜鸟教程，CPP reference 但是通常匿名使用，也就是只使用其只能有一个member的特性，很多时候会放置再Struct 之类的里面。和Struct一起匿名使用是不影响我们的调用层级结构的 存储空间的大小以最大的成员作为标准好像 struct Vet2 { float x,y; }; struct Vet4 { union { struct { float x,y,z,w; }; struct { Vet2 a,b; }; }; }; // 这样的话 Vet4 v = {1.0f,2.0f,3.0f,4.0f}; //v.x 实际上和 v.a.x 是一样的,他们共享了一样的内存地址，这个和type punning有点像。 2.3.7. 结构体绑定（Structured binding） 这一部分实际上解决的是，我们使用struct的方式来实现多类回归的情况：linkto),所以参考那一部分就好了 2.4. Part 5 WorkFlow&逻辑控制 This Part 介绍一些算法的逻辑控制以及workflow控制，包括循环，条件，函数，线程之类的，控制工作流的内容。 2.4.1. Func： 基本的函数定义（Functions） 其实没啥特别好说的就是： 一般在header 中写入declaration，然后把definition写在Cpp files里面。 其实定义的全局变量在function中也是可以直接调用的，不需要重新导入之类的。这个应该都是懂的吧 :star: Always pass you object by const reference!总是使用const和reference传入我们的参数。 需要副本就复制. 2.4.2. Func： 匿名函数（Lambdas） 参考资料：lambda详细教程，捕获值理解 匿名函数实际上是用于基本上一次性的函数：我们不需要真正的（实际的）对函数进行定义。 基本定义方式：[capture](传入参数){实现内容} auto lambda = [](int value){std::cout 需要传入外部数据的时候就需要使用Capture，比如main中的值，用&or =；如果我们要使用Capture的时候，我们可能要#include Question: lambda的传入的参数默认是不能修改的，要修改的话我们需要加入mutable关键词（在传入参数和实现内容之间） 其他的lambda实例： std::vectorvalues = {1,5,4,2,3}; std::find_if(values.begin(), values.end(), [](int value){return value>3;}); // it actually is&#x1F447; 返回第一个>3的值 auto it = std::find_if(values.begin(), values.end(), [](int value){return value>3;}); std::cout 2.4.3. Func：三元运算符（Ternary Operator） 条件表达式？表达式1：表达式2 这种形式实际上和python中的如下的表达式一致 Flag = True a = 5 if Flag else 10 c++中表示为如下 s_Speed = s_Level > 5? 10: 5; s_Speed = s_Level > 5? s_Level >10? 15: 10: 5; 2.4.4. Func: 多值输出 (Multiple Return) include新报本的结构体绑定方式。 由于C++本身的Type机制，我们没办法在func中同时直接return不同类型。 而如果我们试图return同一type的多个value的话，我们实际上可以用returnvector或者array的方式实现，当然这就是一种比较蠢的操作了。 stdarray或者传统的array 好像也可以使用tuple的方式{v1,v2}同个类型的多个值 推荐：当然聪明一点的方法就是，我们定义一个struct，包含我们需要的这些所有type，然后return这个struct就好了 还有一种方法就是使用&来传递参数，就不需要return了，设置为void就可以了 也可以用指针的方式，指针方式的好处就是可以是空值 C++的默认指定方式：tuple和pair 用tuple类型的方式操作起来有点麻烦啊如下，但是也可以混杂多种类型输出。 #import static std::tuple func() { //return std::make_pair(var1,var2); //上面的type指定有时候也能省略 //或者使用下面这种方式,上面那种实际上是pair类型的返回把 return {var1,var2} } auto [name, age] = func(); // c++ 标准更新以后tuple的使用方法变得更加的好用了。 ------------------&#x1F446;NEW Version & Called Structure Binding---------------- --------------------------------&#x1F447;OLD VERSION a = func(); ////或者 //auto a = func(); ////oldversion要取出元素的时候我们还需要 //std::string& name=std::get(a); //这里可以用&防止动态的内存copy的情况 //std::get(a); ////所以这边建议使用struct //// 取出元素的第二种方法. //std::string name; //int age; //std::tie(name,age) = func(); 2.4.5. Threads：线程操作 函数编写过程中的多线程操作和线程管理，下面是一个典型的例子，我们好像也可以使用进程去建立一个线程对象。 使用线程主要的目的是为了1. 完成单线程没法完成的事情以及2. 优化一些算法的运行速度。 #include #include //支撑线程的基准库 static bool Flag = true; // 编写一个函数用于子进程的执行，通常使用函数指针的方式调用 void DoWork() { while (true) { std::cout 如果我们再调用某个进程的时候想看当前的ID，也可以再运行的函数中加入STD::this_thread::get_id()得到当前进程的ID。当然我们每次运行可能都是不一样的。 2.4.6. Threads：多线程管理 这一部分没有英文字幕，缺失了很多信息，后续使用到的时候进行补充和修正把。 线程并行；异步；等等的多线程管理。std::async 对于independent的Application和Function Part，实际上很多操作我们可以在cpu和memory上并行进行，对不相关的任务进行分布（异步），对相关的任务有所约束（同步），合理的对进程进行调度，能够使得我们对资源有更充分的利用，同时也能提升程序的运行速度。 对于不依赖于运行次序的一些操作：比如载入很多模型或者数据（num_worker） cppref参考页面；异步合同的概念； #include static std::mutex s_meshesMutex; //解决1. 针对变量定义一个互斥锁 static void LoadMesh(std::vector>& meshes, std::string filepath) { auto mesh = Mesh::Load(filepath); //解决1. 使用lock，锁住我们可能需要修改的这个变量，使得一个thread在进行修改的时候，&#x1F512;（其余不能对该变量进行操作），修改完成解锁&#x1F511;； std::Lock_guard(std::mutex) lock(s_meshexMutex) meshes.push_back(mesh); } for (const auto& file : filelist) { //1. 异步使用文件载入，但是这样会出现问题，就是当我们两个进程同时进行修改操作的时候怎么办？ m_Futures.push_back(std::async(std::lauch::async,LoadMesh,m_Meshes,filelist)); } 为了防止同时的写入操作，我们还需要Lock操作去锁住可能会修改的变量。同时好像异步程序的返回值比较特殊，所以我们需要在头文件中进行如下定义： std::vector> m_Future; 此外我们可以控制是否执行异步程序（老办法了） #define ASYNC 1 #if ASYNC ASYNCfunc() #else func() #endif 最后我们可以在debug的时候 windows ，parallel stacks找到进程表（很吊）。好像也可以在执行代码的地方跳到正在执行的某个进程 2.4.7. Benchmark：基准测试 在运行程序的时候如何监控我们该代码的性能（运行时间等等），或者测试新方法的方式。这里给出了他的方式。实际上有很多不同的方式。 _debugbreak(): 类似python中的raise exception // 简单的范例， int main() { int v = 0; { Timer timer1; func() } ...; _debugbreak(); } 我们要确信的一点是，计时器是否真正的测量了运行的时间，因为有时候编译器会直接进行中间态计算，所以实际运行的时候，就会没有计算到开销。 测量share pointer和unique pointer unique>make share >new share Visual Benchmarking （可视化） 使用chrome:://tracing 在浏览器中进行可视化,这一课作为补充资料把。暂时不需要用这种方式 2.4.8. Switch：case 分支 一个 switch 语句允许测试一个变量等于多个值时的情况。每个值称为一个 case，且被测试的变量会对每个 switch case 进行检查。 switch(expression){ case constant-expression : statement(s); break; // 可选的 case constant-expression : statement(s); break; // 可选的 // 您可以有任意数量的 case 语句 default : // 可选的 statement(s); } 2.4.9. Workflow：Conditions and Branches 条件和分支 if 指令实际上是检查值是否为0，0 == False， !0 ==True; Keyword：if; else if; else; 2.4.10. Loops: For and While 循环定义 For 循环其实就是 （声明变量；condition；迭代规则） 我们可以直接在括号里写，也可以全部写在外面 condition要声明，但是可以在外面定义 While （condition） Do { }While（condition） 即使条件为false也至少能执行一次 2.4.11. Workflow: Control Flow (contiune, break , return) 循环控制 这几个关键词的使用和含义基本是和Python一致的，但是这里的Break还用于switch 2.4.12. Workflow： Iterators迭代器 迭代器的一些基本的参数：first（key），（当然这个是以这种形式存在的是时候才有的）second（value）；it本身是以指针形式存在的？ 是一种对dataset中的数据进行迭代的方式，这就是一种迭代器，有点像是运算符重载，通常用于对数据结构进行迭代（遍历）。 //最常见的方式就不再说了，。vector.size()来循环就行了 #include // type1 内置的迭代器，也是常用的使用方式。 std::vector values = {1,2,3,4,5}; for (int value : values) std::cout::iterator it = values.begin(); it != values.end(); it++){ std::cout 那么我们如何对于无序的数集(实际上unorder_map是Hash的C++实现)来进行迭代或者遍历呢？，看下面这个例子： #include using ScoreMap = std::unordered_map; //std::unordered_map map; ScoreMap map; map[\"aiken\"] = 5; map[\"c++\"] = 2; // 由于无序图没有index，经典的就是使用这样的方式 for (ScoreMap::const_iterator it = map.begin(); it != map.end(); it++) { auto& key = it->first; auto& value = it->second; //second 应该指的是value把，但是对于多元素的hash怎么处理？ PRINT_FUC HERE. } // 仿照上面那种更方便的方式来编写迭代的话(这里的auto 实际上是pair的形式) for (auto kv : map) { auto& key = kv->first; auto& value = kv->second; PRINT_FUC HERE. } // 当然还有一种梦寐以求的方式，后续可能我们会最常用的方式 for (auto [key, value] : map) { std::cout 编写我们自己Structure中的Iterator： 假设：这是不是应该使用类似linklist之类的方式，将数据通过类似指针的方式迭代的串起来？ 这一部分太长了，还是参考视频94把，我就直接重载[]和size通过for去做迭代器了，建议加入相关的.cpp，不要集成在文档中。 这一部分其实可以帮助对一些重载，还有一些vector机制有一个更好的理解，以及一些动态的内存管理，可以自己在后续编写一下试试。 2.4.13. Workflow: Continuous Integration CI （持续集成） 每次commit后都build 以及run &test就是CI吗？ “持续集成是一种软件开发实践，即团队开发成员经常集成他们的工作，通常每个成员每天至少集成一次，也就意味着每天可能会发生多次集成。每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误。” 使用：jenkins（第86课） 2.4.14. Workflow: Static Analysis(静态代码分析) 也就是一些分析工具，比如pylint之类的东西； Cherno推荐：PVS-Studio 2.5. Part 6 Memory 资源管理 This Section 我们从memory出发来谈及关于Stack，Heap之类的内存管理和优化方法,以及编写的safe。 粗略：Heap和Stack的区别；进阶1：C++中内存分配，堆（Heap）与栈（Stack）区别 为什么c++中要分为heap（堆）和stack（栈） 2.5.1. Stack vs Heap: C++中的内存栈与堆 char* buffer = new char[8] 定义一个8个字节的内存空间，并返回指向内存开始的地址的指针 基本概念：stack和heap都是内存（RAM）中实际存在的单元 stack存在预定义的长度: 2M左右。 heap虽然已有预设的默认值，但会随着我们的Application去更改大小 目的都是为我们的程序和全局或者局部变量提供存储空间。 不同的内存分配方式。 memset可以用来填充内存块 memcpy 内存拷贝，拷贝内存块 基本定义方式：前面一般是定义在stack上的，后半部分是定义在heap上的 int main() { int value = 5; int array[5]; ClassA vector; int* hvalue = new int; *havalue = 5; int* harray = new int[5]; ClassA* hvector = new ClassA(); } 分配方式上的区别（主要是new） stack上分配的内存空间是连续的，实际上就是栈顶的指针移动需要的距离，然后重新赋予数值。每一个在另一个上面。 所以这样分配会比较快，我们只需要在寄存器上移动指针的地址就可以了 {}实际上就是一个stack，超出这个作用域后，栈内的数据会自动销毁，也就是实际上就是将指针还原到了作用域开始的地方。Free操作实际上只是指针的移动。 heap上分配的内存空间是随机的。 实际上会call malloc，给你一个指定大小的内存块，同时也会管理一个需要free-list的内存列表（也就是已经申请了的列表）， 所以在heap上分配空间实际上是一整套任务，而在stack上实际上就是指针移动，他们两个的效率是完全不一样的。但是有各自面对的状况吧。 需要大量数据，或者说是，需要延长生存周期的话都需要用heap。 在debug model中的汇编之类的机器代码是没有经过精简的，但是release后vs会自己优化。 2.5.2. New：Keyword For Mem内存关键词 使用new实际上是一系列命令（运算符重载），包括在空闲的内存块中占用一块指定大小的内存，所以会需要时间； 基本准则：有new有Delete；无new 无delete new经常和数组一起使用来获得指定大小的heap空间 new在使用的时候也会调用constructor（构造函数），相应的delete； new ->delete; new [] -> delete []; int* b = new int [50]; Entity* e = new Entity[50]; //这种情况下同时会调用构造函数 //虽然我们可以用malloc指令定义，但是这种方式不会调用析构函数，所以千万不要用这种方法。 具体的底层原因： new底层其实是call了malloc，malloc是memory allocation的简写，从名字也可以知道它负责分配内存，delete则调用了free()。区别是new和delete不仅管理内存，还会调用constructor和destructor，另外它们都是operator，所以你可以重载它们，做一些有趣的事情。 对了，new【】和delete【】其实另两个operator，它们做的事情稍微有点不一样，你调用new【】的时候，必须要指定一个size，但调用delete【】的时候，并没有指定size，它怎么知道delete多少呢？这是因为new【】不仅分配了所需要的内存，还会多分配一个额外的空间，来存储这个size，所以以视频中的举例，它所做的是分配这样一块内存【8, 0, 0, 0, 0, 0, 0, 0, 0】，连续的，但是多一块在最前面，但是return给你的是跳过那块内存的地址，比如malloc返回的是0x1，但new【】给你返回的是0x1+2（我记得它分配的是一个word（一般是short）的大小，具体大小需要看系统），然后在delete【】的时候，它会往前推一个word，因为它知道前面一个word肯定是size，从而拿到size，进而delete所有） 什么时候通过New来定义实体（instance） 就是如果我们希望在一个Function中定义类的实体的时候，为了延长生命周期，我们需要将实体定义在heap上 或者是class 规模太大，但是stack太小了，所以我们要借助heap的存储空间 Entity* entity = new Entity(\"Cherno\"); 2.5.3. Safety：使用智能指针的情景 什么样的程序是safe的？减少崩溃和内存泄漏的情况，也就是让Code尽量不要越过需要的边界。This Part is about Smart Pointer。 实际上安全性和内存分配是分不开的。 对自己所有allocated的memory负责，所以智能指针特别屌，应该100%使用智能指针，不要仅仅使用原生指针（Raw Poniter），能不用就尽量不用。智能指针我们就不需要担心delete或者内存泄漏等等的问题了。 Raw Poniter在我们使用的小规模程序的时候偷懒，因为只要使用※，他不安全，就只是好读和简单。 所以就是，使用smart pointer，当然在确保安全的情况下，我们也可以用raw pointer自由选择反正。优点和缺点就是这样了。 2.5.4. Track Memory Allocation：内存申请跟踪 优化跟踪内存管理对于计算机的性能来说相当重要，特别是我们要知道我们在哪里分配了数据。 虽然heap的space比较大，但是在性能至上的环境中，可能heap不会是一个最佳的选择。 智能指针会在heap上分配内存，（std::string都是分配在内存中的） Easy Way： 这一部分能够简单的嵌入我们的任何project；(void* 存储的就是一个内存地址) 基本思路：重载我们的new 操作符; import void* operator new(size_t size) { std::cout 那么当然我们也可以重载delete去检测内存的释放情况 void operator delete(void* memory, size_t size) { std::cout 那么最方便的实现方法就是我们使用一个struct来统一管理我们的内存分配情况。 struct AllocationMetrics { uint32_t TotalAllocated = 0; uint32_t TotalFreed = 0; uint32_t CurrentUsage(){return TotalAllocated-TotalFreed;} } //实例化全局架构 static AllocationMetrics s_AllocationMetrics; // 然后将上面的new和delete中的print改成+= 和-= static void PrintUsage() { std::cout 2.6. Part 7 How to make C++ run Faster 算法或者进程优化的部分，这一部分在做题的时候慢慢的进行填充把，在学习的时候先选择性的看看，实际上应该是Part6的延申，逃不脱资源管理的部分、 TODO：（已知可以但是应该暂时没用） std::async （应该是用于进程优化） 79课 80 83：string优化 2.6.1. run string faster 优化string的运行速度 string会在heap上allocated，所以对于性能优先的情况下不是特别推荐的,可以通过下面的方式查看heap申请。 void PrintName(const std::string& name){} // 想要看空间的声明，重载new就对了，看Part6 static uint32_t s_AllocCount = 0; void* operator new(size_t size) { s_AllocCount ++; PrintHere; return malloc(size) } PrintName(const std::string& name){} int main() { name = \"aiken\"; Print(name); //copy一次 std::string name = \"aiken aiken\"; //copy std::string firstname = name.substr(0,3); //copy std::string lastname = name.substr(4,9); //copy } 但是加入我们只是想要一个很简单的输出“”，不希望发生再次的construct，来增加一个string的heap空间。甚至我们使用substr()来输出其中的一部分，也会copy（allocation）一次原本的string。 避免这样无意义的Copy，只是要一个指向原数据内存地址的指针，以及size把，我们可以很容易写一个这样的类，但是在C++17中官方集成了把&#x1F447; PrintName(std::string_view name){} //这样以后print（“”）也不会分配了，原本的情况，执行print甚至都会复制一份。究极不合适 std::string name = \"aiken aiken\"; //allocation only //3可以修改成5 就没有allocation了,但是5的话 6，7的c_str()要去掉 const char* name = \"aiken aiken\"; //not allocation std::string_view firstName(name.c_str(),3); std::string_view lastName(name.c_str()+4,9); print(firstName); //这种类型也不会再发生复制了 print(LastName); print(\"aiken aiken\"); ----------------------------------整理如下-------------------------------------- //只在定义的时候发生一次赋值。 printname(std::string_view name){} std::string name = \"aikenaiken\"; //allow 1(copy happen) std::string_view firstName(name.c_str(),3); std::string_view lastName(name.c_str()+4,9); print(firstName); //这种类型也不会再发生复制了 print(LastName); print(\"aiken aiken\"); 2.7. Somthing Else 无题 畅所欲言，或者等待归类。 sizeof通常用来获取数据的存储空间； strlen():获取const char*的长度 alloca(size)：再当前地址内存分配；所以我们可以类型转换指针（int*） size_t:可以存储各种类型大小的值,size type constexprhttps://www.jianshu.com/p/34a2a79ea947 \\:编写代码的时候的换行续接符号 wandbox.org ：在线编译网站 Visual Studio 表达式的编译顺序是从右到左运算 2.7.1. Argument Evaluation Order 参数输入顺序（面试？） 传入参数实际上可以是传入一个函数或者是一个表达式，我们应该规划一下这样的输入。（和++相关） i ++ : 先传递在增长 ，++i：先增长在传递把 (undefine behavior: 意味着这种方式实际上没有被定义，也就是说是一种不可控的行为，下面是一种实例)（切换这种++的位置也是） void Psum(int a, int b) { std::cout 正确答案是这种实际上是C++没有规范的，我们没法得到真实的值，但是再C++17中要求： The Postfix-Expression is Sequenced before each expression in the expression-list and any default argument。 也就是他们需要被一个接着一个的运行。这个其实没有太听清。 https://blog.csdn.net/samantha_wang/article/details/46942343 https://blog.51cto.com/8681495/1416759 也不要写像这种的 v[i] = ++i; © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Langs/Markdown.html":{"url":"Langs/Markdown.html","title":"L1:Markdown","keywords":"","body":"1. Markdown Material1.1. Editor：1.2. Some daily usage：1.3. 希腊字母表：1. Markdown Material written by ==Aiken==, 2020this document is about Markdown’s Tips, in order to help me writing good notes. 参考资料： 一些关于markdown语法的参考资料，但是实际上如果用Typora的话，有很多的语法是不需要记忆的，只需要稍微了解就可以了，更需要学习的其实是Latex的公式编写。 基本语法：https://www.jianshu.com/p/191d1e21f7ed 进阶语法：https://blog.csdn.net/m0_37925202/article/details/80461714 其他语法：https://blog.csdn.net/cuishizun/article/details/80311673 目录： Editor 一些常用操作 希腊字母表 1.1. Editor： Typora：Notes的主力编写工具 VsCode：主要编写README等工程文档的时候使用 Jupyter：代码笔记编写的时候 1.2. Some daily usage： 操作名称 Typora VsCode 跳转 [button] (#name)-># [button] (#name)-> \\ 复选框 - [ ] - [ ] 1.3. 希腊字母表： 序号 希腊字母 Markdoown 序号 希腊字母 Markdoown 1 α \\alpha 19 β \\beta 2 γ \\gamma 20 δ \\delta 3 Γ \\Gamma 21 Δ \\Delta 4 ε \\varepsilon 22 ϵ \\epsilon 5 ζ \\zeta 23 η \\eta 6 Θ \\Theta 24 ι \\iota 7 θ \\theta 25 κ \\kappa 8 Λ \\Lambda 26 λ \\lambda 9 μ \\mu 27 ν \\nu 10 ξ \\xi 28 ο \\omicron 11 Π \\Pi 29 ρ \\rho 12 π \\pi 30 τ \\tau 13 Σ \\Sigma 31 Φ \\Phi 14 σ \\sigma 32 ϕ \\phi 15 Υ \\Upsilon 33 Ψ \\Psi 16 υ \\upsilon 34 ψ \\psi 17 Ω \\Omega 35 ω \\omega 18 φ \\varphi 36 Ξ \\Xi © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Langs/Latex.html":{"url":"Langs/Latex.html","title":"L2:Latex","keywords":"","body":"1. LATEX 中的公式1. LATEX 中的公式 参考资料 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 17:49:52 "},"Langs/Python.html":{"url":"Langs/Python.html","title":"L1:Python","keywords":"","body":"1. Python Notebook2. 数据模型（Python结构的通用范式）3. 变量赋值传递时的引用和拷贝4. 类与函数4.1. 匿名函数4.2. 单下划线4.3. Bool and or not4.4. Argparse4.5. Random5. Logging System5.1. 基础使用5.2. 进阶使用5.3. Logger与装饰器的组合使用6. FIles System6.1. Import manage6.1.1. init.py 文件的作用6.2. Path Manage6.2.1. 路径切分6.3. 文件遍历6.3.1. os.walk()6.3.2. Glob.glob()6.4. 文件读写7. Data Structural7.1. 位运算7.2. 二进制操作7.3. 序列构成的数组7.3.1. 列表推导式的使用7.3.2. 使用列表推导式生成笛卡尔积7.3.3. 生成器表达式7.3.4. 元组不仅是不可变的列表7.4. 列表的基本操作7.4.1. 列表的条件加和7.4.2. 列表的数乘7.4.3. range函数常用操作7.5. Universal Method7.5.1. Sort（）对列表进行排序7.6. 队列queue & deque7.7. SET集合7.7.1. 利用set进行去重7.8. Dict，Hashmap7.8.1. 判断字典中的key是否存在的方法7.8.2. 字典中的常用方法7.8.3. collections.defaultdict 指定dict中未定义key的value7.9. Vars（）7.10. Python中的数字日期时间计算7.10.1. 获取本机时间的几种方法7.10.2. 精确数字运算7.10.3. 数字的格式化输出8. 迭代器9. 元编程9.1. Some Rules9.2. 装饰器模块9.2.1. Basic Type9.2.2. 接受参数传递9.2.3. 修改装饰器参数9.2.4. 带可选参数的修饰器9.2.5. @property的用法10. Exception10.1. Python3 错误和异常10.2. 异常捕捉try except10.2.1. exception的多种写法和多异常分支10.3. 抛出异常 Raise Exception11. Numpy Tips11.1. reshape11.2. tolist11.3. 用array给list中的元素赋值11.4. flatten & flat operation11.5. Numpy.pad11.6. :: Numpy 索引中双冒号的实际用途11.7. Argpartition()11.8. Allclose()11.9. Clip()11.10. extract()11.11. where()12. DEBUG12.1. 避免重复/冲突的import12.2. 内存调用与Method的定义12.3. TypeError：1. Python Notebook Created by: Aiken H Detail: lang Finished?: No Tags: Code @Aiken 2021 you know what 主要参考文献：《Python Cookbook》 && 《Fluent Python 2. 数据模型（Python结构的通用范式） （Magic method）dunder method：Python特有的双下划线方法，这些方法能够支持Python进行特殊的调用，实现通用方法在新定义的数据结构上的使用，比如最典型的: __len__()后可以支持len()，获得结构的长度 __getitem__()后可以支持data[index]来获取相应的元素，切片，等等数组的操作； # 也可以支持类似如下的一些操作 # 从数据结构中随机选出一个items from random import choice choice(datas) # 也可以支持迭代方法和反迭代方法 for data in datas: ... for data in reversed(datas): ... # 也可以支持sort函数 到这里也就说明了，只要我们在数据结构（class）中定义了相应的dunder method，该class就能支持相应的一系列操作，getitems就可以类比为列表，相应的操作都能够在python解释器下自动的赋予支持。 还有一些好用但不常用的方法： __contain__实现的是in ，当没有实现contain的方法的时候会按照顺序在list中进行搜索 __abs__ __repr__实现的是输出的format设置，也就是print的时候的输出形式 __eq__ 实现的是 == 命令，同时in调用的是eq 下面附上一张特殊方法表： 基本命名规范 相关的文件和函数等命名规则。 命名样例表 3. 变量赋值传递时的引用和拷贝 Python 变量的传递类型：（赋值过程） https://www.runoob.com/w3cnote/python-variable-references-and-copies.html Python 赋值过程中不明确区分拷贝和引用，一般对静态变量的传递为拷贝，对动态变量的传递为引用。（注，对静态变量首次传递时也是引用，当需要修改静态变量时，因为静态变量不能改变，所以需要生成一个新的空间存储数据）。 • 字符串，数值，元组 均为静态变量 • 列表，字典为动态变量。 可以用id（）查看指向的地址 在修改列表值之类的时候要注意这一点，不然可能会影响到源列表，可能要使用深拷贝的方法， copy.deepcopy() 4. 类与函数 args，kwargs的用法和解包，主要将字典作为参数整体传入的这种方法值得学习 可以用*，**定义和解包 id()可以获取变量的地址，type（）查看数据类型，isinstance判断类型 locals().keys() 获得当前已经声明的变量列表 sys.argv[0] 可获取当前工作区的地址 4.1. 匿名函数 4.2. 单下划线 定义的函数，属性，或者方法 这表明这个member是受保护的： 是用来指定私有变量和方法的方式（只是一种约定习惯）,不希望被下游的程序员直接访问的函数。 如果使用from a_module import导入时，这部分变量和函数不会被导入 但是如果使用 import a_module这样导入模块，仍然可以用a_module._pythonPoint这样的形式访问到这样的对象。 4.3. Bool and or not 基本的就不用说了，主要是一些特殊的用法举例 # not 会先于 and 执行 if not flag1 and flag2 == True 用逻辑运算符做参数选择 judge = index == 0 and num1 or num2 4.4. Argparse 基本的用法：参考universal framework即可，主要是bool类型无法通过命令行传入 # 使用store_true属性，就可以执行默认的True or False parser.add_argument(\"--bool_chose\",default=False ,action='store_true',help='a switch of bool variable') # &#x1F447;选择上与原本完全是相反的 parser.add_argument(\"--bool_chose\",default=True ,action='store_true',help='a switch of bool variable') 4.5. Random 使用sample不重复的选取字典或者列表中的指定项 list = [1,2,3,4,5] choose = random.sample(list,2) 使用choice进行可重复的选取 c_r = np.arange(20) for i in range(10): c_i = random.choice(c_r) print(c_i) 打乱列表排序 A = [1,2,3,4,5,6] # 得到index的列表 B = np.arange(len(A)) # 对该列表进行打乱，通过打乱的列表进行索引 random.shuffle(B) print(B) 5. Logging System 日志 HOWTO — Python 3.9.4 文档；日志操作手册 — Python 3.9.4 文档 Python logging模块；logging模块的简单使用 5.1. 基础使用 从一个非常简单的例子开始，默认的命令行输出等级是warning import logging logging.debug('this message should only show up in log file') logging.info('so do this one ') logging.warning('this one will also show up in the console') logging.error('And non-ASCII stuff, too, like resund and Malm') 假如我们设置log文件的存储以及输出的格式（包括算法运行的时间） 但是注意这个config是一次性设置，只有第一次设置是有效的 logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s ', datefmt='%Y-%m-%d %I:%M:%S %p', filename=\"exampleFile.log\",level=logging.DEBUG) # 这里设置了文件的输出名称和输出的格式，以及相应的记录到文件中的等级 也可以从命令行设置日志等级,可以获取当前的等级 --log = INFO # getattr 这个方法目前好像还有点问题， 5.2. 进阶使用 通过4个module的组合来实现record log的功能，通过Logger载入多个Handler，可以通过不同的标准和方式在多个File以及控制台输出不同Level的东西，这就是主要的功能。 Untitled 具体的实现样例如下： import logging # create logger to record log messages logger = logging.getLogger('textlogger') logger.setLevel(logging.DEBUG) # create file handler which logs even debug messages fh = logging.FileHandler('exampleFile.log') fh.setLevel(logging.WARNING) # creatr console handler... ch = logging.StreamHandler() ch.setLevel(logging.DEBUG) # create output format for all the handler formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s ', datefmt='%Y-%m-%d %I:%M:%S %p') ch.setFormatter(formatter) fh.setFormatter(formatter) # add handler to logger logger.addHandler(ch) logger.addHandler(fh) # record logs logger.debug('this message should only show up in log file {}'.format('test is')) logger.info('so do this one ') logger.warning('this one will also show up in the console') logger.error('show up twice') 但是这种格式的时候怎么实现跨文件传输呢？ 再同个文件中我们只需要进行getlogger使用同一个名字即可获得同一个logger，但是跨文件的话可能还是需要传递logger把。 我认为应该传递该logger,然后通过该Logger进行统一的输出，遇到不同的输出要求的时候，我们可以对handler进行不一样的处理从而能够得到多样化的logger输出 5.3. Logger与装饰器的组合使用 参见后续的装饰器解读模块 6. FIles System 6.1. Import manage 6.1.1. init.py 文件的作用 init.py 文件使用 其实主要就是控制着包的导入功能，使用__all__来对应from package import *的功能，我们可以在init中批量的导入我们需要的模块，这样我们就不在需要一个个的进行导入了，基于这种特性，我们也可以编写一个manage fuction，通过config来进行选择性的导入。 主要的左右是python中package的标识，不能删除 定义__all__用来进行模糊导入 编写python代码，会在import package的时候同时import，但是推荐在包中创建另外的模块来写，尽量保证该文件简单 6.2. Path Manage 6.2.1. 路径切分 将路径切分成地址和文件： import os p,f = os.path.split(origin) print(\"path == \",p) print(\"file == \",f) 切分出文件的盘符和文件名 dev,left = os.path.splitdrive(origin) 切分出文件和拓展名 f,ext = os.path.splittext(origin) 6.3. 文件遍历 6.3.1. os.walk() 简单好用的目录遍历器用于在目录树中游走输出目录中的文件名，向上或者向下。 os.walk(top,topdown,onerror,followlinks) top：遍历的目录地址 （option）topdown：True的话优先遍历top目录，否则会优先遍历子目录 （option）onerror：当需要异常的时候，会调用 （option）followlinks：是否要跳转到快捷方式（或者软连接遍历） RETURN：（root，dirs，files） root：根目录 dirs：文件夹中所有目录的名字（子文件夹） files：目录中所有文件的名字 层序遍历每次是该层的所有文件和目录的名字 6.3.2. Glob.glob() 文件遍历方法 6.4. 文件读写 7. Data Structural 7.1. 位运算 位运算判断奇偶一致性 # T：奇偶性不一致 F：奇偶性一致 (a ^ b) & 1 7.2. 二进制操作 与或非就不用多说，主要是介绍一个module bitarray 7.3. 序列构成的数组 这一部分主要有几个重点：列表推导式的使用、元组特性和使用 7.3.1. 列表推导式的使用 # 将字符串变成Unicode码位 symbols = 'sdac@#' codes = [ord(symbol) for symbol in symbols if ord(symbol) >127] # 与map和filter的比较 lists(filter(lambda c:c>127, map(ord,symbols))) 可以看出列表推导式的表达更为简洁易懂，而且实际上运行的效率也不低 7.3.2. 使用列表推导式生成笛卡尔积 举例：每个size有不同的颜色 colors = ['black','blue','red'] sizes = ['S','M','L'] # 先按颜色循环再按size循环，内外层循环的关系 tshirts = [(color,size) for color in colors for size in sizes] 7.3.3. 生成器表达式 我们可以使用列表推导来初始化元组、数组、或者其他的数据类型，但是生成器表达式符合了迭代器的协议，可以逐个的产出元素，而不是先建立一个完整的列表，能够节省内存 语法上和列表推导差不多，只不过把方括号换成圆括号而已 tuple(ord(symbol) for symbol in symbols) import array array.array('I',ord(symbol) for symbol in symbols) 利用生成器表达式来计算笛卡尔积 # 这样可以更好的体现逐个生成的特性？但是实际上列表推导式也可以把？ # 但是总之是由这样的特性的，能够避免额外的内存占用 for tshirt in ('%s %s' %(c,s) for c in colors for s in sizes): print(tshirt) 7.3.4. 元组不仅是不可变的列表 7.4. 列表的基本操作 7.4.1. 列表的条件加和 有不少类似和条件语句相关的操作，列举一些基本实例如下： # np.random.randint? A = np.random.randint(0,3,5) B = np.random.randint(0,3,5) print('origin A　is {} \\n And B is {}'.format(A,B)) # style 1 相当于转换成一个ToF的list，然后对这样的list直接进行sum same = (A == B).sum() print('\\nthe num of same element in same posi is', same) '''列表的+=，也就是简单拼接操作''' [1,2,3]+[2,3,4] 7.4.2. 列表的数乘 列表的数乘是对列表的项数进行一个重复性的扩充，但是注意这种重复不能针对那种特殊类型（也就是赋值会直接基于地址的：引用？） 所以这是对于项数的操作而不是对列表中数值的直接操作，参考变量赋值的部分 value = 5 unlist = [value] outlist = unlist * 5 print('the output is like that : {}'.format(outlist)) 7.4.3. range函数常用操作 https://docs.python.org/zh-cn/3.7/library/stdtypes.html?highlight=range#range range生成的并不是列表，而是一个range组而已 reallist = list(range(20)) # range的步长设置 for i in range(0,20,5): print(i) 7.5. Universal Method 7.5.1. Sort（）对列表进行排序 sort用于对源列表进行排序，如果指定参数，则使用指定的比较函数 参考资料：https://www.runoob.com/python/att-list-sort.html # 纯数字的情况就按基本方式进行排列 list1 = [1,2,4,5,6,23,4] list1.sort() list1 # 类似的string就按找字母表进行逐项排序吧，我是这样理解的 7.6. 队列queue & deque 7.7. SET集合 https://www.runoob.com/python3/python3-set.html {}可以定义字典，也可以用于创建集合 但是空的集合只能用set()定义（因为{}定义的是空字典） 基本的method： add、remove、discard（也是移除，但是假如元素不存在的话也不会报错） len，clear 主要是可以利用其中不会重复的元素的特性来进行特殊的操作 basker = {'apple', 'organge', 'apple', 'pear'} print('basker:', basker) 'orange' in basker a = set('go straight forward') # 可以在集合中做交并等等集合的操作 7.7.1. 利用set进行去重 如何利用set对unhashable的data structure进行去重，这里采取的方式是使用tuple对数组进行变换； 实际上unhashable的原因在于对象是可变对象：比如np.array，所以我们将其转换为不可变的tuple之后就可以进行hash的计算从而进行去重了。 # 二维数组为例 array1 = np.random.rand(3,4) array1_t = tuple(map(tuple,array1)) resume = np.array(array1_t) # 进行转换的时候注意不要进行过度的拆分，上述的方法只适用于二维数组的情况， text = ['abcsd','dsdc','cdsda'] text = tuple(text) # 即可，不然可能会将其中的文本全部拆分出来 # 后续补充一下map的其他用法。[func,iterator?] 7.8. Dict，Hashmap 实际上python中的字典就是hashmap的具体实现，是一个无序的结构 7.8.1. 判断字典中的key是否存在的方法 首先如果我们调用的key不存在的话： keyerror >>> 'key1' in dict1 false 或者使用get方法，能给不存在的key赋予默认的value,在这个时候出现的则是nameerror >>> d.get('key1') >>> d.get('key1', -1) -1 7.8.2. 字典中的常用方法 … 7.8.3. collections.defaultdict 指定dict中未定义key的value 通过指定的默认值，在一些使用场景下可以对dict进行简化的定义 同时也能针对一些特殊的情况，比如说未见数据的情况，进行定义 # 指定list类型用于未定义类别的填充 from collections import defaultdict dict1 = {} dict2 = defaultdict(list) try: print(dict1['a']) except: print('dict1 print key error') print('dict2 is like ', dict2['a']) dict1 print key error dict2 is like [] # 用法2，避免keyerror更容易对其进行赋值 from collections import defaultdict bags = ['apple', 'orange', 'cherry', 'apple','apple', 'cherry', 'blueberry'] count = defaultdict(int) for fruit in bags: count[fruit] += 1 print('the count output is like \\n', count) # print(locals().keys()) the count output is like defaultdict(, {'apple': 3, 'orange': 1, 'cherry': 2, 'blueberry': 1}) # 用法3：可以自定义函数作为初始化的函数参数 # 基于这样的方法我们可以定义各种各样的默认值 from collections import defaultdict def defaultvalue(value=2): return value dict3 = defaultdict(defaultvalue) dict3['hello'] 7.9. Vars（） vars() 函数返回对象object的属性和属性值的字典对象。 7.10. Python中的数字日期时间计算 @Aiken 2020 @Source：《Python Cookbook》 Chapter3 数字日期和时间 主要针对Python中的数字数字运算的运算做一个笔记 7.10.1. 获取本机时间的几种方法 主要为了方便格式化时间输出，我们需要将机器时间转换成指定的年月日之类的。 分别来自于time 和 datatime，这两种方式的时间复杂度好像实际上并没有太大的差别，姑且用着把暂时。 import time from datetime import datetime def get_time(type=1): if type == 0: now = time.strftime('%m/%d:%H:%M') else: now = datetime.now().strftime('%m/%d:%H:%M') return now get_time(0) 7.10.2. 精确数字运算 我们知道python中的计算不是绝对精准的， 浮点的精度是有限的，但是当我们需要进行金融领域或者数学领域的一些高精度要求的计算，可以为其牺牲一定的复杂度的时候&#x1F449;decimal模块 from decimal import Decimal a = Decimal('4.2') b = Decimal('2.1') print(a + b, a+b==Decimal('6.3')) # 注意数据的类型实际上也是Decimal # 能控制计算的每一方面，包括数字位数和四舍五入之类的，需要创建一个本地的上下文 from decimal import localcontext # 精确度控制 with localcontext() as ctx: ctx.prec = 3 print(a/b) 计算方法中的大数吃小数的情况 (运算中的量纲差异超过17位的浮点数精度的情况)使用math.fsum()函数 import math nums = [1.23e+18，1，-1.23e+18] assert sum(nums) != math.fsum(nums), 'the correct ans is fsum {}, error ans is sum {}'.format(math.fsum(nums),sum(nums)) # we can find it what we meet and waht we want. 7.10.3. 数字的格式化输出 控制输出的格式（精确度，对齐，千分位分割符）format x = 1234.56789 anslist = [] value = format(x, '0.2f') # &#x1F448; 两位小数 anslist.append(value) Untitled 进制转换： 2,8,16 -> bin（） oct（） hex（） OR format(x, ‘b’) format(x, ‘o’) format(x, ‘h’) 复数运算 complex(real, imag)``numpy好像能处理复数cmath一些math无法处理的复数运算 正负无穷于NaN（非数字） inf，-inf，nan， 可以使用float(‘inf’)创建验证 math.isinf() 分数运算 Fractions（5，4）==5/4.numerator 分子 .denominator 分母 8. 迭代器 主要包括迭代的模块和解包的一些相关操作： enumerate 、items、zip enumerate可以将可迭代对象，除了dict，解压出来，并自带序号（多加入一个维度）。 字典的解包主要靠items（） zip将可迭代对象作为参数，把每一项可迭代对象中取出一个值，组合成一个个元组，，然后返回。 for a,b,c in zip(A,B,C): ... 9. 元编程 9.1. Some Rules ->in python: 常常出现在python函数定义的函数名后面，为函数添加元数据，描述函数的返回类型，从而方面开发人员使用。 拓展：进行函数内的参数定义的时候也可以用冒号指定类型，以及默认值 def func(isPre: bool = True): pass 9.2. 装饰器模块 装饰器在我个人的理解里面更像是一个嵌套的函数结构，编写装饰器实际上是为了给函数套壳，最根本的目的仍然是为了repeat coding，而这样的写法最直接适用的有以下的几种情况： Timing or Logging 当成函数指针进行函数的传递（但是这点上实际上用类传递的方式可能会更常见一点） 9.2.1. Basic Type 最基本的编写样例： import time from functional import wraps def timethis(func): '''Decorator that report the execution time. this Decorator can not accept parameters''' # 通过下面这个内置的装饰器来保留func的元信息 __name__ __doc___之类的 @wraps(func) def wrapper(*args,**kwargs): # * ** 来保证可以对func传入各种参数 start = time.time() result = func(*args, **kwargs) end = time.time() print(func.__name__, end - start) return result return wrapper 9.2.2. 接受参数传递 但是这个装饰器实际上不满足我们的需求，我们希望装饰器能接受传入的参数，这样的话，我们才能更好的进行print或者是使用logging这个模块。 Then we can write it like this : # 实际上直观的理解的话，就是在外面再多嵌套一层函数，通过这个函数来对我们的decorator传递需要的参数 from functional import wraps import logging # 实现对装饰器的参数传递，同时和 def logged(level, name=None,message=None): '''通过最外层接受参数并将其传递到内层的装饰器中''' def decorate(func): # setting paramter we passing here logname = name if name else func.__moudule__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args,**kwargs): log.log(level,logmsg) return func(*args,**kwargs) return wrapper return decorate # 但是实际上我们要传递的就是一些输出结果，所以我们不需要用到这一点，只要再内部赋予logging就行了，所以这里我们设定的就是基本的level和logger_nanme 9.2.3. 修改装饰器参数 对上面这个装饰器模块进行简单的改进，就能使得用包装器包装的函数，能够调用附加函数来修改装饰器的参数 （相当于赋予被装饰方法一个对装饰器的类外访问函数） # 这里有个模块就比较猎奇了，以前倒是没见过 from functional import wraps,partial import logging # utility decorator to attach a functional as an attribute of obj def attach_wrapper(obj, func=None): if func is None: return partial(attach_wrapper, obj) setattr(obj, func.__name__,func) return func #原有装饰器上面添加东西即可 def logged(level, name=None,message=None): '''通过最外层接受参数并将其传递到内层的装饰器中''' def decorate(func): # setting paramter we passing here logname = name if name else func.__moudule__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args,**kwargs): log.log(level,logmsg) return func(*args,**kwargs) '''使用nonlocal添加属性修改的模块''' @attach_wrapper(wrapper) def set_level(newlevel): nonlocal level level = newlevel @attach_wrapper(wrapper) def set_message(newmsg): nonlocal logmsg logmsg = newmsg return wrapper return decorate @logged(logging.DEBUG) def add(x,y): return x + y @logged(logging.CRITICAL,'example') def spam(): print('Spam') # 使用范例:可以再类外调用内内的属性设置了 add.set_message('add called') add(2,3) add.set_level(logging.WARNING) add(2,3) 9.2.4. 带可选参数的修饰器 # 感觉没太理解这个文章中说到的不带参数的意思，难道可以不传入函数吗 # 先把模板放在这 def logged(func = None, *, level=logging.DEBUG,name=None, message=None): if func is None: return partial(logged,level=level,name=name,message=message) logname = name if name else func.__moudule__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args,**kwargs): log.log(level,logmsg) return func(*args,**kwargs) return wrapper 9.2.5. @property的用法 将类别方法转换为类别属性，可以直接用.获取属性值或者对属性进行赋值。 具体的实现和要求在后面再看看 10. Exception @Aiken 2020 Python的异常处理操作：主要内容包括捕捉异常，抛出异常，基于异常进行判断处理等。 基本原理: 参考资料： python3_错误和异常 、 python3_错误和异常2 10.1. Python3 错误和异常 错误：一般语法解析器的解析错误，换句话说也就是基本的语法错误。 异常：语法正确，但是运行期间出现的错误， 异常有很多种类：未定义，类型异常，除数0异常，etc. ...在附录附加常用常见的错误类型 10.2. 异常捕捉try except 通过try exception 捕捉可能会出现的异常，然后用except，指定当该异常出现时候要执行的命令，可以指定多种异常。 基本的算法流程是： 首先，执行 try 子句（在关键字 try 和关键字 except 之间的语句）。 如果没有异常发生，忽略 except 子句，try 子句执行后结束。 如果在执行 try 子句的过程中发生了异常，那么 try 子句余下的部分将被忽略。如果异常的类型和 except 之后的名称相符，那么对应的 except 子句将被执行。 如果一个异常没有与任何的 except 匹配，那么这个异常将会传递给上层的 try 中。 完整的算法逻辑如图所示&#x1F447;，通常可以指使用t-e部分即可 Image1 #主要依赖模块 import time import sys 写法的优点 在可预见的Exception出现的时候不会中断程序的进行， 可以以指定的方式进行规避，或者针对该情况进行特定的异常处理。 else的优势 如果try中出现了多个异常，我们可能会忽视其中的一些异常。 可以针对性的进行异常算法设计，这样会使得可读性和便于分析。 # 用try except的方式最好的一点在于，他不会终端程序的执行。 try: x = int(input(\"please type in NUMBER \")) except ValueError: print('your input is not NUMBER') # if we donot use t-e x = int(input(\"repeat you input\")) # 通过对比，我们可以知道这样执行的好处，在一些无关紧要的地方， # 可以让程序继续运行而不必因为这些而中断。 10.2.1. exception的多种写法和多异常分支 try中的语句可能有多种异常抛出的情况： 针对不同的异常进行处理。 统一处理不同异常。 统一处理所有类型 以上面的代码为例： try except except ... EXCEPT (TUPLE) except不带任何参数 # type 1 try: x = 123 except ValueError: t = 123 except TypeError: y = 123 # type 2 try: x = int(input(\"please type in NUMBER \")) except (ValueError,TypeError,NameError): print('your input is not NUMBER') your input is not NUMBER 10.3. 抛出异常 Raise Exception 使用raise 语句能够抛出指定类型的异常，从而终止程序的运行，和assert断言起到相似的作用。 关键用法：设置异常抛出，然后用try except捕捉，然后进行指定的分支操作。 raise [Exception [, args [, traceback]]] raise_exception x = 10 if x >= 5: raise Exception('x 不能大于5，当前值为 {} '.format(x)) 11. Numpy Tips 11.1. reshape 和numpy格式的reshape的相关内容整合 基本reshape的使用 reshape不改变原数据 bk1_a = np.array([1,2,3,4,5,6,7,8]) bk1_b = np.array([[1,1,1,1],[2,2,2,2]]) bk1_c = bk1_a.reshape(bk1_b.shape) print(\"b's datashpe is {}\".format(bk1_b.shape)) print(\"reshape by b。shape is ↓ \\n {}\".format(bk1_c)) # 测试是否改变原数据 print(\"b's shape is {} \".format(bk1_b.shape)) assert bk1_a == bk1_c, 'do not change the origin data, a is like {}'.format(bk1_a) 11.2. tolist numpy array 和list之间的互相转换，在大规模编程中有比较广泛的应用场景。 **有^次方的意思 arange 包含下限，不包含上线 bk2_a= (2 ** np.arange(4,6)) # bk2_a bk2_b = bk2_a.tolist() # bk2_b 11.3. 用array给list中的元素赋值 以下是这种方式建立一个类似one-hot的函数介绍 可以很容易的从输出看出规律，而且最外层仍然是列表，也就是其中的元素是array list1 = [1,2,3,4,12,3,4] for i in range(len(list1)): temp = list1[i]-1 list1[i] = np.zeros(13) list1[i][temp] = 1 list1 11.4. flatten & flat operation flatten：将数据摊开降维成一维的数组/矩阵，以副本形式生成，不影响原数据 flat，生成一个迭代器，按行的形式迭代 # A:flatten function B:flat function bk3_a = np.random.rand(2,3) print('A is just like\\n {}'.format(bk3_a)) bk3_a2 = bk3_a.flatten() print('A2 is just like\\n {}'.format(bk3_a2)) printz('********************clip*************************') bk3_b = np.random.rand(2,3) print('B is just like \\n{}'.format(bk3_b)) print(bk3_b.flat, 'as we can see, this is a iter') for i in bk3_b.flat: print(i) 11.5. Numpy.pad pad，就是拓展原本数据的维度，方便后面机器学习中的其他步骤，主要用处包括： 维度保持 增加对图像边界的重视 ## numpy.pad x = np.random.randint(0,5,(3,4,4)) x = np.pad(x,2) print(x.shape) h,w = x.shape[1:] new_h,new_w = 3,3 top = np.random.randint(0,h-new_h) left = np.random.randint(0,w-new_w) x = x[:,top: top+new_h,left:left+new_w] x.shape 11.6. :: Numpy 索引中双冒号的实际用途 参照该文章进行分析，主要用途包括：对图像进行反转等操作 https://blog.csdn.net/GracePro/article/details/102079331 a = np.random.rand(3,2,2) print(a) print('----------------------------') a = a[:,::-1] print(a) 11.7. Argpartition() 借助于 argpartition()，Numpy 可以找出 N 个最大数值的索引，也会将找到的这些索引输出。然后我们根据需要对数值进行排序。 x = np.array([12, 10, 12, 0, 6, 8, 9, 1, 16, 4, 6, 0]) index_val = np.argpartition(x, -5)[-5:] index2 = np.argmin(x) print(index2) index_val 基于numpy的sort函数，输出找出的最大的几个数，要全体排序的话，还是考sort np.sort(x[index_val]) 11.8. Allclose() allclose() 用于匹配两个数组，并得到布尔值表示的输出。如果在一个公差范围内（within a tolerance）两个数组不等同， 则 allclose() 返回 False。该函数对于检查两个数组是否相似非常有用。 array1 = np.array([0.12,0.17,0.24,0.29]) array2 = np.array([0.13,0.19,0.26,0.31]) # with a tolerance of 0.1, it should return False: print(np.allclose(array1,array2,0.1)) # with a tolerance of 0.2, it should return True: print(np.allclose(array1,array2,0.2)) 11.9. Clip() 使得一个数组中的数值保持在一个区间内。有时，我们需要保证数值在上下限范围内。为此，我们可以借助 Numpy 的 clip() 函数实现该目的。给定一个区间，则区间外的数值被剪切至区间上下限（interval edge）。 x = np.array([3, 17, 14, 23, 2, 2, 6, 8, 1, 2, 16, 0]) np.clip(x,2,5) 11.10. extract() 顾名思义，extract() 是在特定条件下从一个数组中提取特定元素。 借助于 extract()，我们还可以使用 and 和 or 等条件。 array = np.random.randint(20, size=12) print('basic array is {} '.format(array)) # Divide by 2 and check if remainder is 1 cond = np.mod(array, 2)==1 print('是否符合条件的list，条件list\\n {}'.format(cond)) # Use extract to get the values # 提取出表现为True的哪些元素 print('按照条件提取出元素:\\n {}'.format(np.extract(cond, array))) # Apply condition on extract directly # 更直接的指定条件 print('复杂条件下的表现情况') print(np.extract(((array 15)), array)) 11.11. where() Where() 用于从一个数组中返回满足特定条件的元素。比如，它会返回满足特定条件的数值的索引位 Where() 与 SQL 中使用的 where condition 类似，如以下示例所示： y = np.array([1,5,6,8,1,7,3,6,9]) # Where y is greater than 5, returns index position print(np.where(y>5)) # First will replace the values that match the condition, # second will replace the values that does not print(np.where(y>5, \"Hit\", \"Miss\")) 12. DEBUG 记录一些典型错误，便于后续Debug的时候查找原因 12.1. 避免重复/冲突的import 在工程实现中，对于同一个module。最好能做到不需要重复的import，但是在跨文件的工程项目中，或者说是一些跨文件调用的情况下，可能有一些基本的module会需要这样的时候，那我们最好做到不冲突，以同样的形式来进行import，不然有时候这样的重定义方式会出现一定的问题或者bug。 for example from time import time 和 import time同时出现的情况。 12.2. 内存调用与Method的定义 在较为复杂的工程项目中，应该使用Method（Function）模块化的解决问题；这样做的优势可以从一下几点来看： 易于阅读分析，写好相关method的Doc，然后做好注释，方便阅读和后续修改 能够在迭代过程中有效的释放暂态的变量，节约在主进程中无效的参数存储空间，节省内存或者显存。 12.3. TypeError： 一：cannnot unpack not-iterable NoneType object（无法解包非迭代类型的NoneType对象） def test(): if value == 1: a=b=1 return a, b a,b = test() print(a,b) 原因分析，当python函数没有确定的return的时候默认的返回值是None，这样在进行检查的时候，就会到导致编译的错误 解决：指定默认的return，或者使用else方法完善所有情况下的return值的个数是一致的 二：missing 1 required positional argument： “self” 对象的声明需要括号，我们可能在调用类内函数的时候，用错了变量，用了类而不是类的实例去调用这个函数，导致执行出现了错误。 三：builtin_function_or_method error 很多时候都是由于前面的数据操作少加了()导致的问题 四：bad operand type for unary -: ‘NoneType’ 输入的数据存在着值为空的情况，可能没定义之类的，问题要根据后面的具体报错来进行分析。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Langs/Extensible_Markup_Language.html":{"url":"Langs/Extensible_Markup_Language.html","title":"L2:标记语言：Extensible Markup Language","keywords":"","body":"1. Read Local Data1.1. Python: Glob1.1.1. glob.glob:1.1.2. glob.iglob()1.2. Python：pickle1.3. YAML1.3.1. 写在前面1.3.2. YAML-Python1.3.3. YAML的写入1.4. JSON1.4.1. Json-Python1.5. XML1.6. CSV1.6.1. write1.6.2. read1. Read Local Data @Aiken 2021 对于各种形式的标记文档和数据集的处理进行一个整合，还有一些python中的相关模块（比比如glob，后续可能会迁移到别的文档中），主要包括：yaml，json，csv，xml，这些可拓展的标记语言. TODO： [ ] csv,xml：这一部分可以看一下吉仲师兄那边是怎么存和取文件的，继承一下代码减少我这一部分的工作量 [ ] 按照csv文件对数据集进行本地的文件夹切分。实际上很多数据集，像mini-imageNet这类的是需要我们下载下来之后按照csv文件对训练集和测试集进行切分的 [ ] 使用sklearn对完整的未切分数据进行切分。 1.1. Python: Glob 文件操作相关模块，用于简单的路径匹配的模块，用来查找路径中的相关文件，基本的正则匹配规则如下： “*”: 匹配0哥或多个字符 “?” : 匹配单个字符 “[ ]”: 匹配指定范围内的字符,如[0-9]匹配所有的数字 1.1.1. glob.glob: 返回所有匹配的路径列表,只有一个参数pathname,定一乐文件路径的匹配规则,可以是绝对路径或者是相对路径,具体的使用可以参考如下的方式: for xmlpath in glob.glob('media/all/DATAPART/' + \"*\") # xmlpath 遍历文件夹下的所有文件和文件夹 for xmlpath in glob.glob(xmlpath + \"/*/*\") # xmlpath 遍历文件夹下所有文件夹中的文件夹中的文件:按照层数自由设定 img_path = sorted(glob.glob(os.path.join(images, '*.npy'))) # 遍历文件夹下的所有npy文件,说实话感觉这个怪离谱的,晚点试一下 import glob print(glob.glob(r\"E:/imgdir/*/*.jpg\")) 1.1.2. glob.iglob() 获取一个可遍历对象使用它可以逐个获取匹配的文件路径名: glob:一次获取全部 iglob:逐个匹配路径获取. 1.2. Python：pickle palceholder 1.3. YAML YAML是一种标记语言，可以通过YAML定义超参数，然后从外部引入，所以常用来作为一些特定的config，具体的用发和用途可以这样理解： 当我们使用不同的backbone module的时候，我们可能对于超参数等等的一系列配置是不恒定的，所以使用config文件去配置的时候，当我们每次切换，我们就只需要读取不同的config文件就行了。 实际上就是argparse的一种替代 所以本文档聚焦于如何在python/cpp中读取yaml（以及cpp补充相应的数据类型） 1.3.1. 写在前面 基本的语法什么的很好搜索，随便百度一下就行了 offical site 菜鸟入门教程 实际上大部分都是使用缩进去控制的，例子&#x1F447;，很明显可以看出对应的元素关系，包括字典，boolean，float等其他的类型。 # default num_head = 2 criterions: PerformanceLoss: def_file: ./loss/SoftmaxLoss.py loss_params: {} optim_params: null weight: 1.0 last: false # apply incremental pca to remove main components apply_ipca: false num_components: 512 networks: classifier: def_file: ./models/CausalNormClassifier.py optim_params: {lr: 0.2, momentum: 0.9, weight_decay: 0.0005} scheduler_params: {coslr: true, endlr: 0.0, gamma: 0.1, step_size: 30} params: {dataset: ImageNet_LT, feat_dim: 2048, num_classes: 1000, stage1_weights: false, use_effect: true, num_head: 2, tau: 16.0, alpha: 3.0, gamma: 0.03125} shuffle: false training_opt: backbone: resnext50 batch_size: 512 dataset: ImageNet_LT display_step: 10 1.3.2. YAML-Python 下面直接给出一个例子，基本就按照这个格式去编写就没什么问题了。 import yaml import os # 通常使用这种方式去打开文件并进行读取，这里实际上涉及到Python的IO操作 with open(args.cfg) as f: config = yaml.load(f) # 为了保证编写的一致性和与argparse的一致性使用（整合同个用途或者同个类型的数据），通常会编写update函数将两种类型中的参数整合起来 config = update(config,args) # 然后用字典的方式将config（yaml）中的每一部分要素按照命名读取出来 # 原则是：让读取出来的数据的堆叠层数不要太多，尽量就是一个dict或者一个list把 def update(config,args): # 在这里可以只提取出args中感兴趣的要素，也可以递归调用args中的所有参数 for k,v in args.items(): config[k] = v # or write down some interest elements only config['element'] = 'specific value' 1.3.3. YAML的写入 1.4. JSON json是一种存储和交换文本的语法，类似XML。Link1 经纬师兄这块是按照coco的json格式去整理的文档，同时数据的存储用的是npy,npz { \"employees\": [ { \"firstName\":\"Bill\" , \"lastName\":\"Gates\" }, { \"firstName\":\"George\" , \"lastName\":\"Bush\" }, { \"firstName\":\"Thomas\" , \"lastName\":\"Carter\" }] } 可以看VsCode中的配置文件实际上也是这种格式的： \"todo-tree.highlights.customHighlight\": { \"TODO\": { \"foreground\": \"#2f3542\", \"background\": \"#f6b93b\", \"iconColour\": \"#f39c12\", \"icon\": \"issue-opened\", \"type\": \"line\" }, \"FIXME\": { \"foreground\": \"#2f3542\", \"background\": \"#e55039\", \"iconColour\": \"#e55039\", \"icon\": \"flame\", \"type\": \"line\" } }, 读取的时候实际上也是和键值对一样的读取,用dict, 1.4.1. Json-Python 首先给出一个Json和python的类型对照表 Python Json dict object list,tuple array str string int float int-&float-derived Enums number True true False false None null Python中Json的主要导入和输出的方式主要是使用dumps和loads将python对象编写成json字符串,以及对json字符串在python中编码 dumps import json data = [ { 'a' : 1, 'b' : 2, 'c' : 3, 'd' : 4, 'e' : 5 } ] data2 = json.dumps(data) print(data2) # 使用参数让json数据格式化输出 #!/usr/bin/python data2 = json.dumps({'a': 'Runoob', 'b': 7}, sort_keys=True, indent=4, separators=(',', ': ')) print(data2) loads #!/usr/bin/python import json jsonData = '{\"a\":1,\"b\":2,\"c\":3,\"d\":4,\"e\":5}'; text = json.loads(jsonData) print(text) 载入文件的示例: with open(\"../config/record.json\",'r') as load_f: load_dict = json.load(load_f) print(load_dict) load_dict['smallberg'] = [8200,{1:[['Python',81],['shirt',300]]}] print(load_dict) with open(\"../config/record.json\",\"w\") as dump_f: json.dump(load_dict,dump_f) 1.5. XML 参考一下吉仲师兄的数据处理文件,按照该文件进行数据处理和xml python 读取情景的学习。 1.6. CSV python3：csv的读写_katyusha1的博客-CSDN博客 1.6.1. write 好像直接修改文件后缀进行编写的编码方式会出现一些离奇的问题，所以最好还是调用代码来写入csv 1.6.2. read 需要注意的参数是 quotechar：说明：delimiter是分隔符，quotechar是引用符，当一段话中出现分隔符的时候，用引用符将这句话括起来，就能排除歧义。 首先按照row进行文件的读取，这应该回事比较常见的那种类型。 import csv with open('test.csv'，newline = '') as f: f_csv = f.reader(f,delimiter=default,quotechar = default) for row in f_csv: print(row) # 这种格式读取出来的数据会有一个存放对应的=label，然后剩下的就是每一行数据的每一个 # 可以按照这种方式去根据index 索引对应的数据 [‘class’,‘name’,’sex’,...] [‘1’,‘xiaoming’，‘male’,...] [‘1’,‘xiaohong’，‘male’,...] 按照上面的很容易知道，只读取指定的列就是通过即可 for row in f_csv: print(row[i]) © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Langs/PyTorch.html":{"url":"Langs/PyTorch.html","title":"L3:PyTorch","keywords":"","body":"1. PyTorch Notebook2. Basic Part基础设定部分2.1. Tensor张量计算2.1.1. 两个tensor的数乘2.1.2. 张量命名2.1.3. 类型转换2.1.4. 维度堆叠2.2. 基本的张量函数2.2.1. 选取划窗2.3. Torch环境设置2.3.1. pytorch中的随机种子初始化2.3.2. nn.parameter()2.3.3. nn.Softmax中的dim2.4. 测试、验证模块2.4.1. 基本编写2.4.2. model.eval()和model.train()的区别2.4.3. with torch.no_grad()2.4.4. 模型的保存和读取专题3. GPU相关的设置3.1. 查看GPU状态3.1.1. 设置默认GPU设备3.1.2. 设备基本信息3.2. GPU使用率优化（注意事项）3.2.1. 缓存爆炸问题3.2.2. 运行效率优化3.2.3. 设置使用GPU的方式3.2.4. 设置相应的随机种子3.2.5. CUDA转换3.2.6. 多GPU并行4. CPU4.1. 核心和线程数设置5. 网络定义模块5.1. 数据定义模块5.1.1. torch 自定义Dataset后的使用5.1.2. Dataloader中的transformer（）：5.1.3. Dataloader中的参数5.2. 编写模型5.2.1. 模型基本单元5.2.2. 模型参数共享：5.2.3. 网络定义的方式对比分析5.2.4. Detach & detach_5.2.5. 模型调用的Tips5.2.6. Warm-up factor5.2.7. Weight decay（L2）5.2.8. Learning Rate Decay5.3. 损失函数5.3.1. CrossEntropy交叉熵5.4. 模型参数初始化和架构查看方法5.4.1. children、modules、parameters：5.4.2. 初始化原则：（继续调研）5.4.3. 典型的参数初始化方法5.5. 数据类型和维度5.5.1. 输入数据的通道5.5.2. 标签的形式转换one-hot6. Visualize 可视化部分6.1. Tensorboard in Pytorch6.1.1. Histogram 直方图参数统计6.2. Embedding Projection6.3. 可视化神经网络热力图（CAM）6.3.1. 算法原理6.3.2. 代码实现：7. DEBUG7.1. 1.ImportError: cannot import name 'PILLOW_VERSION'7.2. 2.模型参数&计算量统计 and Debug输出7.3. 3.PyTorch加载预训练模型7.4. 4.some of the strides of a given numpy array are negative.7.5. 5.读取loader的时候图像的大小不一7.6. 6.bus error dataloader num_worker7.7. 7.bus error：insufficient shared memory（shm）7.8. 8.训练过程中Cache和Memory的占用逐渐升高7.9. 9.梯度爆炸问题，算法没有学习效果7.10. 10.类型转换问题汇总7.11. 11.数据维度不对应问题汇总7.12. 12.取出具体数值时候的问题7.13. 13.CPU占用99%7.14. 14. 预测值全为0，模型收敛到奇怪的地方，损失保持一致（全均等）7.15. 15.模型部分： 训练中模型准确率不上升1. PyTorch Notebook Created by: Aiken H Detail: lang Finished?: No Tags: Code @AikenH 2021 Make My notebook of Pytorch in One File. Which Make it Easier to Serach Info We Need 2. Basic Part基础设定部分 @AikenH 2020 + 2021 this part is about pytorch basic unit, help me to code deep learning better. 2.1. Tensor张量计算 2.1.1. 两个tensor的数乘 计算两个tensor的矩阵乘法，注意其中的batch要相互对应，如果不考虑batch，就是另一个函数 # 简单的分析一下算法的逻辑 # 这是割裂出来batch的矩阵相乘形式 batch1 = torch.randn(10,3,4) batch2 = torch.randn(10,4,5) out = torch.bmm(batch1, batch2) out.size() '''output ans is torch.size([10,3,5])''' # 按位相乘 res = torch.mul(batch1,batch2) view和permute的使用实际上都是不改变原值，要用赋值的方式去做，主要是使用方式要对，一个是按照顺序去做。 2.1.2. 张量命名 NCHW = [‘N’, ‘C’, ‘H’, ‘W’] images = torch.randn(32, 3, 56, 56, names=NCHW) images.sum('C') images.select('C', index=0) 2.1.3. 类型转换 # tensor 与 nd.array进行互换 ndarray = tensor.cpu().numpy() tensor = torch.from_numpy(ndarray).float() # tensor与PIL.IMAGE进行互换 image = torchvision.transforms.functional.to_pil_image(tensor) path = r'./figure.jpg' tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path)) # np.ndarray 与 PIL.Image的互换 image = PIL.Image.fromarray(nd.array.astype(np.uint8)) ndarray = np.asarray(PIL.Image.open(path)) 2.1.4. 维度堆叠 Stack，普通的维度堆叠的测试代码如下 测试代码如下，实际上dim=0就是基本的堆起来，dim=1就是按照行来堆，dim=2就是按照列来堆 a = torch.arange(1,10).reshape(3,3) b = torch.arange(10,100,10).reshape(3,3) c = torch.arange(100,1000,100).reshape(3,3) print('-----------------a----------------') print(a) print('-----------------b----------------') print(b) print('-----------------c----------------') print(c) print('-----------------dim =0----------------') d = torch.stack((a,b,c),dim = 0) print(d.shape) print('the value of d:- {}'.format(d[2,1,0])) print(d) # 也就是说，把单个当成整体直接从上往下堆叠 # 以x[:][:]为构成单元 print('-----------------dim =1----------------') d = torch.stack((a,b,c),dim = 1) print(d.shape) print('the value of d:- {}'.format(d[1,2,2])) print(d) # 将每个的第一个维度，按次序纳出来，同value的堆在一起 # for example：[a[i][:],b[i][:],c[i][:] ]组成新的单元块 # 不，另一种理解，以x[i][:] 为单元 print('-----------------dim =2----------------') d = torch.stack((a,b,c),dim = 2) print(d.shape) print('the value of d:- {}'.format(d[1,2,1])) print(d) # 相应的以x[i][j]为单元构成 list的情况下的维度堆叠测试代码如下 相应的测试代码如下，实际上一般是按照dim=1来进行堆叠 A = torch.randn([3,4,2]) B = [A[:,i] for i in range(A.size(1))] # 这样生成的是一个list,按照我们index的排序 print(A) print(B) C = torch.stack(B,dim=1) print('---------------------result-----------------------') print(C) Cat 实际上应该也是类似的堆叠思路 2.2. 基本的张量函数 torch.split() 划分tensor torch.randperm进行list的乱序处理 # 和shuffle区分，这是另一种乱序的操作 # cat操作 a = [] for i in range(3): a.append(torch.tensor([i,i])) all_inputs = torch.cat(a) # randperm的效果 test1 idx = torch.randperm(all_inputs.size(0)) print(idx) a1, b = all_inputs, all_inputs[idx] print(a1,b) # test2 ， print('-------------------------') # randperm 进行list的shuffle tensor_a = torch.randint(0,10,[8]) print('origin version ', tensor_a) idx = torch.randperm(tensor_a.size(0)) print('shuffle idx ', idx) tensor_b = tensor_a[idx] print('after operation ', tensor_b) .fill_()按照输入的值对张量进行填充 2.2.1. 选取划窗 nn.unfold拆解卷积中的划窗步骤 import torch inputs = torch.randn(1,3,224,224) unfold = torch.nn.Unfold(4,stride=4) output = unfold(inputs) # res output output.size() $ [1,4,3136] # 3136 = (224/4) * (224/4) 2.3. Torch环境设置 2.3.1. pytorch中的随机种子初始化 yTorch 和 Python的随机数生成器就算随机种子一样也不会产生一样的结果。 我们可以这样来设置Pytorch的随机数种子：（通常和GPU一起使用） torch.manual_seed(seed) 2.3.2. nn.parameter() Main idea：parameter的作用，主要是将参数和model绑定在一起，我们就知道这个模型中，可能需要训练的参数有哪些，可以需要进行训练的参数加进去，但是当我们想要freeze it的时候就使用detach或者直接修改require_grad来让参数不在接受训练就好了， require_grad是其中的一个属性。可以结合上面的代码分析。 tensor变量是不可训练的，只有修改成parameter才能进行训练。 自带的网络结构中的一些weight和bias应该都是parameter的变量 2.3.3. nn.Softmax中的dim 其实没那么复杂，就和数据的维度是一样的，我们需要把那一个维度的数据之后的数据全部加起来处理就用哪个维度去做。 IMAGE = N* DATA，dim=1 说明dim = 0 的Channel 是需要被排外的。也就是我们的softmax是基于data进行的。可以找寻源码进行进一步分析解释。 2.4. 测试、验证模块 2.4.1. 基本编写 2.4.2. model.eval()和model.train()的区别 通常在模型测试的时候会执行model.eval()切换模型的状态，而在训练的时候会执行model.train()，model在这两个状态下的区别主要有： 在train状态下会启用BN和Dropout，而在eval不启用这两个模块； 启用BN指的是：用到每一个Batch数据的均值和方差；不启用则指的是使用整体的均值和方差（同时停止更新mean和var） 而对于Dropout来说：启用的时候指的是会随机进行dropout，而关闭的话就会用到全部的网络链接 2.4.3. with torch.no_grad() 上下文管理器，wrap起来的部分不会track grade 主要用于停止autograd模块的工作，被with包裹起来的部分会停止梯度的更新，得到进一步的加速把，因为我们实际上在验证的时候不会执行step()等操作，所以能够节省计算模型梯度的时间。 2.4.4. 模型的保存和读取专题 @Aiken 2020 基于onenote笔记，我们知道关键在于如何自由的读取模型中的参数，并选择性的取出来。 pytorch 模型部分参数的加载_LXX516的博客-CSDN博客_pytorch 加载部分参数 # 至少基于这样的方式我们能把模型中参数的string取出来。 pretrained_dict=torch.load(model_weight) model_dict=myNet.state_dict() # 1. filter out unnecessary keys pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict} # 2. overwrite entries in the existing state dict model_dict.update(pretrained_dict) myNet.load_state_dict(model_dict) 3. GPU相关的设置 @written by Aiken, 2020 this document is about Pytorch‘s CUDA, & GPU setting. 3.1. 查看GPU状态 3.1.1. 设置默认GPU设备 一般使用GPU之前，我们需要知道系统中有多少GPU设备，因为默认的GPU设备是0，而且，大家一般都直接使用这张卡，所以我们如果只使用单卡的话，切换一下默认的GPU设备，能够避免一定的冲突。 # 查看GPU使用状态 $ nvidia-smi # or $ gpustat [--watch] 3.1.2. 设备基本信息 查看是否存在GPU，数量，类型 import torch # 查看是否存在GPU，数量，类型 torch.cuda.is_available() torch.cuda.device_count() torch.cuda.get_device_name(0) 查看指定的GPU的容量和名称 torch.cuda.get_device_capability(device) torch.cuda.get_device_name(device) 设置当前系统的默认gpu_devices，推荐使用os来设置（实际上是命令行中的操作）实际上是系统设定针对当前进程的可见GPU，其他的GPU会对当前的程序隐藏，所以默认的0 os.environ['CUDA_VISIBLE_DEVICES'] = \"id\" #推荐用法 # 可以在vscode的launch.json中设置env 注意事项：该命令需要在所有调用了CUDA的代码、子程序之前，包括import，所以很多代码的import都是在main()中的。 3.2. GPU使用率优化（注意事项） 3.2.1. 缓存爆炸问题 GPU使用途中需要注意的地方，在每次iteration之后记得清除在GPU中占用的memory，cache等，不然有时候会导致缓存和内存的递增和爆炸。 具体操作： torch.cuda.empty_cache() # after every iteration 3.2.2. 运行效率优化 cudnn.benchmark、pytorch论坛 pytorch中文网、zhihu究极分析文 基本使用思路： 在程序的开始，让cudnn花费一点额外的时间，找到适用于当前配置的最佳算法，从而优化运行效率。 注意事项： 但是如果我们的input_size在每个iteration都存在变化的话，那么每一个iteration都要执行一次搜索，反而得不偿失。 具体操作 torch.backends.cudnn.benchmark = true 3.2.3. 设置使用GPU的方式 3.2.4. 设置相应的随机种子 torch.cuda.empty_cache() # part2 设置随机种子 torch.cuda.manual_seed(seed) torch.cuda.manual_seed_all(seed) 3.2.5. CUDA转换 使用.cuda()来对模型，数据，Loss进行赋值，或者使用to_devices()来设置到相应的GPU设备 将模型转化到cuda中要在优化器的建立之前执行，因为optimizer是对于模型建立的，对模型执行cuda后已经和原本的参数和模型都不是同一个了，所以一定要在建立优化器之前就对模型进行Cuda 的转化。 3.2.6. 多GPU并行 主要使用的命令nn.DataParallel() model = nn.DataParaller(model,device_ids=None) # 如果不设定id的话，应该是自动指定全部可见的GPU的 4. CPU 偶然会由于pin_memory 的设置来致使CPU的不正常运行（满载等等），并非总是这样。 4.1. 核心和线程数设置 限制或增加pytorch的线程个数！指定核数或者满核运行Pytorch！！！_lei_qi的博客-CSDN博客 import os from multiprocessing import cpu_count # 设置环境变量来控制线程多发的情况 cpu_num = cpu_count() # 核心代码 os.environ['OMP_NUM_THREADS'] = str(cpu_num) # 下面这些应该是不一定药有 os.environ ['OPENBLAS_NUM_THREADS'] = str(cpu_num) os.environ ['MKL_NUM_THREADS'] = str(cpu_num) os.environ ['VECLIB_MAXIMUM_THREADS'] = str(cpu_num) os.environ ['NUMEXPR_NUM_THREADS'] = str(cpu_num) # 从其他资料中可以感觉这条代码应该是和核心代码一样的功能，所以两个写一个应该就可以了 torch.set_num_threds(cpu_num) 5. 网络定义模块 5.1. 数据定义模块 5.1.1. torch 自定义Dataset后的使用 自定义dataset的继承以及后续调用需要注意的是不能忘记将其转换成dataloaer，然后进行iter命令的执行。 也可以用enumerate函数来进行调用，就是记得调用的格式是什么就好 可以参考basicunit中的对shuffle的认知对该函数进行进一步的理解。 # 定义dataset的部分 class RL_AET_Dataset(torch.utils.data.Dataset): def __init__(self): super(RL_AET_Dataset,self).__init__() pass def __len__(self): pass def __getitem(self): pass # 声明和构建部分 要记得使用dataloader train_l_dataset = RL_AET_Dataset(x_l, y_l, args) train_l_dataloader =torch.utils.data.DataLoader(train_l_dataset,batch_size=args['b_s'],shuffle=True,num_workers=args['num_workers'],drop_last=True,pin_memory=True) #调用迭代部分 labeled_loader = iter(train_l_dataloader) #all_label_info = [*next(labeled_loader)] 5.1.2. Dataloader中的transformer（）： 疑惑解答 用compose集成的所有transform，都会应用，有个to_tensor，切to_tensor会自动转换PIL中的channel和数值范围。 compose中的变换组合的顺序关系 PIL处理的图像变换（比如数据增强之类的方法） to_tensor() 处理tensor的方法：normalize 示例代码 data_transforms = transforms.Compose([ transforms.RandomResizedCrop(224), transforms.RandomHorizontalFlip(). transforms.ToTensor(), transforms.Normalize([a,b,c],[A,B,C])]) # 然后直接加入dataset中的参数，或者是我们自定义的部分 # 在dataset中的写法如下，我们可以在自己的dataset中进行定义 if self.transformer is not None: img = self.transform(img) # 具体的源码细节表现如下 for t in self.transforms: img = t(img) return img 5.1.3. Dataloader中的参数 shuffle机制 主要解决问题： 是否每次调用的时候都进行随机的操作，还是只有在初始化的时候才进行随机 两种不同使用Dataloader的方式是否会对shuffle的方式进行区分 结论： 每次对dataloader进行重新调用（重新放到enumerate），或者重新定义iter，都会重新进行shuffle。 num_worker 参考资料1 参考资料2：pytorch中文文档&#x1F447; num_workers (int, optional) – 用多少个子进程加载数据。0表示数据将在主进程中加载(默认: 0) 用num_worker个子进程加载数据，所以能够将数据在主进程展示还没有调用到该数据之前就将后续的数据存入RAM，所以在数据读取上会比较快，但是占用的RAM和CPU资源会比较大。 samples: torch.utils.data - PyTorch 1.9.0 documentation 一文弄懂Pytorch的DataLoader, DataSet, Sampler之间的关系 官方的解释是： sampler (Sampler or Iterable, optional) – defines the strategy to draw samples from the dataset. Can be any Iterable with len implemented. If specified, shuffle must not be specified. 定义从数据集（还是最开始的哪个数据集，不能是额外的数据集）中提取样本的策略：是否能通过该Method去实现Hard-Task或者像Meta-Task一样的采样过程呢？从Meta-Transfer-Learning中看来是可以的，可以学习一下它的写法。 collate_fn() collatefn的作用就是将一个batch的数据进行合并操作。默认的collatefn是将img和label分别合并成imgs和labels，所以如果你的__getitem方法只是返回 img, label,那么你可以使用默认的collate_fn方法，但是如果你每次读取的数据有img, box, label等等，那么你就需要自定义collate_fn来将对应的数据合并成一个batch数据，这样方便后续的训练步骤。 5.2. 编写模型 5.2.1. 模型基本单元 nn.conv2D： kernel_size[1]应该指的是卷积核的宽（不一定都是正方形的） 5.2.2. 模型参数共享： pytorch：对比clone、detach以及copy_等张量复制操作 # 假设有modela和modelb，我们需要在进行下降的时候执行参数统一， for a_para,b_para in zip(modela.parameters(),modelb.parameters()): b_para.data.copy_(a_para.data) 5.2.3. 网络定义的方式对比分析 @Aiken 2021 主要对比的是ModuleList和Sequtial 结论：通常使用的话，这里我个人推荐使用的是sequtial结合collection中的orderdict来构建的方法，这个方法集成了内部的forward，同时通过`orderdict也能给print带来更好的可视化效果。 但是还是有一些特殊的使用场景我们会用到ModuleList 详解PyTorch中的ModuleList和Sequential 主要区别： nn.Sequential内部实现了forward函数，因此可以不用写forward函数。而nn.ModuleList则没有实现内部forward函数。 nn.Sequential可以使用OrderedDict对每层进行命名，上面已经阐述过了； nn.Sequential里面的模块按照顺序进行排列的，所以必须确保前一个模块的输出大小和下一个模块的输入大小是一致的。而nn.ModuleList 并没有定义一个网络，它只是将不同的模块储存在一起，这些模块之间并没有什么先后顺序可言。网络的执行顺序按照我们在forward中怎么编写来决定的 有的时候网络中有很多相似或者重复的层，我们一般会考虑用 for 循环来创建它们，而不是一行一行地写，这种时候就使用ModuleList： class net4(nn.Module): def __init__(self): super(net4, self).__init__() layers = [nn.Linear(10, 10) for i in range(5)] self.linears = nn.ModuleList(layers) def forward(self, x): for layer in self.linears: x = layer(x) return x net = net4() print(net) # net4( # (linears): ModuleList( # (0): Linear(in_features=10, out_features=10, bias=True) # (1): Linear(in_features=10, out_features=10, bias=True) # (2): Linear(in_features=10, out_features=10, bias=True) # ) # ) 基本使用： nn.sequential 可以通过list和*以及add moudle来进行迭代的定义，同时这种定义方式，会方便我们的重复注册 from collections import OrderedDict class net_seq(nn.Module): def __init__(self): super(net_seq, self).__init__() self.seq = nn.Sequential(OrderedDict([ ('conv1', nn.Conv2d(1,20,5)), ('relu1', nn.ReLU()), ('conv2', nn.Conv2d(20,64,5)), ('relu2', nn.ReLU()) ])) def forward(self, x): return self.seq(x) net_seq = net_seq() print(net_seq) #net_seq( # (seq): Sequential( # (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1)) # (relu1): ReLU() # (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1)) # (relu2): ReLU() # ) #) nn.ModuleList:与python自带的List不同的地方在于他会自动将网络注册到Parameter中，成为网络，但是需要自己去编写forward过程 class net_modlist(nn.Module): def __init__(self): super(net_modlist, self).__init__() self.modlist = nn.ModuleList([ nn.Conv2d(1, 20, 5), nn.ReLU(), nn.Conv2d(20, 64, 5), nn.ReLU() ]) def forward(self, x): for m in self.modlist: x = m(x) return x net_modlist = net_modlist() print(net_modlist) #net_modlist( # (modlist): ModuleList( # (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1)) # (1): ReLU() # (2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1)) # (3): ReLU() # ) #) for param in net_modlist.parameters(): print(type(param.data), param.size()) # torch.Size([20, 1, 5, 5]) # torch.Size([20]) # torch.Size([64, 20, 5, 5]) # torch.Size([64]) 5.2.4. Detach & detach_ 这个模块在后续进行pretrain或者transfer的时候应该会经常被用到，所以这种方法还是需要熟练掌握的 详细的分析介绍 detach是产生一组不需要下降的“Copy”：如果要修改原值的话就要进行赋值操作。 detach_则是修改本身参数的属性（require_gradetc.）执行函数就能将参数修改为不需要下降的情况，不需要执行赋值处理。 5.2.5. 模型调用的Tips 使用list进行多模型的混合调用 由于python默认的是引用赋值，也就是浅拷贝的方式？ 通过list来进行模型的批量构建，通过list来将模型整合起来，是不会使用额外的存储空间的，它们指向同一个地址。基于这样的假设，我们可以基于list来简化代码，通过LOOP来执行，相关的调用操作，比如生成器或者预测之类的，来简化代码结构。 model1 = AET_model(3,4,5,**kwargs) model2 = AET_model(3,4,5,**kwargs) model_list = [model1,model2] if id(model1)==id(model2): print('the address of those model is same, so donot need extra space') # 具体可以简化什么类型的操作： optimizer_list = [] for _, models_t in enumerate(model_list): optimizer_list.append(optim.SGD( models_t.parameters(), lr,mom，wd)) optimizer1 = _[0] optimizer2 = _[1] # like this 5.2.6. Warm-up factor 对于这一部分的概念我还是有些不了解，是否和冷启动和热启动的概念是相关的，如果不是的话，顺便就学习一下冷启动和热启动的概念。 具体解析： neural network - What does \"learning rate warm-up\" mean? - Stack Overflow 关于warmup学习率云中寻雾的博客-CSDN博客 pytorch学习率调整方法（warm up） ，label smooth、apex混合精度训练、梯度累加_xys430381_1的专栏-CSDN博客 神经网络中 warmup 策略为什么有效；有什么理论解释么？ 5.2.7. Weight decay（L2） 实际上就是对权重进行L2正则化，让权重衰减到更小的值，在一定程度上减少模型的过拟合问题，所以权重衰减实际上也叫L2正则化。 具体的数学推导后续将集成到GoodNote笔记上，将正则化单独作为一个模块去整理。 权重衰减（L2正则化）的作用 作用： 权重衰减（L2正则化）可以避免模型过拟合问题。 思考： L2正则化项有让w变小的效果，但是为什么w变小可以防止过拟合呢？ 原理： （1）从模型的复杂度上解释：更小的权值w，从某种意义上说，表示网络的复杂度更低，对数据的拟合更好（这个法则也叫做奥卡姆剃刀），而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果。（2）从数学方面的解释：过拟合的时候，拟合函数的系数往往非常大，为什么？如下图所示，过拟合，就是拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。而正则化是通过约束参数的范数使其不要太大，所以可以在一定程度上减少过拟合情况。 image-20201205175236273 内容来自： 正则化方法：L1和L2 regularization、数据集扩增、dropout 5.2.8. Learning Rate Decay 当我们选择了一个合适的lr，但是损失训练到一定程度以后就不再下降了，就在一个区间中来回动荡，可能是出现了一下的问题： image-20201205175605729 对这种问题的解决就是通过学习率衰减来实现的：将学习率随着训练的进行来进行衰减，这个方法就比较直观了。具体的方法描述可以在 ../project_note/训练参数调整策略.md中找到。 也可以参考如下连接：详细理解pytorch的六种学习率pytorch 5.3. 损失函数 nn中自带的Loss Function比如说MSE之类的，计算出来的值本身就已经对batch取了平均值，同时我们进行交叉熵的计算的时候，我们不需要实现对他进行softmax，因为再CE中已经集成了softmax的操作。 5.3.1. CrossEntropy交叉熵 这里会介绍一下Pytorch中的CE损失的具体实现的方法，这里给出三种方式的对比。 import torch # initial data and calculate method input_x = torch.randn((4,5)) label = torch.tensor((1,2,3,4)) cri = torch.nn.CrossEntropyLoss() nll_f = torch.nn.NLLLoss() # output softmax and logsoftmax and pred softamx_x = torch.softmax(input_x,dim=1) logsoftmax_x = torch.log(softamx_x) print(\"softamx_x \\n\", softamx_x) print(\"pre_res \\n\", softamx_x.argmax(axis=1)) print(\"log_softamx_x \\n\", logsoftmax_x) # calculate official ce and NLL print(\"torch ce \\n\",cri(input_x,label)) print(\"nll_cal \\n\", nll_f(logsoftmax_x,label)) # calculate the manual ce loss we cal res = [-logsoftmax_x[i][label[i]] for i in range(len(label))] print(\"manual cal \\n\",sum(res)/len(label)) 可以发现三种方式计算出来的损失是一样的，这就说明了我们在计算的时候要记住，ce中是自己集成了softmax的操作，同时在Nll中是存在了取negative的操作的。按照这个操作手册去实现自己相应的损失函数设计 5.4. 模型参数初始化和架构查看方法 实际上对参数初始化也就是需要对整体的架构进行遍历，所以这两个会归为一个子课题 参数的初始化方法只要使用如下的方式，无论我们采取那种定义的方式，，都能遍历到其中所包含的所有网络层 # 如果直接在网络定义的时候直接进行初始化 for m in self.modules(): if isinstance(m,nn.Conv2d): nn.init.kaiming_normal_(m.weight,mode='fan_out') if isinstance(m,nn.BatchNorm2d): nn.init.constant_(m.weight,1) nn.init.constant_(m.bias,1) # 如果是在模型定义的外部的话 for layer in model.modules(): if isinstance(layer, torch.nn.Conv2d): torch.nn.init.kaiming_normal_(layer.weight,mode='fan_out', nonlinearity='relu') if layer.bias isnotNone: torch.nn.init.constant_(layer.bias, val=0.0) elif isinstance(layer, torch.nn.BatchNorm2d): torch.nn.init.constant_(layer.weight, val=1.0) torch.nn.init.constant_(layer.bias, val=0.0) elif isinstance(layer, torch.nn.Linear): torch.nn.init.xavier_normal_(layer.weight) if layer.bias isnotNone: torch.nn.init.constant_(layer.bias, val=0.0) layer.weight = torch.nn.Parameter(tensor) # 也可以使用其他的方法比如parameters，children 5.4.1. children、modules、parameters： model.modules会遍历model中所有的子层，而children只会遍历当前层，也就是最外层的情况，所以如果要进行参数的初始化的话，最好是用类内或者类外的两种方法来实现初始化 parameter返回的是模型的所有参数，所以初始化最好使用的是`modules，而parameter一般用来初始化参数 用numel与parameters计算参数的个数 #可以简洁的写成下面的形式 #numel()函数本身的作用是返回数组中元素的个数 def count_parameters(model): return sum(P.numel() for P in model.parameters() if P.requires_grad) #帮助理解的结构形式可以表达如下： def count_parameters(model): for p in model.parameters(): if p.requires_grad: ans += p.numel() 5.4.2. 初始化原则：（继续调研） pytorch中的参数初始化方法总结_ys1305的博客-CSDN博客_pytorch 参数初始化 Batch-Normalization：Batch Normalization详解 - shine-lee - 博客园 (cnblogs.com) conv：kaming_normal_ fc：constan_,xvaier bn：normal_\\constant| 5.4.3. 典型的参数初始化方法 EnAET中可以看到参考的源码如下，需要注意的是，BN中只有两个参数，所以不需要进行参数的初始化，或者直接置0、1即可. for m in self.modules(): if isinstance(m,nn.Conv2d): # 计算参数 n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels m.weight.data.normal_(0,math.sqrt(2. / n)) elif isinstance(m,nn.BatchNorm2d): m.weight.data.fill_(1) m.bias.data.zero_() elif isinstance(m, nn.Linear): nn.init.xavier_normal_(m.weight.data) # what's this method m.bias.data.zero_() 5.5. 数据类型和维度 在算法编写的过程中，数据的类型和维度的对齐和channel是很重要的，在这里也很容易出现很多的bug，在这里做一个信息的汇总 5.5.1. 输入数据的通道 结论：pytorch网络输入图片的shape要求通道是channel_first（通道在前）的，所以如果我们的图片不是这样的话，我们就需要执行相应的变化。 TODO：整理各种数据读取方式读入的channel first 或是 last : skimage,PIL,numpy 整理相应的各种数据类型进行transpose（numpy）的方式 # 也可以使用view函数，但是相应的，view需要计算出各个维度相应的数值 # view（）直接使用的时候不改变原值的大小，permute也不改变，使用的方法不同而已 if img.shape[-1] == 3: img = img.permute(0,3,1,2) 5.5.2. 标签的形式转换one-hot 进行训练之前要将数据转化为onehot的形式，才能输入训练，而且一般因为是batch_size的形式，所以我们需要转化为矩阵形式的onehot，不能用单个label的转化方法。 def make_onehot_single(num,index): '''根据类别数量和index生成single，onehot''' # BTW：scatter方法也能生成one-hot onehot = torch.zeros(num) onehot[index] = 1.0 return onehot # 主要是下面这种方法需要掌握， def make_onehot_array(width,target): '''根据label生成onehot矩阵。 width：类别数 target：具体的labeldata''' try: length = len(target.view(-1,1)) except ValueError: print('the type of target is {} '.format(type(target))) print(target) raise Exception('break down') onehot = torch.zeros(length, width).scatter_(1,target.view(-1,1),1) return onehot 6. Visualize 可视化部分 6.1. Tensorboard in Pytorch @Aiken H 2021 review 之前这一部分的projection和model都没有成功显示，这次在新框架中展示一下。 Visualizing Models, Data, and Training with TensorBoard - PyTorch Tutorials 1.8.1+cu102 documentation 详解PyTorch项目使用TensorboardX进行训练可视化_浅度寺-CSDN博客_tensorboardx 在pytorch教程中的Projection可以结合后续输出的Feature使用来分析相应的聚类和分类可靠性 可以尝试使用，教程写的很简单易懂。 存在问题：Graph的无法显示，只有两个框框，后续进行修改吧，在本地试一下tensorboardX,很担心之后Projection也会出现一样的问题，会的话就自己绘图吧。可以去tensorboadX官网下demo来试一下。 6.1.1. Histogram 直方图参数统计 一般来说用来统计模型中间的一些参数的分布情况，具体的使用在训练的epoch之间，和val是一个比较类似的机制，具体的代码样例如下： # visualize those parameter as historgram # we can add other model here if i % 10 == 0: for name,param in self.main_model.named_parameters(): self.writer.add_histogram('main_model'+name,param.clone().cpu().data.numpy(),i) pass 6.2. Embedding Projection @Aiken H 2021 这一部分可能才是神经网络的特征分布的可视化图。 下面这个是Google的Embedding Projection，需要上传.tsv保存的数据，但是实际上就是Tensorboard上也有集成的功能 Embedding projector - visualization of high-dimensional data Visualizing Data using the Embedding Projector in TensorBoard 6.3. 可视化神经网络热力图（CAM） @Aiken2020 为了便于查看神经网络的输出，对于图像的哪一部分更加的侧重，也就是指导网络进行分类的主要是图像的哪些区域，（相应的也可以按照类似的方法查看Attention Network的效果把），就想着可视化一下CAM。看指导分类的高响应区域是否落在核心区域。 参考链接： CAM Pytorch 6.3.1. 算法原理 其计算方法如下图所示。对于一个CNN模型，对其最后一个featuremap做全局平均池化（GAP）计算各通道均值，然后通过FC层等映射到class score，找出argmax，计算最大的那一类的输出相对于最后一个featuremap的梯度（实际上就是最后一个map中哪些对于分类的变化其更大的作用，也就是类似权重的机制），再把这个梯度可视化到原图上即可。直观来说，就是看一下网络抽取到的高层特征的哪部分对最终的classifier影响更大。 img Quote: 找到了一篇基于Keras的CAM实现，感谢： https://blog.csdn.net/Einstellung/article/details/82858974 但是我还是习惯用Pytorch一点，所以参考着改了一版Pytorch的实现。其中，有一个地方困扰了一下，因为Pytorch的自动求导机制，一般只会保存函数值对输入的导数值，而中间变量的导数值都没有保留，而此处我们需要计算输出层相对于最后一个feature map梯度，所以参考https://blog.csdn.net/qq_27061325/article/details/84728539解决了该问题。 6.3.2. 代码实现： import os from PIL import Image import torch import numpy as np import cv2 import matplotlib.pyplot as plt def draw_CAM(model, img_path, save_path, transform=None, visual_heatmap=False): ''' 绘制 Class Activation Map :param model: 加载好权重的Pytorch model :param img_path: 测试图片路径 :param save_path: CAM结果保存路径 :param transform: 输入图像预处理方法 :param visual_heatmap: 是否可视化原始heatmap（调用matplotlib） :return: ''' # 图像加载&预处理 img = Image.open(img_path).convert('RGB') if transform: img = transform(img) img = img.unsqueeze(0) # 获取模型输出的feature/score model.eval() features = model.features(img) output = model.classifier(features) # 为了能读取到中间梯度定义的辅助函数 def extract(g): global features_grad features_grad = g # 预测得分最高的那一类对应的输出score pred = torch.argmax(output).item() pred_class = output[:, pred] features.register_hook(extract) pred_class.backward() # 计算梯度 grads = features_grad # 获取梯度 pooled_grads = torch.nn.functional.adaptive_avg_pool2d(grads, (1, 1)) # 此处batch size默认为1，所以去掉了第0维（batch size维） pooled_grads = pooled_grads[0] features = features[0] # 512是最后一层feature的通道数 for i in range(512): features[i, ...] *= pooled_grads[i, ...] # 以下部分同Keras版实现 heatmap = features.detach().numpy() heatmap = np.mean(heatmap, axis=0) heatmap = np.maximum(heatmap, 0) heatmap /= np.max(heatmap) # 可视化原始热力图 if visual_heatmap: plt.matshow(heatmap) plt.show() img = cv2.imread(img_path) # 用cv2加载原始图像 heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0])) # 将热力图的大小调整为与原始图像相同 heatmap = np.uint8(255 * heatmap) # 将热力图转换为RGB格式 heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) # 将热力图应用于原始图像 superimposed_img = heatmap * 0.4 + img # 这里的0.4是热力图强度因子 cv2.imwrite(save_path, superimposed_img) # 将图像保存到硬盘 7. DEBUG 7.1. 1.ImportError: cannot import name 'PILLOW_VERSION' PIL版本过高，换低就可以，他不配是一个棘手的问题 pip install Pillow==6.2.2 --user 7.2. 2.模型参数&计算量统计 and Debug输出 用来计算模型构建中网络的参数，空间大小，MAdd，FLOPs等指标，count_params很好写，然后剩下的计算我们交给两个第三方的库来实现：torchstat,thop from torchstat import stat stat(model,(3,224,224)) #that‘s all using it in the eval stage 也可以使用torchsummary来查看各层输出的数据的维度数目 from torchsummary import summary summary(model.cuda(),input_size=(3,224,224),batch_size=1) 相应的Debug还可以使用torchsnooper进行：变量的类型和维度追踪这个模块通过@xxxx修饰器的方法调用在指定的method前面，能够在训练过程中输出一些参数值的类型和数值变化的较为详细的信息。个人理解的最佳使用环境是，用于调试或者监控类型之间的错误。 # 这个package如果没记错的话好像是使用装饰器的方法去进行测试 @... method() 7.3. 3.PyTorch加载预训练模型 具体错误：在于模型Dict中的Key和预训练model中的Key不对应，无法匹配。 Unexpected key(s) in state_dict: \"module.features. ...\".，Expected \".features....\" 问题分析： situation1：可以看到前面多了module这个str，这一般是由于其中一方使用了多GPU训练后直接保存的，也就是DataParallel模式下导致的不匹配问题。 solution1： 参考资料 load模型后去掉多余的参数在事先的时候发现这个方法还是存在问题的，并不是简单的dict封装的结构，所以没法这样简单的进行赋值处理:x: 用空白代替module，暂时还没尝试，但是我觉得会遇到和第一个一样的问题:x: :zap:最简单的方法：加载模型后将模型进行DataParallel，再进行数据的转化，将数据进行并行化。具体的操作如下 model.cuda() # 将ids设置成拥有的GPU即可，但是不知道单GPU的情况可不可以实现这种情况 model = nn.DataParallel(model, device_ids=None) Situation2： 保存模型格式为.pth.tar，无法载入训练好的模型 Solution2： 原因是因为被保存的模型是在高版本的pytorch下实现的，但是再低版本中读取的模型是.pth格式的，就会出现版本冲突。 解决方法如下&#x1F447;： # 在高版本的环境中load model，然后再重新保存，保存的时候添加参数，使得保存成旧版本即可 torch.save(checkpoint,save_path,_use_new_zipfile_serialization=False) # DONE xxx is a zip archive(did you mean to use torch.jit.load()?) 使用低版本的Torch去Load高版本（>1.6）保存的模型（.pth.tar）遇到的问题, 这种错误，主要是模型的版本冲突。 解决办法：在高版本的环境中，重新load模型，然后直接save，在保存的时候添加参数 torch.save(model.state_dict(),model_path,_use_new_zipfile_serialization=False) 就可以保存成.pth的模型，也能在低版本的torch环境中使用了 7.4. 4.some of the strides of a given numpy array are negative. ver：torch1.2 这个问题可能会在后续的版本中被优化。 Situation： https://www.cnblogs.com/devilmaycry812839668/p/13761613.html 问题出现在flat操作中，反向切片[::-1]会导致数据存储在内存上不连续，在旧版本中无法实现，对这样数据进行存储。 Solution1: 所以在执倒排切片的时候执行，img2 = np.ascontiguousarray(img) 使得数据在内存空间上连续。 Solution2: 或者执行倒排切片的时候，直接return img.copy() 7.5. 5.读取loader的时候图像的大小不一 使用Crop对图像进行处理的时候，不注意的话就是会出现这样的问题，图像的size随机改变，导致的输出不统一。也可能是Crop函数写的有问题。 bug info如下 $ RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 182 and 360 in dimension 2 Solution： resize，spp，padding，adaptiveMaxPooling（自适应的pooling，pooling到指定的size（channel除外）） 7.6. 6.bus error dataloader num_worker 原因暂时还不是太清楚，但是我们可以把num_worker设置为0 来解决这个问题.jpg 7.7. 7.bus error：insufficient shared memory（shm） 这种原因通常会在docker环境中出现，由于未指定shm容量大小，比如ipc=host之类的命令，就会导致docker的shm只有64m，于是在运行的时候就会出问题。这种情况下只能重新run docker（目前只找到了这个方法）。 如果要妥协的话，就只能试着减小batch_size。但是随着模型的设计上，这其实不是一个可以逃避的问题，也会增加莫须有的其他成本，所以。 7.8. 8.训练过程中Cache和Memory的占用逐渐升高 主要的体现是：逐渐升高这一点，而不是稳定的情况； 有点玄学，但是在这种情况下，我们在每个iteration结束的时候使用清楚显存的函数，竟然就能进行控制了，虽然我不知道为啥清楚显存的函数会顺便连内存中的cache也一起清除了，但是就是，学。 torch.cuda.empty_cache() 7.9. 9.梯度爆炸问题，算法没有学习效果 梯度爆炸问题，分析可能出现存在的问题： 某一部分的学习参数可能的lr过高，权重过高，导致误差快速传播。 问题的复杂度过高，算法overpower了把。 针对于第一点的话，我们参考工程笔记中的学习率调整策略即可。 如果是问题的复杂度过高，那么可能是问题对于我们的模型来说已经overpower的，我们可能需要去加深网络的层数，或者对网络进行进一步的设计和对数据的分析问题。 7.10. 10.类型转换问题汇总 比如scatter_需要将数据从int32的格式转换成int64，我们要掌握一下在Pytorch中进行数据类型转换的技巧。 Expected object of scalar type Float but got scalar type Double for argument #2 'target' 数据类型不匹配，一个是np.float32,另一个是64 参考解决方案：重要 Expected object of scalar type Long but got scalar type Float for argument 希望得到的是Long型标量数据，但是得到了Float型的数据（实际上可能是我们进行测试的时候使用了小数带来的，但是我们也能将其转化就是了） Longtensor() type(torch.longtensor) RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.DoubleTensor) should be the same RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same问题实际上都是和权重的数据类型不匹配，需要将字节型或者是FLoat型向Weight的数据类型转换，但是可能这里的问题实际上出现在就是我们导入的数据类型是不正确的。还是使用type()命令来进行数据类型的转换，但是关键还是：检查输入数据的类型以及数值范围，同时看看在进行dataloader的时候有没有指定to_tensor的变换等等 参考资料链接 进行数据转换的几种方式 使用函数tensor1.type_as(tensor2)将1的数据类型转换成2的数据类型。 tensor_1 = torch.FloatTensor(5) tensor_2 = torch.IntTensor([10, 20]) tensor_1 = tensor_1.type_as(tensor_2) tensor.type(torch.IntTensor) tensor.long(),tensor.char(),tensor.int(),tensor.byte(),tensor.double() tenosr.to(torch.long) 7.11. 11.数据维度不对应问题汇总 multi-target not supported at问题实际上可以翻译成：维度上和交叉熵损失函数的需求不对应。在使用交叉熵损失函数的时候，target的形状应该是和label的形状一致或者是只有batchsize这一个维度的。如果target是这样的【batchszie，1】就会出现上述的错误 使用squeeze（）函数降低维度 7.12. 12.取出具体数值时候的问题 RuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy()对于输出的结果要转换成具体的数值的时候，如果我们后续还需要这个数值的梯度，就不能转换到cpu后再转换到numpy,就好比说，我们要取出Loss的时候，我们可以直接使用item()取出具体的数值，而不需要转到CPU上 7.13. 13.CPU占用99% 问题描述：使用torch自带的dataset中的cifar10的时候，在每个epoch结束的时候，CPU占用率高达99%，并不随着num_workder而改变，问题可能由于pytorch开辟了太多的线程 windows10下pytorch的GPU利用率低，占用率低_stay_zezo的博客-CSDN博客 可能是由于GPU运算太快了，启用了多线程进行加载数据，这种时候启用pin_memory=true 能起到一定的作用把，加快一点数据读取。 最终解决方案 ：pin-memory=false 反正原因很神奇，但是最终就是因为这个解决的，可能是因为memory超了，所以每次都需要重新empty_cache 重新装进页，所以反而加重了CPU的负担 7.14. 14. 预测值全为0，模型收敛到奇怪的地方，损失保持一致（全均等） 这种情况通常是由于模型设计中存在一点问题： 比如这次是由于模型中fc后面添加了relu，这样导致输出的负值全被抑制了，导致学习出现了严重的错误后果。 7.15. 15.模型部分： 训练中模型准确率不上升 由于框架已经验证过是可以进行正常训练的，在这种情况下出现模型的准确率不上升可能是由于模型本身设计（内部代码编写）上的问题。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Langs/PythonTips.html":{"url":"Langs/PythonTips.html","title":"L4:PythonTips","keywords":"","body":"1. What the f*ck Python! &#x1F40D;2. Table of Contents/目录3. Structure of the Examples/示例结构4. Usage/用法5. &#x1F440; Examples/示例5.1. Section: Strain your brain!/大脑运动!5.1.1. > Strings can be tricky sometimes/微妙的字符串 *5.1.2. > Time for some hash brownies!/是时候来点蛋糕了!5.1.3. > Return return everywhere!/到处返回！5.1.4. > Deep down, we're all the same./本质上,我们都一样. *5.1.5. > For what?/为什么?5.1.6. > Evaluation time discrepancy/执行时机差异5.1.7. > is is not what it is!/出人意料的is!5.1.8. > A tic-tac-toe where X wins in the first attempt!/一蹴即至!5.1.9. > The sticky output function/麻烦的输出5.1.10. > is not ... is not is (not ...)/is not ... 不是 is (not ...)5.1.11. > The surprising comma/意外的逗号5.1.12. > Backslashes at the end of string/字符串末尾的反斜杠5.1.13. > not knot!/别纠结!5.1.14. > Half triple-quoted strings/三个引号5.1.15. > Midnight time doesn't exist?/不存在的午夜?5.1.16. > What's wrong with booleans?/布尔你咋了?5.1.17. > Class attributes and instance attributes/类属性和实例属性5.1.18. > yielding None/生成 None5.1.19. > Mutating the immutable!/强人所难5.1.20. > The disappearing variable from outer scope/消失的外部变量5.1.21. > When True is actually False/真亦假5.1.22. > From filled to None in one instruction.../从有到无...5.1.23. > Subclass relationships/子类关系 *5.1.24. > The mysterious key type conversion/神秘的键型转换 *5.1.25. > Let's see if you can guess this?/看看你能否猜到这一点?5.2. Section: Appearances are deceptive!/外表是靠不住的!5.2.1. > Skipping lines?/跳过一行?5.2.2. > Teleportation/空间移动 *5.2.3. > Well, something is fishy.../嗯，有些可疑...5.3. Section: Watch out for the landmines!/小心地雷!5.3.1. > Modifying a dictionary while iterating over it/迭代字典时的修改5.3.2. > Stubborn del operator/坚强的 del *5.3.3. > Deleting a list item while iterating/迭代列表时删除元素5.3.4. > Loop variables leaking out!/循环变量泄漏!5.3.5. > Beware of default mutable arguments!/当心默认的可变参数!5.3.6. > Catching the Exceptions/捕获异常5.3.7. > Same operands, different story!/同人不同命!5.3.8. > The out of scope variable/外部作用域变量5.3.9. > Be careful with chained operations/小心链式操作5.3.10. > Name resolution ignoring class scope/忽略类作用域的名称解析5.3.11. > Needle in a Haystack/大海捞针5.4. Section: The Hidden treasures!/隐藏的宝藏!5.4.1. > Okay Python, Can you make me fly?/Python, 可否带我飞? *5.4.2. > goto, but why?/goto, 但为什么? *5.4.3. > Brace yourself!/做好思想准备 *5.4.4. > Let's meet Friendly Language Uncle For Life/让生活更友好 *5.4.5. > Even Python understands that love is complicated/连Python也知道爱是难言的 *5.4.6. > Yes, it exists!/是的, 它存在!5.4.7. > Inpinity/无限 *5.4.8. > Mangling time!/修饰时间! *5.5. Section: Miscellaneous/杂项5.5.1. > += is faster/更快的 +=5.5.2. > Let's make a giant string!/来做个巨大的字符串吧！5.5.3. > Explicit typecast of strings/字符串的显式类型转换5.5.4. > Minor Ones/小知识点6. Contributing/贡献7. Acknowledgements/致谢8. &#x1F393; License/许可8.1. Help/帮助8.2. Surprise your geeky pythonist friends?/想给你的极客朋友一个惊喜?8.3. Need a pdf version?/需要来一份pdf版的?8.4. Follow Commit/追踪Commit8.5. 996.icu 1. What the f*ck Python! &#x1F40D; 一些有趣且鲜为人知的 Python 特性. English | 中文 Python, 是一个设计优美的解释型高级语言, 它提供了很多能让程序员感到舒适的功能特性. 但有的时候, Python 的一些输出结果对于初学者来说似乎并不是那么一目了然. 这个有趣的项目意在收集 Python 中那些难以理解和反人类直觉的例子以及鲜为人知的功能特性, 并尝试讨论这些现象背后真正的原理! 虽然下面的有些例子并不一定会让你觉得 WTFs, 但它们依然有可能会告诉你一些你所不知道的 Python 有趣特性. 我觉得这是一种学习编程语言内部原理的好办法, 而且我相信你也会从中获得乐趣! 如果您是一位经验比较丰富的 Python 程序员, 你可以尝试挑战看是否能一次就找到例子的正确答案. 你可能对其中的一些例子已经比较熟悉了, 那这也许能唤起你当年踩这些坑时的甜蜜回忆 :sweat_smile: PS: 如果你不是第一次读了, 你可以在这里获取变动内容. 那么, 让我们开始吧... 2. Table of Contents/目录 Table of Contents/目录 Structure of the Examples/示例结构 Usage/用法 &#x1F440; Examples/示例 Section: Strain your brain!/大脑运动! > Strings can be tricky sometimes/微妙的字符串 * > Time for some hash brownies!/是时候来点蛋糕了! > Return return everywhere!/到处返回！ > Deep down, we're all the same./本质上,我们都一样. * > For what?/为什么? > Evaluation time discrepancy/执行时机差异 > is is not what it is!/出人意料的is! > A tic-tac-toe where X wins in the first attempt!/一蹴即至! > The sticky output function/麻烦的输出 > is not ... is not is (not ...)/is not ... 不是 is (not ...) > The surprising comma/意外的逗号 > Backslashes at the end of string/字符串末尾的反斜杠 > not knot!/别纠结! > Half triple-quoted strings/三个引号 > Midnight time doesn't exist?/不存在的午夜? > What's wrong with booleans?/布尔你咋了? > Class attributes and instance attributes/类属性和实例属性 > yielding None/生成 None > Mutating the immutable!/强人所难 > The disappearing variable from outer scope/消失的外部变量 > When True is actually False/真亦假 > From filled to None in one instruction.../从有到无... > Subclass relationships/子类关系 * > The mysterious key type conversion/神秘的键型转换 * > Let's see if you can guess this?/看看你能否猜到这一点? Section: Appearances are deceptive!/外表是靠不住的! > Skipping lines?/跳过一行? > Teleportation/空间移动 * > Well, something is fishy.../嗯, 有些可疑... Section: Watch out for the landmines!/小心地雷! > Modifying a dictionary while iterating over it/迭代字典时的修改 > Stubborn del operator/坚强的 del * > Deleting a list item while iterating/迭代列表时删除元素 > Loop variables leaking out!/循环变量泄漏! > Beware of default mutable arguments!/当心默认的可变参数! > Catching the Exceptions/捕获异常 > Same operands, different story!/同人不同命! > The out of scope variable/外部作用域变量 > Be careful with chained operations/小心链式操作 > Name resolution ignoring class scope/忽略类作用域的名称解析 > Needle in a Haystack/大海捞针 Section: The Hidden treasures!/隐藏的宝藏! > Okay Python, Can you make me fly?/Python, 可否带我飞? * > goto, but why?/goto, 但为什么? * > Brace yourself!/做好思想准备 * > Let's meet Friendly Language Uncle For Life/让生活更友好 * > Even Python understands that love is complicated/连Python也知道爱是难言的 * > Yes, it exists!/是的, 它存在! > Inpinity/无限 * > Mangling time!修饰时间! * Section: Miscellaneous/杂项 > += is faster/更快的 += > Let's make a giant string!/来做个巨大的字符串吧! > Explicit typecast of strings/字符串的显式类型转换 > Minor Ones/小知识点 Contributing/贡献 Acknowledgements/致谢 &#x1F393; License/许可 Help/帮助 Surprise your geeky pythonist friends?/想给你的极客朋友一个惊喜? Need a pdf version?/需要来一份pdf版的? Follow Commit/追踪Commit 996.icu 3. Structure of the Examples/示例结构 所有示例的结构都如下所示: > 一个精选的标题 * 标题末尾的星号表示该示例在第一版中不存在，是最近添加的. # 准备代码. # 释放魔法... Output (Python version): >>> 触发语句 出乎意料的输出结果 (可选): 对意外输出结果的简短描述. &#x1F4A1; 说明: 简要说明发生了什么以及为什么会发生.如有必要, 举例说明 Output:>>> 触发语句 # 一些让魔法变得容易理解的例子 # 一些正常的输入 注意: 所有的示例都在 Python 3.5.2 版本的交互解释器上测试过, 如果不特别说明应该适用于所有 Python 版本. 4. Usage/用法 我个人建议, 最好依次阅读下面的示例, 并对每个示例: 仔细阅读设置例子最开始的代码. 如果您是一位经验丰富的 Python 程序员, 那么大多数时候您都能成功预期到后面的结果. 阅读输出结果, 确认结果是否如你所料. 确认你是否知道这背后的原理. 如果不知道, 深呼吸然后阅读说明 (如果你还是看不明白, 别沉默! 可以在这提个 issue). 如果知道, 给自己点奖励, 然后去看下一个例子. PS: 你也可以在命令行阅读 WTFpython. 我们有 pypi 包 和 npm 包(支持代码高亮).(译: 这两个都是英文版的) 安装 npm 包 wtfpython $ npm install -g wtfpython 或者, 安装 pypi 包 wtfpython $ pip install wtfpython -U 现在, 在命令行中运行 wtfpython, 你就可以开始浏览了. 5. &#x1F440; Examples/示例 5.1. Section: Strain your brain!/大脑运动! 5.1.1. > Strings can be tricky sometimes/微妙的字符串 * 1. >>> a = \"some_string\" >>> id(a) 140420665652016 >>> id(\"some\" + \"_\" + \"string\") # 注意两个的id值是相同的. 140420665652016 2. >>> a = \"wtf\" >>> b = \"wtf\" >>> a is b True >>> a = \"wtf!\" >>> b = \"wtf!\" >>> a is b False >>> a, b = \"wtf!\", \"wtf!\" >>> a is b True # 3.7 版本返回结果为 False. 3. >>> 'a' * 20 is 'aaaaaaaaaaaaaaaaaaaa' True >>> 'a' * 21 is 'aaaaaaaaaaaaaaaaaaaaa' False # 3.7 版本返回结果为 True 很好理解, 对吧? &#x1F4A1; 说明: 这些行为是由于 Cpython 在编译优化时, 某些情况下会尝试使用已经存在的不可变对象而不是每次都创建一个新对象. (这种行为被称作字符串的驻留[string interning]) 发生驻留之后, 许多变量可能指向内存中的相同字符串对象. (从而节省内存) 在上面的代码中, 字符串是隐式驻留的. 何时发生隐式驻留则取决于具体的实现. 这里有一些方法可以用来猜测字符串是否会被驻留: 所有长度为 0 和长度为 1 的字符串都被驻留. 字符串在编译时被实现 ('wtf' 将被驻留, 但是 ''.join(['w', 't', 'f']) 将不会被驻留) 字符串中只包含字母，数字或下划线时将会驻留. 所以 'wtf!' 由于包含 ! 而未被驻留. 可以在这里找到 CPython 对此规则的实现. 当在同一行将 a 和 b 的值设置为 \"wtf!\" 的时候, Python 解释器会创建一个新对象, 然后同时引用第二个变量(译: 仅适用于3.7以下, 详细情况请看这里). 如果你在不同的行上进行赋值操作, 它就不会“知道”已经有一个 wtf！ 对象 (因为 \"wtf!\" 不是按照上面提到的方式被隐式驻留的). 它是一种编译器优化, 特别适用于交互式环境. 常量折叠(constant folding) 是 Python 中的一种 窥孔优化(peephole optimization) 技术. 这意味着在编译时表达式 'a'*20 会被替换为 'aaaaaaaaaaaaaaaaaaaa' 以减少运行时的时钟周期. 只有长度小于 20 的字符串才会发生常量折叠. (为啥? 想象一下由于表达式 'a'*10**10 而生成的 .pyc 文件的大小). 相关的源码实现在这里. 如果你是使用 3.7 版本中运行上述示例代码, 会发现部分代码的运行结果与注释说明相同. 这是因为在 3.7 版本中, 常量折叠已经从窥孔优化器迁移至新的 AST 优化器, 后者可以以更高的一致性来执行优化. (由 Eugene Toder 和 INADA Naoki 在 bpo-29469 和 bpo-11549 中贡献.) (译: 但是在最新的 3.8 版本中, 结果又变回去了. 虽然 3.8 版本和 3.7 版本一样, 都是使用 AST 优化器. 目前不确定官方对 3.8 版本的 AST 做了什么调整.) 5.1.2. > Time for some hash brownies!/是时候来点蛋糕了! hash brownie指一种含有大麻成分的蛋糕, 所以这里是句双关 1. some_dict = {} some_dict[5.5] = \"Ruby\" some_dict[5.0] = \"JavaScript\" some_dict[5] = \"Python\" Output: >>> some_dict[5.5] \"Ruby\" >>> some_dict[5.0] \"Python\" >>> some_dict[5] \"Python\" \"Python\" 消除了 \"JavaScript\" 的存在? &#x1F4A1; 说明: Python 字典通过检查键值是否相等和比较哈希值来确定两个键是否相同. 具有相同值的不可变对象在Python中始终具有相同的哈希值.>>> 5 == 5.0 True >>> hash(5) == hash(5.0) True 注意: 具有不同值的对象也可能具有相同的哈希值（哈希冲突）. 当执行 some_dict[5] = \"Python\" 语句时, 因为Python将 5 和 5.0 识别为 some_dict 的同一个键, 所以已有值 \"JavaScript\" 就被 \"Python\" 覆盖了. 这个 StackOverflow的 回答 漂亮地解释了这背后的基本原理. 5.1.3. > Return return everywhere!/到处返回！ def some_func(): try: return 'from_try' finally: return 'from_finally' Output: >>> some_func() 'from_finally' &#x1F4A1; 说明: 当在 \"try...finally\" 语句的 try 中执行 return, break 或 continue 后, finally 子句依然会执行. 函数的返回值由最后执行的 return 语句决定. 由于 finally 子句一定会执行, 所以 finally 子句中的 return 将始终是最后执行的语句. 5.1.4. > Deep down, we're all the same./本质上,我们都一样. * class WTF: pass Output: >>> WTF() == WTF() # 两个不同的对象应该不相等 False >>> WTF() is WTF() # 也不相同 False >>> hash(WTF()) == hash(WTF()) # 哈希值也应该不同 True >>> id(WTF()) == id(WTF()) True &#x1F4A1; 说明: 当调用 id 函数时, Python 创建了一个 WTF 类的对象并传给 id 函数. 然后 id 函数获取其id值 (也就是内存地址), 然后丢弃该对象. 该对象就被销毁了. 当我们连续两次进行这个操作时, Python会将相同的内存地址分配给第二个对象. 因为 (在CPython中) id 函数使用对象的内存地址作为对象的id值, 所以两个对象的id值是相同的. 综上, 对象的id值仅仅在对象的生命周期内唯一. 在对象被销毁之后, 或被创建之前, 其他对象可以具有相同的id值. 那为什么 is 操作的结果为 False 呢? 让我们看看这段代码. class WTF(object): def __init__(self): print(\"I\") def __del__(self): print(\"D\") Output: >>> WTF() is WTF() I I D D False >>> id(WTF()) == id(WTF()) I D I D True 正如你所看到的, 对象销毁的顺序是造成所有不同之处的原因. 5.1.5. > For what?/为什么? some_string = \"wtf\" some_dict = {} for i, some_dict[i] in enumerate(some_string): pass Output: >>> some_dict # 创建了索引字典. {0: 'w', 1: 't', 2: 'f'} &#x1F4A1; 说明: Python 语法 中对 for 的定义是: for_stmt: 'for' exprlist 'in' testlist ':' suite ['else' ':' suite] 其中 exprlist 指分配目标. 这意味着对可迭代对象中的每一项都会执行类似 {exprlist} = {next_value} 的操作. 一个有趣的例子说明了这一点: for i in range(4): print(i) i = 10 Output: 0 1 2 3 你可曾觉得这个循环只会运行一次? &#x1F4A1; 说明: 由于循环在Python中工作方式, 赋值语句 i = 10 并不会影响迭代循环, 在每次迭代开始之前, 迭代器(这里指 range(4)) 生成的下一个元素就被解包并赋值给目标列表的变量(这里指 i)了. 在每一次的迭代中, enumerate(some_string) 函数就生成一个新值 i (计数器增加) 并从 some_string 中获取一个字符. 然后将字典 some_dict 键 i (刚刚分配的) 的值设为该字符. 本例中循环的展开可以简化为: >>> i, some_dict[i] = (0, 'w') >>> i, some_dict[i] = (1, 't') >>> i, some_dict[i] = (2, 'f') >>> some_dict 5.1.6. > Evaluation time discrepancy/执行时机差异 1. array = [1, 8, 15] g = (x for x in array if array.count(x) > 0) array = [2, 8, 22] Output: >>> print(list(g)) [8] 2. array_1 = [1,2,3,4] g1 = (x for x in array_1) array_1 = [1,2,3,4,5] array_2 = [1,2,3,4] g2 = (x for x in array_2) array_2[:] = [1,2,3,4,5] Output: >>> print(list(g1)) [1,2,3,4] >>> print(list(g2)) [1,2,3,4,5] &#x1F4A1; 说明 在生成器表达式中, in 子句在声明时执行, 而条件子句则是在运行时执行. 所以在运行前, array 已经被重新赋值为 [2, 8, 22], 因此对于之前的 1, 8 和 15, 只有 count(8) 的结果是大于 0 的, 所以生成器只会生成 8. 第二部分中 g1 和 g2 的输出差异则是由于变量 array_1 和 array_2 被重新赋值的方式导致的. 在第一种情况下, array_1 被绑定到新对象 [1,2,3,4,5], 因为 in 子句是在声明时被执行的， 所以它仍然引用旧对象 [1,2,3,4](并没有被销毁). 在第二种情况下, 对 array_2 的切片赋值将相同的旧对象 [1,2,3,4] 原地更新为 [1,2,3,4,5]. 因此 g2 和 array_2 仍然引用同一个对象(这个对象现在已经更新为 [1,2,3,4,5]). 5.1.7. > is is not what it is!/出人意料的is! 下面是一个在互联网上非常有名的例子. >>> a = 256 >>> b = 256 >>> a is b True >>> a = 257 >>> b = 257 >>> a is b False >>> a = 257; b = 257 >>> a is b True &#x1F4A1; 说明: is 和 == 的区别 is 运算符检查两个运算对象是否引用自同一对象 (即, 它检查两个运算对象是否相同). == 运算符比较两个运算对象的值是否相等. 因此 is 代表引用相同, == 代表值相等. 下面的例子可以很好的说明这点,>>> [] == [] True >>> [] is [] # 这两个空列表位于不同的内存地址. False 256 是一个已经存在的对象, 而 257 不是 当你启动Python 的时候, 数值为 -5 到 256 的对象就已经被分配好了. 这些数字因为经常被使用, 所以会被提前准备好. Python 通过这种创建小整数池的方式来避免小整数频繁的申请和销毁内存空间. 引用自 https://docs.python.org/3/c-api/long.html 当前的实现为-5到256之间的所有整数保留一个整数对象数组, 当你创建了一个该范围内的整数时, 你只需要返回现有对象的引用. 所以改变1的值是有可能的. 我怀疑这种行为在Python中是未定义行为. :-) >>> id(256) 10922528 >>> a = 256 >>> b = 256 >>> id(a) 10922528 >>> id(b) 10922528 >>> id(257) 140084850247312 >>> x = 257 >>> y = 257 >>> id(x) 140084850247440 >>> id(y) 140084850247344 这里解释器并没有智能到能在执行 y = 257 时意识到我们已经创建了一个整数 257, 所以它在内存中又新建了另一个对象. 当 a 和 b 在同一行中使用相同的值初始化时，会指向同一个对象. >>> a, b = 257, 257 >>> id(a) 140640774013296 >>> id(b) 140640774013296 >>> a = 257 >>> b = 257 >>> id(a) 140640774013392 >>> id(b) 140640774013488 当 a 和 b 在同一行中被设置为 257 时, Python 解释器会创建一个新对象, 然后同时引用第二个变量. 如果你在不同的行上进行, 它就不会 \"知道\" 已经存在一个 257 对象了. 这是一种特别为交互式环境做的编译器优化. 当你在实时解释器中输入两行的时候, 他们会单独编译, 因此也会单独进行优化. 如果你在 .py 文件中尝试这个例子, 则不会看到相同的行为, 因为文件是一次性编译的. 5.1.8. > A tic-tac-toe where X wins in the first attempt!/一蹴即至! # 我们先初始化一个变量row row = [\"\"]*3 #row i['', '', ''] # 并创建一个变量board board = [row]*3 Output: >>> board [['', '', ''], ['', '', ''], ['', '', '']] >>> board[0] ['', '', ''] >>> board[0][0] '' >>> board[0][0] = \"X\" >>> board [['X', '', ''], ['X', '', ''], ['X', '', '']] 我们有没有赋值过3个 \"X\" 呢？ &#x1F4A1; 说明: 当我们初始化 row 变量时, 下面这张图展示了内存中的情况。 而当通过对 row 做乘法来初始化 board 时, 内存中的情况则如下图所示 (每个元素 board[0], board[1] 和 board[2] 都和 row 一样引用了同一列表.) 我们可以通过不使用变量 row 生成 board 来避免这种情况. (这个issue提出了这个需求.) >>> board = [['']*3 for _ in range(3)] >>> board[0][0] = \"X\" >>> board [['X', '', ''], ['', '', ''], ['', '', '']] 5.1.9. > The sticky output function/麻烦的输出 funcs = [] results = [] for x in range(7): def some_func(): return x funcs.append(some_func) results.append(some_func()) # 注意这里函数被执行了 funcs_results = [func() for func in funcs] Output: >>> results [0, 1, 2, 3, 4, 5, 6] >>> funcs_results [6, 6, 6, 6, 6, 6, 6] 即使每次在迭代中将 some_func 加入 funcs 前的 x 值都不相同, 所有的函数还是都返回6. // 再换个例子 >>> powers_of_x = [lambda x: x**i for i in range(10)] >>> [f(2) for f in powers_of_x] [512, 512, 512, 512, 512, 512, 512, 512, 512, 512] &#x1F4A1; 说明: 当在循环内部定义一个函数时, 如果该函数在其主体中使用了循环变量, 则闭包函数将与循环变量绑定, 而不是它的值. 因此, 所有的函数都是使用最后分配给变量的值来进行计算的. 可以通过将循环变量作为命名变量传递给函数来获得预期的结果. 为什么这样可行? 因为这会在函数内再次定义一个局部变量. funcs = [] for x in range(7): def some_func(x=x): return x funcs.append(some_func) Output: >>> funcs_results = [func() for func in funcs] >>> funcs_results [0, 1, 2, 3, 4, 5, 6] 5.1.10. > is not ... is not is (not ...)/is not ... 不是 is (not ...) >>> 'something' is not None True >>> 'something' is (not None) False &#x1F4A1; 说明: is not 是个单独的二元运算符, 与分别使用 is 和 not 不同. 如果操作符两侧的变量指向同一个对象, 则 is not 的结果为 False, 否则结果为 True. 5.1.11. > The surprising comma/意外的逗号 Output: >>> def f(x, y,): ... print(x, y) ... >>> def g(x=4, y=5,): ... print(x, y) ... >>> def h(x, **kwargs,): File \"\", line 1 def h(x, **kwargs,): ^ SyntaxError: invalid syntax >>> def h(*args,): File \"\", line 1 def h(*args,): ^ SyntaxError: invalid syntax &#x1F4A1; 说明: 在Python函数的形式参数列表中, 尾随逗号并不一定是合法的. 在Python中, 参数列表部分用前置逗号定义, 部分用尾随逗号定义. 这种冲突导致逗号被夹在中间, 没有规则定义它.(译:这一句看得我也很懵逼,只能强翻了.详细解释看下面的讨论帖会一目了然.) 注意: 尾随逗号的问题已经在Python 3.6中被修复了. 而这篇帖子中则简要讨论了Python中尾随逗号的不同用法. 5.1.12. > Backslashes at the end of string/字符串末尾的反斜杠 Output: >>> print(\"\\\\ C:\\\\\") \\ C:\\ >>> print(r\"\\ C:\") \\ C: >>> print(r\"\\ C:\\\") File \"\", line 1 print(r\"\\ C:\\\") ^ SyntaxError: EOL while scanning string literal &#x1F4A1; 说明: 在以 r 开头的原始字符串中, 反斜杠并没有特殊含义.>>> print(repr(r\"wt\\\"f\")) 'wt\\\\\"f' 解释器所做的只是简单的改变了反斜杠的行为, 因此会直接放行反斜杠及后一个的字符. 这就是反斜杠在原始字符串末尾不起作用的原因. 5.1.13. > not knot!/别纠结! x = True y = False Output: >>> not x == y True >>> x == not y File \"\", line 1 x == not y ^ SyntaxError: invalid syntax &#x1F4A1; 说明: 运算符的优先级会影响表达式的求值顺序, 而在 Python 中 == 运算符的优先级要高于 not 运算符. 所以 not x == y 相当于 not (x == y), 同时等价于 not (True == False), 最后的运算结果就是 True. 之所以 x == not y 会抛一个 SyntaxError 异常, 是因为它会被认为等价于 (x == not) y, 而不是你一开始期望的 x == (not y). 解释器期望 not 标记是 not in 操作符的一部分 (因为 == 和 not in 操作符具有相同的优先级), 但是它在 not 标记后面找不到 in 标记, 所以会抛出 SyntaxError 异常. 5.1.14. > Half triple-quoted strings/三个引号 Output: >>> print('wtfpython''') wtfpython >>> print(\"wtfpython\"\"\") wtfpython >>> # 下面的语句会抛出 `SyntaxError` 异常 >>> # print('''wtfpython') >>> # print(\"\"\"wtfpython\") &#x1F4A1; 说明: Python 提供隐式的字符串连接, 例如,>>> print(\"wtf\" \"python\") wtfpython >>> print(\"wtf\" \"\") # or \"wtf\"\"\" wtf ''' 和 \"\"\" 在 Python中也是字符串定界符, Python 解释器在先遇到三个引号的的时候会尝试再寻找三个终止引号作为定界符, 如果不存在则会导致 SyntaxError 异常. 5.1.15. > Midnight time doesn't exist?/不存在的午夜? from datetime import datetime midnight = datetime(2018, 1, 1, 0, 0) midnight_time = midnight.time() noon = datetime(2018, 1, 1, 12, 0) noon_time = noon.time() if midnight_time: print(\"Time at midnight is\", midnight_time) if noon_time: print(\"Time at noon is\", noon_time) Output: ('Time at noon is', datetime.time(12, 0)) midnight_time 并没有被输出. &#x1F4A1; 说明: 在Python 3.5之前, 如果 datetime.time 对象存储的UTC的午夜时间(译: 就是 00:00), 那么它的布尔值会被认为是 False. 当使用 if obj: 语句来检查 obj 是否为 null 或者某些“空”值的时候, 很容易出错. 5.1.16. > What's wrong with booleans?/布尔你咋了? 1. # 一个简单的例子, 统计下面可迭代对象中的布尔型值的个数和整型值的个数 mixed_list = [False, 1.0, \"some_string\", 3, True, [], False] integers_found_so_far = 0 booleans_found_so_far = 0 for item in mixed_list: if isinstance(item, int): integers_found_so_far += 1 elif isinstance(item, bool): booleans_found_so_far += 1 Output: >>> integers_found_so_far 4 >>> booleans_found_so_far 0 2. another_dict = {} another_dict[True] = \"JavaScript\" another_dict[1] = \"Ruby\" another_dict[1.0] = \"Python\" Output: >>> another_dict[True] \"Python\" 3. >>> some_bool = True >>> \"wtf\"*some_bool 'wtf' >>> some_bool = False >>> \"wtf\"*some_bool '' &#x1F4A1; 说明: 布尔值是 int 的子类 >>> isinstance(True, int) True >>> isinstance(False, int) True 所以 True 的整数值是 1, 而 False 的整数值是 0. >>> True == 1 == 1.0 and False == 0 == 0.0 True 关于其背后的原理, 请看这个 StackOverflow 的回答. 5.1.17. > Class attributes and instance attributes/类属性和实例属性 1. class A: x = 1 class B(A): pass class C(A): pass Output: >>> A.x, B.x, C.x (1, 1, 1) >>> B.x = 2 >>> A.x, B.x, C.x (1, 2, 1) >>> A.x = 3 >>> A.x, B.x, C.x (3, 2, 3) >>> a = A() >>> a.x, A.x (3, 3) >>> a.x += 1 >>> a.x, A.x (4, 3) 2. class SomeClass: some_var = 15 some_list = [5] another_list = [5] def __init__(self, x): self.some_var = x + 1 self.some_list = self.some_list + [x] self.another_list += [x] Output: >>> some_obj = SomeClass(420) >>> some_obj.some_list [5, 420] >>> some_obj.another_list [5, 420] >>> another_obj = SomeClass(111) >>> another_obj.some_list [5, 111] >>> another_obj.another_list [5, 420, 111] >>> another_obj.another_list is SomeClass.another_list True >>> another_obj.another_list is some_obj.another_list True &#x1F4A1; 说明: 类变量和实例变量在内部是通过类对象的字典来处理(译: 就是 __dict__ 属性). 如果在当前类的字典中找不到的话就去它的父类中寻找. += 运算符会在原地修改可变对象, 而不是创建新对象. 因此, 在这种情况下, 修改一个实例的属性会影响其他实例和类属性. 5.1.18. > yielding None/生成 None some_iterable = ('a', 'b') def some_func(val): return \"something\" Output: >>> [x for x in some_iterable] ['a', 'b'] >>> [(yield x) for x in some_iterable] at 0x7f70b0a4ad58> >>> list([(yield x) for x in some_iterable]) ['a', 'b'] >>> list((yield x) for x in some_iterable) ['a', None, 'b', None] >>> list(some_func((yield x)) for x in some_iterable) ['a', 'something', 'b', 'something'] &#x1F4A1; 说明: 来源和解释可以在这里找到: https://stackoverflow.com/questions/32139885/yield-in-list-comprehensions-and-generator-expressions 相关错误报告: http://bugs.python.org/issue10544 这个bug在3.7以后的版本中不被推荐使用, 并在3.8中被修复. 因此在3.8中尝试在推导式中使用 yield, 只会得到一个 SyntaxError. 详细内容可以看3.7更新内容, 3.8更新内容. 5.1.19. > Mutating the immutable!/强人所难 some_tuple = (\"A\", \"tuple\", \"with\", \"values\") another_tuple = ([1, 2], [3, 4], [5, 6]) Output: >>> some_tuple[2] = \"change this\" TypeError: 'tuple' object does not support item assignment >>> another_tuple[2].append(1000) # 这里不出现错误 >>> another_tuple ([1, 2], [3, 4], [5, 6, 1000]) >>> another_tuple[2] += [99, 999] TypeError: 'tuple' object does not support item assignment >>> another_tuple ([1, 2], [3, 4], [5, 6, 1000, 99, 999]) 我还以为元组是不可变的呢... &#x1F4A1; 说明: 引用 https://docs.python.org/2/reference/datamodel.html 不可变序列 不可变序列的对象一旦创建就不能再改变. (如果对象包含对其他对象的引用，则这些其他对象可能是可变的并且可能会被修改; 但是，由不可变对象直接引用的对象集合不能更改.) += 操作符在原地修改了列表. 元素赋值操作并不工作, 但是当异常抛出时, 元素已经在原地被修改了. (译: 对于不可变对象, 这里指tuple, += 并不是原子操作, 而是 extend 和 = 两个动作, 这里 = 操作虽然会抛出异常, 但 extend 操作已经修改成功了. 详细解释可以看这里) 5.1.20. > The disappearing variable from outer scope/消失的外部变量 e = 7 try: raise Exception() except Exception as e: pass Output (Python 2.x): >>> print(e) # prints nothing Output (Python 3.x): >>> print(e) NameError: name 'e' is not defined &#x1F4A1; 说明: 出处: https://docs.python.org/3/reference/compound_stmts.html#except 当使用 as 为目标分配异常的时候, 将在except子句的末尾清除该异常. 这就好像 except E as N: foo 会被翻译成 except E as N: try: foo finally: del N 这意味着异常必须在被赋值给其他变量才能在 except 子句之后引用它. 而异常之所以会被清除, 则是由于上面附加的回溯信息(trackback)会和栈帧(stack frame)形成循环引用, 使得该栈帧中的所有本地变量在下一次垃圾回收发生之前都处于活动状态.(译: 也就是说不会被回收) 子句在 Python 中并没有独立的作用域. 示例中的所有内容都处于同一作用域内, 所以变量 e 会由于执行了 except 子句而被删除. 而对于有独立的内部作用域的函数来说情况就不一样了. 下面的例子说明了这一点: def f(x): del(x) print(x) x = 5 y = [5, 4, 3] Output: >>>f(x) UnboundLocalError: local variable 'x' referenced before assignment >>>f(y) UnboundLocalError: local variable 'x' referenced before assignment >>> x 5 >>> y [5, 4, 3] 在 Python 2.x 中, Exception() 实例被赋值给了变量 e, 所以当你尝试打印结果的时候, 它的输出为空.（译: 正常的Exception实例打印出来就是空） Output (Python 2.x): >>> e Exception() >>> print e # 没有打印任何内容! 5.1.21. > When True is actually False/真亦假 True = False if True == False: print(\"I've lost faith in truth!\") Output: I've lost faith in truth! &#x1F4A1; 说明: 最初, Python 并没有 bool 型 (人们用0表示假值, 用非零值比如1作为真值). 后来他们添加了 True, False, 和 bool 型, 但是, 为了向后兼容, 他们没法把 True 和 False 设置为常量, 只是设置成了内置变量. Python 3 由于不再需要向后兼容, 终于可以修复这个问题了, 所以这个例子无法在 Python 3.x 中执行! 5.1.22. > From filled to None in one instruction.../从有到无... some_list = [1, 2, 3] some_dict = { \"key_1\": 1, \"key_2\": 2, \"key_3\": 3 } some_list = some_list.append(4) some_dict = some_dict.update({\"key_4\": 4}) Output: >>> print(some_list) None >>> print(some_dict) None &#x1F4A1; 说明: 大多数修改序列/映射对象的方法, 比如 list.append, dict.update, list.sort 等等. 都是原地修改对象并返回 None. 这样做的理由是, 如果操作可以原地完成, 就可以避免创建对象的副本来提高性能. (参考这里) 5.1.23. > Subclass relationships/子类关系 * Output: >>> from collections import Hashable >>> issubclass(list, object) True >>> issubclass(object, Hashable) True >>> issubclass(list, Hashable) False 子类关系应该是可传递的, 对吧? (即, 如果 A 是 B 的子类, B 是 C 的子类, 那么 A 应该 是 C 的子类.) &#x1F4A1; 说明: Python 中的子类关系并不一定是传递的. 任何人都可以在元类中随意定义 __subclasscheck__. 当 issubclass(cls, Hashable) 被调用时, 它只是在 cls 中寻找 __hash__ 方法或者从继承的父类中寻找 __hash__ 方法. 由于 object is 可散列的(hashable), 但是 list 是不可散列的, 所以它打破了这种传递关系. 在这里可以找到更详细的解释. 5.1.24. > The mysterious key type conversion/神秘的键型转换 * class SomeClass(str): pass some_dict = {'s':42} Output: >>> type(list(some_dict.keys())[0]) str >>> s = SomeClass('s') >>> some_dict[s] = 40 >>> some_dict # 预期: 两个不同的键值对 {'s': 40} >>> type(list(some_dict.keys())[0]) str &#x1F4A1; 说明: 由于 SomeClass 会从 str 自动继承 __hash__ 方法, 所以 s 对象和 \"s\" 字符串的哈希值是相同的. 而 SomeClass(\"s\") == \"s\" 为 True 是因为 SomeClass 也继承了 str 类 __eq__ 方法. 由于两者的哈希值相同且相等, 所以它们在字典中表示相同的键. 如果想要实现期望的功能, 我们可以重定义 SomeClass 的 __eq__ 方法. class SomeClass(str): def __eq__(self, other): return ( type(self) is SomeClass and type(other) is SomeClass and super().__eq__(other) ) # 当我们自定义 __eq__ 方法时, Python 不会再自动继承 __hash__ 方法 # 所以我们也需要定义它 __hash__ = str.__hash__ some_dict = {'s':42} Output: >>> s = SomeClass('s') >>> some_dict[s] = 40 >>> some_dict {'s': 40, 's': 42} >>> keys = list(some_dict.keys()) >>> type(keys[0]), type(keys[1]) (__main__.SomeClass, str) 5.1.25. > Let's see if you can guess this?/看看你能否猜到这一点? a, b = a[b] = {}, 5 Output: >>> a {5: ({...}, 5)} &#x1F4A1; 说明: 根据 Python 语言参考, 赋值语句的形式如下 (target_list \"=\")+ (expression_list | yield_expression) 赋值语句计算表达式列表(expression list)(牢记 这可以是单个表达式或以逗号分隔的列表, 后者返回元组)并将单个结果对象从左到右分配给目标列表中的每一项. (target_list \"=\")+ 中的 + 意味着可以有一个或多个目标列表. 在这个例子中, 目标列表是 a, b 和 a[b] (注意表达式列表只能有一个, 在我们的例子中是 {}, 5). 表达式列表计算结束后, 将其值自动解包后从左到右分配给目标列表(target list). 因此, 在我们的例子中, 首先将 {}, 5 元组并赋值给 a, b, 然后我们就可以得到 a = {} 且 b = 5. a 被赋值的 {} 是可变对象. 第二个目标列表是 a[b] (你可能觉得这里会报错, 因为在之前的语句中 a 和 b 都还没有被定义. 但是别忘了, 我们刚刚将 a 赋值 {} 且将 b 赋值为 5). 现在, 我们将通过将字典中键 5 的值设置为元组 ({}, 5) 来创建循环引用 (输出中的 {...} 指与 a 引用了相同的对象). 下面是一个更简单的循环引用的例子 >>> some_list = some_list[0] = [0] >>> some_list [[...]] >>> some_list[0] [[...]] >>> some_list is some_list[0] True >>> some_list[0][0][0][0][0][0] == some_list True 我们的例子就是这种情况 (a[b][0] 与 a 是相同的对象) 总结一下, 你也可以把例子拆成 a, b = {}, 5 a[b] = a, b 并且可以通过 a[b][0] 与 a 是相同的对象来证明是循环引用 >>> a[b][0] is a True 5.2. Section: Appearances are deceptive!/外表是靠不住的! 5.2.1. > Skipping lines?/跳过一行? Output: >>> value = 11 >>> valuе = 32 >>> value 11 什么鬼? 注意: 如果你想要重现的话最简单的方法是直接复制上面的代码片段到你的文件或命令行里. &#x1F4A1; 说明: 一些非西方字符虽然看起来和英语字母相同, 但会被解释器识别为不同的字母. >>> ord('е') # 西里尔语的 'e' (Ye) 1077 >>> ord('e') # 拉丁语的 'e', 用于英文并使用标准键盘输入 101 >>> 'е' == 'e' False >>> value = 42 # 拉丁语 e >>> valuе = 23 # 西里尔语 'e', Python 2.x 的解释器在这会抛出 `SyntaxError` 异常 >>> value 42 内置的 ord() 函数可以返回一个字符的 Unicode 代码点, 这里西里尔语 'e' 和拉丁语 'e' 的代码点不同证实了上述例子. 5.2.2. > Teleportation/空间移动 * import numpy as np def energy_send(x): # 初始化一个 numpy 数组 np.array([float(x)]) def energy_receive(): # 返回一个空的 numpy 数组 return np.empty((), dtype=np.float).tolist() Output: >>> energy_send(123.456) >>> energy_receive() 123.456 谁来给我发个诺贝尔奖? &#x1F4A1; 说明: 注意在 energy_send 函数中创建的 numpy 数组并没有返回, 因此内存空间被释放并可以被重新分配. numpy.empty() 直接返回下一段空闲内存，而不重新初始化. 而这个内存点恰好就是刚刚释放的那个(通常情况下, 并不绝对). 5.2.3. > Well, something is fishy.../嗯，有些可疑... def square(x): \"\"\" 一个通过加法计算平方的简单函数. \"\"\" sum_so_far = 0 for counter in range(x): sum_so_far = sum_so_far + x return sum_so_far Output (Python 2.x): >>> square(10) 10 难道不应该是100吗? 注意: 如果你无法重现, 可以尝试运行这个文件mixed_tabs_and_spaces.py. &#x1F4A1; 说明: 不要混用制表符(tab)和空格(space)! 在上面的例子中, return 的前面是\"1个制表符\", 而其他部分的代码前面是 \"4个空格\". Python是这么处理制表符的: 首先, 制表符会从左到右依次被替换成8个空格, 直到被替换后的字符总数是八的倍数 因此, square 函数最后一行的制表符会被替换成8个空格, 导致return语句进入循环语句里面. Python 3 很友好, 在这种情况下会自动抛出错误. Output (Python 3.x): TabError: inconsistent use of tabs and spaces in indentation 5.3. Section: Watch out for the landmines!/小心地雷! 5.3.1. > Modifying a dictionary while iterating over it/迭代字典时的修改 x = {0: None} for i in x: del x[i] x[i+1] = None print(i) Output (Python 2.7- Python 3.5): 0 1 2 3 4 5 6 7 是的, 它运行了八次然后才停下来. &#x1F4A1; 说明: Python不支持对字典进行迭代的同时修改它. 它之所以运行8次, 是因为字典会自动扩容以容纳更多键值(我们有8次删除记录, 因此需要扩容). 这实际上是一个实现细节. (译: 应该是因为字典的初始最小值是8, 扩容会导致散列表地址发生变化而中断循环.) 在不同的Python实现中删除键的处理方式以及调整大小的时间可能会有所不同.(译: 就是说什么时候扩容在不同版本中可能是不同的, 在3.6及3.7的版本中到5就会自动扩容了. 以后也有可能再次发生变化. 这是为了避免散列冲突. 顺带一提, 后面两次扩容会扩展为32和256. 即8->32->256.) 更多的信息, 你可以参考这个StackOverflow的回答, 它详细的解释一个类似的例子. 5.3.2. > Stubborn del operator/坚强的 del * class SomeClass: def __del__(self): print(\"Deleted!\") Output: 1. >>> x = SomeClass() >>> y = x >>> del x # 这里应该会输出 \"Deleted!\" >>> del y Deleted! 唷, 终于删除了. 你可能已经猜到了在我们第一次尝试删除 x 时是什么让 __del__ 免于被调用的. 那让我们给这个例子增加点难度. 2. >>> x = SomeClass() >>> y = x >>> del x >>> y # 检查一下y是否存在 >>> del y # 像之前一样, 这里应该会输出 \"Deleted!\" >>> globals() # 好吧, 并没有. 让我们看一下所有的全局变量 Deleted! {'__builtins__': , 'SomeClass': , '__package__': None, '__name__': '__main__', '__doc__': None} 好了，现在它被删除了 :confused: &#x1F4A1; 说明: del x 并不会立刻调用 x.__del__(). 每当遇到 del x, Python 会将 x 的引用数减1, 当 x 的引用数减到0时就会调用 x.__del__(). 在第二个例子中, y.__del__() 之所以未被调用, 是因为前一条语句 (>>> y) 对同一对象创建了另一个引用, 从而防止在执行 del y 后对象的引用数变为0. 调用 globals 导致引用被销毁, 因此我们可以看到 \"Deleted!\" 终于被输出了. (译: 这其实是 Python 交互解释器的特性, 它会自动让 _ 保存上一个表达式输出的值, 详细可以看这里.) 5.3.3. > Deleting a list item while iterating/迭代列表时删除元素 list_1 = [1, 2, 3, 4] list_2 = [1, 2, 3, 4] list_3 = [1, 2, 3, 4] list_4 = [1, 2, 3, 4] for idx, item in enumerate(list_1): del item for idx, item in enumerate(list_2): list_2.remove(item) for idx, item in enumerate(list_3[:]): list_3.remove(item) for idx, item in enumerate(list_4): list_4.pop(idx) Output: >>> list_1 [1, 2, 3, 4] >>> list_2 [2, 4] >>> list_3 [] >>> list_4 [2, 4] 你能猜到为什么输出是 [2, 4] 吗? &#x1F4A1; 说明: 在迭代时修改对象是一个很愚蠢的主意. 正确的做法是迭代对象的副本, list_3[:] 就是这么做的. >>> some_list = [1, 2, 3, 4] >>> id(some_list) 139798789457608 >>> id(some_list[:]) # 注意python为切片列表创建了新对象. 139798779601192 del, remove 和 pop 的不同: del var_name 只是从本地或全局命名空间中删除了 var_name (这就是为什么 list_1 没有受到影响). remove 会删除第一个匹配到的指定值, 而不是特定的索引, 如果找不到值则抛出 ValueError 异常. pop 则会删除指定索引处的元素并返回它, 如果指定了无效的索引则抛出 IndexError 异常. 为什么输出是 [2, 4]? 列表迭代是按索引进行的, 所以当我们从 list_2 或 list_4 中删除 1 时, 列表的内容就变成了 [2, 3, 4]. 剩余元素会依次位移, 也就是说, 2 的索引会变为 0, 3 会变为 1. 由于下一次迭代将获取索引为 1 的元素 (即 3), 因此 2 将被彻底的跳过. 类似的情况会交替发生在列表中的每个元素上. 参考这个StackOverflow的回答来解释这个例子 关于Python中字典的类似例子, 可以参考这个Stackoverflow的回答. 5.3.4. > Loop variables leaking out!/循环变量泄漏! 1. for x in range(7): if x == 6: print(x, ': for x inside loop') print(x, ': x in global') Output: 6 : for x inside loop 6 : x in global 但是 x 从未在循环外被定义... 2. # 这次我们先初始化x x = -1 for x in range(7): if x == 6: print(x, ': for x inside loop') print(x, ': x in global') Output: 6 : for x inside loop 6 : x in global 3. x = 1 print([x for x in range(5)]) print(x, ': x in global') Output (on Python 2.x): [0, 1, 2, 3, 4] (4, ': x in global') Output (on Python 3.x): [0, 1, 2, 3, 4] 1 : x in global &#x1F4A1; 说明: 在 Python 中, for 循环使用所在作用域并在结束后保留定义的循环变量. 如果我们曾在全局命名空间中定义过循环变量. 在这种情况下, 它会重新绑定现有变量. Python 2.x 和 Python 3.x 解释器在列表推导式示例中的输出差异, 在文档 What’s New In Python 3.0 中可以找到相关的解释: \"列表推导不再支持句法形式 [... for var in item1, item2, ...]. 取而代之的是 [... for var in (item1, item2, ...)]. 另外, 注意列表推导具有不同的语义: 它们更接近于 list() 构造函数中生成器表达式的语法糖(译: 这一句我也不是很明白), 特别是循环控制变量不再泄漏到周围的作用域中.\" 5.3.5. > Beware of default mutable arguments!/当心默认的可变参数! def some_func(default_arg=[]): default_arg.append(\"some_string\") return default_arg Output: >>> some_func() ['some_string'] >>> some_func() ['some_string', 'some_string'] >>> some_func([]) ['some_string'] >>> some_func() ['some_string', 'some_string', 'some_string'] &#x1F4A1; 说明: Python中函数的默认可变参数并不是每次调用该函数时都会被初始化. 相反, 它们会使用最近分配的值作为默认值. 当我们明确的将 [] 作为参数传递给 some_func 的时候, 就不会使用 default_arg 的默认值, 所以函数会返回我们所期望的结果. def some_func(default_arg=[]): default_arg.append(\"some_string\") return default_arg Output: >>> some_func.__defaults__ # 这里会显示函数的默认参数的值 ([],) >>> some_func() >>> some_func.__defaults__ (['some_string'],) >>> some_func() >>> some_func.__defaults__ (['some_string', 'some_string'],) >>> some_func([]) >>> some_func.__defaults__ (['some_string', 'some_string'],) 避免可变参数导致的错误的常见做法是将 None 指定为参数的默认值, 然后检查是否有值传给对应的参数. 例: def some_func(default_arg=None): if not default_arg: default_arg = [] default_arg.append(\"some_string\") return default_arg 5.3.6. > Catching the Exceptions/捕获异常 some_list = [1, 2, 3] try: # 这里会抛出异常 ``IndexError`` print(some_list[4]) except IndexError, ValueError: print(\"Caught!\") try: # 这里会抛出异常 ``ValueError`` some_list.remove(4) except IndexError, ValueError: print(\"Caught again!\") Output (Python 2.x): Caught! ValueError: list.remove(x): x not in list Output (Python 3.x): File \"\", line 3 except IndexError, ValueError: ^ SyntaxError: invalid syntax &#x1F4A1; 说明: 如果你想要同时捕获多个不同类型的异常时, 你需要将它们用括号包成一个元组作为第一个参数传递. 第二个参数是可选名称, 如果你提供, 它将与被捕获的异常实例绑定. 例, some_list = [1, 2, 3] try: # 这里会抛出异常 ``ValueError`` some_list.remove(4) except (IndexError, ValueError), e: print(\"Caught again!\") print(e) Output (Python 2.x): Caught again! list.remove(x): x not in list Output (Python 3.x): File \"\", line 4 except (IndexError, ValueError), e: ^ IndentationError: unindent does not match any outer indentation level 在 Python 3 中, 用逗号区分异常与可选名称是无效的; 正确的做法是使用 as 关键字. 例, some_list = [1, 2, 3] try: some_list.remove(4) except (IndexError, ValueError) as e: print(\"Caught again!\") print(e) Output: Caught again! list.remove(x): x not in list 5.3.7. > Same operands, different story!/同人不同命! 1. a = [1, 2, 3, 4] b = a a = a + [5, 6, 7, 8] Output: >>> a [1, 2, 3, 4, 5, 6, 7, 8] >>> b [1, 2, 3, 4] 2. a = [1, 2, 3, 4] b = a a += [5, 6, 7, 8] Output: >>> a [1, 2, 3, 4, 5, 6, 7, 8] >>> b [1, 2, 3, 4, 5, 6, 7, 8] &#x1F4A1; 说明: a += b 并不总是与 a = a + b 表现相同. 类实现 op= 运算符的方式 也许 是不同的, 列表就是这样做的. 表达式 a = a + [5,6,7,8] 会生成一个新列表, 并让 a 引用这个新列表, 同时保持 b 不变. 表达式 a += [5,6,7,8] 实际上是使用的是 \"extend\" 函数, 所以 a 和 b 仍然指向已被修改的同一列表. 5.3.8. > The out of scope variable/外部作用域变量 a = 1 def some_func(): return a def another_func(): a += 1 return a Output: >>> some_func() 1 >>> another_func() UnboundLocalError: local variable 'a' referenced before assignment &#x1F4A1; 说明: 当你在作用域中对变量进行赋值时, 变量会变成该作用域内的局部变量. 因此 a 会变成 another_func 函数作用域中的局部变量, 但它在函数作用域中并没有被初始化, 所以会引发错误. 可以阅读这个简短却很棒的指南, 了解更多关于 Python 中命名空间和作用域的工作原理. 想要在 another_func 中修改外部作用域变量 a 的话, 可以使用 global 关键字. def another_func() global a a += 1 return a Output: >>> another_func() 2 5.3.9. > Be careful with chained operations/小心链式操作 >>> (False == False) in [False] # 可以理解 False >>> False == (False in [False]) # 可以理解 False >>> False == False in [False] # 为毛? True >>> True is False == False False >>> False is False is False True >>> 1 > 0 >> (1 > 0) >> 1 > (0 &#x1F4A1; 说明: 根据 https://docs.python.org/2/reference/expressions.html#not-in 形式上, 如果 a, b, c, ..., y, z 是表达式, 而 op1, op2, ..., opN 是比较运算符, 那么除了每个表达式最多只出现一次以外 a op1 b op2 c ... y opN z 就等于 a op1 b and b op2 c and ... y opN z. 虽然上面的例子似乎很愚蠢, 但是像 a == b == c 或 0 就很棒了. False is False is False 相当于 (False is False) and (False is False) True is False == False 相当于 True is False and False == False, 由于语句的第一部分 (True is False) 等于 False, 因此整个表达式的结果为 False. 1 > 0 相当于 1 > 0 and 0 , 所以最终结果为 True. 表达式 (1 > 0) 相当于 True 且>>> int(True) 1 >>> True + 1 # 与这个例子无关，只是好玩 2 所以, 1 等于 False 5.3.10. > Name resolution ignoring class scope/忽略类作用域的名称解析 1. x = 5 class SomeClass: x = 17 y = (x for i in range(10)) Output: >>> list(SomeClass.y)[0] 5 2. x = 5 class SomeClass: x = 17 y = [x for i in range(10)] Output (Python 2.x): >>> SomeClass.y[0] 17 Output (Python 3.x): >>> SomeClass.y[0] 5 &#x1F4A1; 说明: 类定义中嵌套的作用域会忽略类内的名称绑定. 生成器表达式有它自己的作用域. 从 Python 3.X 开始, 列表推导式也有自己的作用域. 5.3.11. > Needle in a Haystack/大海捞针 1. x, y = (0, 1) if True else None, None Output: >>> x, y # 期望的结果是 (0, 1) ((0, 1), None) 几乎每个 Python 程序员都遇到过类似的情况. 2. t = ('one', 'two') for i in t: print(i) t = ('one') for i in t: print(i) t = () print(t) Output: one two o n e tuple() &#x1F4A1; 说明: 对于 1, 正确的语句是 x, y = (0, 1) if True else (None, None). 对于 2, 正确的语句是 t = ('one',) 或者 t = 'one', (缺少逗号) 否则解释器会认为 t 是一个字符串, 并逐个字符对其进行迭代. () 是一个特殊的标记，表示空元组. 5.4. Section: The Hidden treasures!/隐藏的宝藏! This section contains few of the lesser-known interesting things about Python that most beginners like me are unaware of (well, not anymore). 5.4.1. > Okay Python, Can you make me fly?/Python, 可否带我飞? * 好, 去吧. import antigravity Output: 嘘.. 这是个超级秘密. &#x1F4A1; 说明: antigravity 模块是 Python 开发人员发布的少数复活节彩蛋之一. import antigravity 会打开一个 Python 的经典 XKCD 漫画页面. 不止如此. 这个复活节彩蛋里还有一个复活节彩蛋. 如果你看一下代码, 就会发现还有一个函数实现了 XKCD's geohashing 算法. 5.4.2. > goto, but why?/goto, 但为什么? * from goto import goto, label for i in range(9): for j in range(9): for k in range(9): print(\"I'm trapped, please rescue!\") if k == 2: goto .breakout # 从多重循环中跳出 label .breakout print(\"Freedom!\") Output (Python 2.3): I'm trapped, please rescue! I'm trapped, please rescue! Freedom! &#x1F4A1; 说明: 2004年4月1日, Python 宣布 加入一个可用的 goto 作为愚人节礼物. 当前版本的 Python 并没有这个模块. 就算可以用, 也请不要使用它. 这里是为什么Python中没有 goto 的原因. 5.4.3. > Brace yourself!/做好思想准备 * 如果你不喜欢在Python中使用空格来表示作用域, 你可以导入 C 风格的 {}, from __future__ import braces Output: File \"some_file.py\", line 1 from __future__ import braces SyntaxError: not a chance 想用大括号? 没门! 觉得不爽, 请去用java. &#x1F4A1; 说明: 通常 __future__ 会提供 Python 未来版本的功能. 然而，这里的 “未来” 是一个讽刺. 这是一个表达社区对此类问题态度的复活节彩蛋. 5.4.4. > Let's meet Friendly Language Uncle For Life/让生活更友好 * Output (Python 3.x) >>> from __future__ import barry_as_FLUFL >>> \"Ruby\" != \"Python\" # 这里没什么疑问 File \"some_file.py\", line 1 \"Ruby\" != \"Python\" ^ SyntaxError: invalid syntax >>> \"Ruby\" <> \"Python\" True 这就对了. &#x1F4A1; 说明: 相关的 PEP-401 发布于 2009年4月1日 (所以你现在知道这意味着什么了吧). 引用 PEP-401 意识到 Python 3.0 里的 != 运算符是一个会引起手指疼痛的恐怖错误, FLUFL 将 <> 运算符恢复为唯一写法. Uncle Barry 在 PEP 中还分享了其他东西; 你可以在这里获得他们. (译: 虽然文档中没写，但应该是只能在交互解释器中使用.) 5.4.5. > Even Python understands that love is complicated/连Python也知道爱是难言的 * import this 等等, this 是什么? this 是爱 :heart: Output: The Zen of Python, by Tim Peters Beautiful is better than ugly. 优美胜于丑陋（Python 以编写优美的代码为目标） Explicit is better than implicit. 明了胜于晦涩（优美的代码应当是明了的，命名规范，风格相似） Simple is better than complex. 简洁胜于复杂（优美的代码应当是简洁的，不要有复杂的内部实现） Complex is better than complicated. 复杂胜于凌乱（如果复杂不可避免，那代码间也不能有难懂的关系，要保持接口简洁） Flat is better than nested. 扁平胜于嵌套（优美的代码应当是扁平的，不能有太多的嵌套） Sparse is better than dense. 间隔胜于紧凑（优美的代码有适当的间隔，不要奢望一行代码解决问题） Readability counts. 可读性很重要（优美的代码一定是可读的） Special cases aren't special enough to break the rules. 没有特例特殊到需要违背这些规则（这些规则至高无上） Although practicality beats purity. 尽管我们更倾向于实用性 Errors should never pass silently. 不要安静的包容所有错误 Unless explicitly silenced. 除非你确定需要这样做（精准地捕获异常，不写 except:pass 风格的代码） In the face of ambiguity, refuse the temptation to guess. 拒绝诱惑你去猜测的暧昧事物 There should be one-- and preferably only one --obvious way to do it. 而是尽量找一种，最好是唯一一种明显的解决方案（如果不确定，就用穷举法） Although that way may not be obvious at first unless you're Dutch. 虽然这并不容易，因为你不是 Python 之父（这里的 Dutch 是指 Guido ） Now is better than never. 现在行动好过永远不行动 Although never is often better than *right* now. 尽管不行动要好过鲁莽行动 If the implementation is hard to explain, it's a bad idea. 如果你无法向人描述你的方案，那肯定不是一个好方案； If the implementation is easy to explain, it may be a good idea. 如果你能轻松向人描述你的方案，那也许会是一个好方案（方案测评标准） Namespaces are one honking great idea -- let's do more of those! 命名空间是一种绝妙的理念，我们应当多加利用（倡导与号召） 这是 Python 之禅! >>> love = this >>> this is love True >>> love is True False >>> love is False False >>> love is not True or False True >>> love is not True or False; love is love # 爱是难言的 True &#x1F4A1; 说明: this 模块是关于 Python 之禅的复活节彩蛋 (PEP 20). 如果你认为这已经够有趣的了, 可以看看 this.py 的实现. 有趣的是, Python 之禅的实现代码违反了他自己 (这可能是唯一会发生这种情况的地方). * 至于 love is not True or False; love is love, 意外却又不言而喻. 5.4.6. > Yes, it exists!/是的, 它存在! 循环的 else. 一个典型的例子: def does_exists_num(l, to_find): for num in l: if num == to_find: print(\"Exists!\") break else: print(\"Does not exist\") Output: >>> some_list = [1, 2, 3, 4, 5] >>> does_exists_num(some_list, 4) Exists! >>> does_exists_num(some_list, -1) Does not exist 异常的 else . 例, try: pass except: print(\"Exception occurred!!!\") else: print(\"Try block executed successfully...\") Output: Try block executed successfully... &#x1F4A1; 说明: 循环后的 else 子句只会在循环没有触发 break 语句, 正常结束的情况下才会执行. try 之后的 else 子句也被称为 \"完成子句\", 因为在 try 语句中到达 else 子句意味着try块实际上已成功完成. 5.4.7. > Inpinity/无限 * 英文拼写是有意的, 请不要为此提交补丁. (译: 这里是为了突出 Python 中无限的定义与Pi有关, 所以将两个单词拼接了.) Output (Python 3.x): >>> infinity = float('infinity') >>> hash(infinity) 314159 >>> hash(float('-inf')) -314159 &#x1F4A1; 说明: infinity 的哈希值是 10⁵ x π. 有意思的是, float('-inf') 的哈希值在 Python 3 中是 \"-10⁵ x π\" , 而在 Python 2 中是 \"-10⁵ x e\". 5.4.8. > Mangling time!/修饰时间! * class Yo(object): def __init__(self): self.__honey = True self.bitch = True Output: >>> Yo().bitch True >>> Yo().__honey AttributeError: 'Yo' object has no attribute '__honey' >>> Yo()._Yo__honey True 为什么 Yo()._Yo__honey 能运行? 只有印度人理解.(译: 这个梗可能是指印度音乐人Yo Yo Honey Singh) &#x1F4A1; 说明: 名字修饰 用于避免不同命名空间之间名称冲突. 在 Python 中, 解释器会通过给类中以 __ (双下划线)开头且结尾最多只有一个下划线的类成员名称加上_NameOfTheClass 来修饰(mangles)名称. 所以, 要访问 __honey 对象,我们需要加上 _Yo 以防止与其他类中定义的相同名称的属性发生冲突. 5.5. Section: Miscellaneous/杂项 5.5.1. > += is faster/更快的 += # 用 \"+\" 连接三个字符串: >>> timeit.timeit(\"s1 = s1 + s2 + s3\", setup=\"s1 = ' ' * 100000; s2 = ' ' * 100000; s3 = ' ' * 100000\", number=100) 0.25748300552368164 # 用 \"+=\" 连接三个字符串: >>> timeit.timeit(\"s1 += s2 + s3\", setup=\"s1 = ' ' * 100000; s2 = ' ' * 100000; s3 = ' ' * 100000\", number=100) 0.012188911437988281 &#x1F4A1; 说明: 连接两个以上的字符串时 += 比 + 更快, 因为在计算过程中第一个字符串 (例如, s1 += s2 + s3 中的 s1) 不会被销毁.(译: 就是 += 执行的是追加操作，少了一个销毁新建的动作.) 5.5.2. > Let's make a giant string!/来做个巨大的字符串吧！ def add_string_with_plus(iters): s = \"\" for i in range(iters): s += \"xyz\" assert len(s) == 3*iters def add_bytes_with_plus(iters): s = b\"\" for i in range(iters): s += b\"xyz\" assert len(s) == 3*iters def add_string_with_format(iters): fs = \"{}\"*iters s = fs.format(*([\"xyz\"]*iters)) assert len(s) == 3*iters def add_string_with_join(iters): l = [] for i in range(iters): l.append(\"xyz\") s = \"\".join(l) assert len(s) == 3*iters def convert_list_to_string(l, iters): s = \"\".join(l) assert len(s) == 3*iters Output: >>> timeit(add_string_with_plus(10000)) 1000 loops, best of 3: 972 µs per loop >>> timeit(add_bytes_with_plus(10000)) 1000 loops, best of 3: 815 µs per loop >>> timeit(add_string_with_format(10000)) 1000 loops, best of 3: 508 µs per loop >>> timeit(add_string_with_join(10000)) 1000 loops, best of 3: 878 µs per loop >>> l = [\"xyz\"]*10000 >>> timeit(convert_list_to_string(l, 10000)) 10000 loops, best of 3: 80 µs per loop 让我们将迭代次数增加10倍. >>> timeit(add_string_with_plus(100000)) # 执行时间线性增加 100 loops, best of 3: 9.75 ms per loop >>> timeit(add_bytes_with_plus(100000)) # 二次增加 1000 loops, best of 3: 974 ms per loop >>> timeit(add_string_with_format(100000)) # 线性增加 100 loops, best of 3: 5.25 ms per loop >>> timeit(add_string_with_join(100000)) # 线性增加 100 loops, best of 3: 9.85 ms per loop >>> l = [\"xyz\"]*100000 >>> timeit(convert_list_to_string(l, 100000)) # 线性增加 1000 loops, best of 3: 723 µs per loop &#x1F4A1; 说明: 你可以在这获得更多 timeit 的相关信息. 它通常用于衡量代码片段的执行时间. 不要用 + 去生成过长的字符串, 在 Python 中, str 是不可变的, 所以在每次连接中你都要把左右两个字符串复制到新的字符串中. 如果你连接四个长度为10的字符串, 你需要拷贝 (10+10) + ((10+10)+10) + (((10+10)+10)+10) = 90 个字符而不是 40 个字符. 随着字符串的数量和大小的增加, 情况会变得越发的糟糕 (就像add_bytes_with_plus 函数的执行时间一样) 因此, 更建议使用 .format. 或 % 语法 (但是, 对于短字符串, 它们比 + 稍慢一点). 又或者, 如果你所需的内容已经以可迭代对象的形式提供了, 使用 ''.join(可迭代对象) 要快多了. add_string_with_plus 的执行时间没有像 add_bytes_with_plus 一样出现二次增加是因为解释器会如同上一个例子所讨论的一样优化 +=. 用 s = s + \"x\" + \"y\" + \"z\" 替代 s += \"xyz\" 的话, 执行时间就会二次增加了. def add_string_with_plus(iters): s = \"\" for i in range(iters): s = s + \"x\" + \"y\" + \"z\" assert len(s) == 3*iters >>> timeit(add_string_with_plus(10000)) 100 loops, best of 3: 9.87 ms per loop >>> timeit(add_string_with_plus(100000)) # 执行时间二次增加 1 loops, best of 3: 1.09 s per loop 5.5.3. > Explicit typecast of strings/字符串的显式类型转换 a = float('inf') b = float('nan') c = float('-iNf') # 这些字符串不区分大小写 d = float('nan') Output: >>> a inf >>> b nan >>> c -inf >>> float('some_other_string') ValueError: could not convert string to float: some_other_string >>> a == -c #inf==inf True >>> None == None # None==None True >>> b == d #但是 nan!=nan False >>> 50/a 0.0 >>> a/a nan >>> 23 + b nan &#x1F4A1; 说明: 'inf' 和 'nan' 是特殊的字符串(不区分大小写), 当显示转换成 float 型时, 它们分别用于表示数学意义上的 \"无穷大\" 和 \"非数字\". 5.5.4. > Minor Ones/小知识点 join() 是一个字符串操作而不是列表操作. (第一次接触会觉得有点违反直觉) &#x1F4A1; 说明: 如果 join() 是字符串方法 那么它就可以处理任何可迭代的对象(列表，元组，迭代器). 如果它是列表方法, 则必须在每种类型中单独实现. 另外, 在 list 对象的通用API中实现一个专用于字符串的方法没有太大的意义. 看着奇怪但能正确运行的语句: [] = () 语句在语义上是正确的 (解包一个空的 tuple 并赋值给 list) 'a'[0][0][0][0][0] 在语义上也是正确的, 因为在 Python 中字符串同时也是序列(可迭代对象支持使用整数索引访问元素). 3 --0-- 5 == 8 和 --5 == 5 在语义上都是正确的, 且结果等于 True.(译: 3减负0等于3，再减负5相当于加5等于8；负的负5等于5.) 鉴于 a 是一个数字, ++a 和 --a 都是有效的 Python 语句, 但其效果与 C, C++ 或 Java 等不一样. >>> a = 5 >>> a 5 >>> ++a 5 >>> --a 5 &#x1F4A1; 说明: python 里没有 ++ 操作符. 这其实是两个 + 操作符. ++a 被解析为 +(+a) 最后等于 a. --a 同理. 这个 StackOverflow 回答 讨论了为什么 Python 中缺少增量和减量运算符. Python 使用 2个字节存储函数中的本地变量. 理论上, 这意味着函数中只能定义65536个变量. 但是，Python 内置了一个方便的解决方案，可用于存储超过2^16个变量名. 下面的代码演示了当定义了超过65536个局部变量时堆栈中发生的情况 (警告: 这段代码会打印大约2^18行文本, 请做好准备!): import dis exec(\"\"\" def f(): \"\"\" + \"\"\" \"\"\".join([\"X\"+str(x)+\"=\" + str(x) for x in range(65539)])) f() print(dis.dis(f)) 你的 Python 代码 并不会多线程同时运行 (是的, 你没听错!). 虽然你觉得会产生多个线程并让它们同时执行你的代码, 但是, 由于 全局解释锁的存在, 你所做的只是让你的线程依次在同一个核心上执行. Python 多线程适用于IO密集型的任务, 但如果想要并行处理CPU密集型的任务, 你应该会想使用 multiprocessing 模块. 列表切片超出索引边界而不引发任何错误 >>> some_list = [1, 2, 3, 4, 5] >>> some_list[111:] [] int('١٢٣٤٥٦٧٨٩') 在 Python 3 中会返回 123456789. 在 Python 中, 十进制字符包括数字字符, 以及可用于形成十进制数字的所有字符, 例如: U+0660, ARABIC-INDIC DIGIT ZERO. 这有一个关于此的 有趣故事. 'abc'.count('') == 4. 这有一个 count 方法的相近实现, 能更好的说明问题 def count(s, sub): result = 0 for i in range(len(s) + 1 - len(sub)): result += (s[i:i + len(sub)] == sub) return result 这个行为是由于空子串('')与原始字符串中长度为0的切片相匹配导致的. 6. Contributing/贡献 欢迎各种补丁! 详情请看CONTRIBUTING.md.(译: 这是给原库提贡献的要求模版) 你可以通过新建 issue 或者在上 Gitter 与我们进行讨论. (译: 如果你想对这个翻译项目提供帮助, 请看这里) 7. Acknowledgements/致谢 这个系列最初的想法和设计灵感来自于 Denys Dovhan 的项目 wtfjs. 社区的强大支持让它成长为现在的模样. Some nice Links!/一些不错的资源 https://www.youtube.com/watch?v=sH4XF6pKKmk https://www.reddit.com/r/Python/comments/3cu6ej/what_are_some_wtf_things_about_python https://sopython.com/wiki/Common_Gotchas_In_Python https://stackoverflow.com/questions/530530/python-2-x-gotchas-and-landmines https://stackoverflow.com/questions/1011431/common-pitfalls-in-python https://www.python.org/doc/humor/ https://www.codementor.io/satwikkansal/python-practices-for-efficient-code-performance-memory-and-usability-aze6oiq65 8. &#x1F393; License/许可 © Satwik Kansal 8.1. Help/帮助 如果您有任何想法或建议，欢迎分享. 8.2. Surprise your geeky pythonist friends?/想给你的极客朋友一个惊喜? 您可以使用这些快链向 Twitter 和 Linkedin 上的朋友推荐 wtfpython, Twitter | Linkedin 8.3. Need a pdf version?/需要来一份pdf版的? 我收到一些想要pdf版本的需求. 你可以快速在这获得. 8.4. Follow Commit/追踪Commit 这是中文版 fork 时所处的原库 Commit, 当原库更新时我会跟随更新. 8.5. 996.icu © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Langs/Shell.html":{"url":"Langs/Shell.html","title":"Shell","keywords":"","body":"1. Shell Lang1. Shell Lang Created by: Aiken H Detail: lang Finished?: No Tags: Code Linux-shell中$(( ))、$( )、``与${ }的区别 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Papers/Attention.html":{"url":"Papers/Attention.html","title":"P1:Attention","keywords":"","body":"1. ATTENTION MECHANISM1.1. What’s Attention In Deep Learning1.2. What’s Wrong with Seq2Seq Model1.3. Born for Translation1.4. A Family of Attention Mechanism1.4.1. Summary1.4.2. Self-Attention1.4.3. Soft vs Hard Attention1.4.4. Global vs Loacal Attention1.5. Neural Turing Machines1.5.1. Attention Mechanisms1.6. Pointer Network1.7. Transformer Introduction1.7.1. Key,Value and Query1.8. Encoder-Decoder and Taxonomy of Attention1.9. Transformer and Self-Attention1.10. Reference1. ATTENTION MECHANISM @Aiken 2020.9.16 对基本注意力机制的一些资料和理解做一些简单的汇总，着重分析基本思想原理，应用和实现（即 structure），还有一些Weakness和相应的解决方案。 基本索引，根据论文和工程需求实现： 1.TODO-List： 根据Lil’Log的Attention？Attention！进行初步的整理 各个分类的具体含义分开整理，理解一部分整理一部分，可能结合实际的应用去整理吧。 其中很重要的一点是数学分析的部分，需要对数学原理进行整理和领会。 1.1. What’s Attention In Deep Learning 在某种程度上，注意力是由我么如何关注视觉图像的不同区域或者我们如何关联同一个句子中的不同单词所启发的：针对于问题的不同，我们会对图像的某些具体的区域重视（某些区域在视觉中呈现高分辨率，而另一些则是低分辨率的情况），或者句子中的某些词重视的情况。 可以解释一个句子中紧密的上下文单词之间的关系，比如我们看到eating就会期待看到food，而color对于我们来说就没有那么重要。 简而言之，深度学习中的注意力就是针对不同问题下的重要性权重的向量，比如我们根据关联性，给上面的每个单词赋予一个相关性的向量权重，然后基于注意力加权后的总和作为目标的近似值。 1.2. What’s Wrong with Seq2Seq Model seq2swq旨在将再encoder-decoder的架构下，将输入序列转换为新序列，对两个序列的长度没有要求。 Encoder：将输入序列转换成固定长度的context vector，用来概括整个源序列的信息 Decoder：使用context vector初始化，来进行解码（转换） 这样的Encoder和Decoder架构都是Recurrent Neural Networks，就像LSTM和GRU架构。 缺陷：固定长度的context vector可能会导致序列信息的缺失，同时可能会无法记住长句子，同时也会丢失时序的对齐信息。所以Attention就诞生了。 :question: 1.3. Born for Translation 这几个部分的研究都是基于NMT自然机器翻译，来进行分析的（文本非图像） 原本的E-D是通过Encoder的最后一个hidden states构建单个Context Vector，而Attention 做的就是在Context Vec和Source之间建立一个Shortcut（简单的Feed Forword Network），而源和目标的对齐由上下文向量来学习和控制。而上下文中应该consumes（包含）几个维度的信息 Encoder的hidden States； Decoder的hidden States； Source 和 Target之间的对齐信息； Encoder Decoder实际上都是RNN的架构，S实际上就是H，隐层状态，Decoder对EOS输出了一个初始的预测Y以后，推进Decoder的进程。 双向的recurrent network（bidirectional RNN）使得Encoder隐态同时考虑前后单词。而在Decoder中 st = f(s{t-1},y_{t-1},c_t) 其中上下文向量c_t是输入序列的隐态之和，通过alignment score来进行加权。 $a_{t,i}$将作为输入i对输出t的隐态加权（相关性），在网络中共同训练，通过tanh来进行激活处理。Score则使用下面的策略： \r score(st,hi)=v_a^Ttanh(Wa[st;hi])\r 其中V, W都是对齐模型中学到的参数 最终对齐完成以后就会是： 1.4. A Family of Attention Mechanism 1.4.1. Summary 由于这个良好的理论基础和实现效果，以及对序列的良好兼容性，这样的算法就被很快的拓展到了计算机视觉的领域中。（学 科 交 叉） 这些不同的score方法实际上就是对每个position上的input和当前位置（通常用上一个时刻的state）来进行相关性建模，针对这些相关性建模，来确定输入对于下一个状态的影响因子，也就是得到一个context向量。这实际上就是注意力机制的核心理念把。 Referred to as “concat” in Luong, et al, 2015 and as “additive attention” in Vaswani, et al, 2017.(^) It adds a scaling factor 1/n−−√1/n, motivated by the concern when the input is large, the softmax function may have an extremely small gradient, hard for efficient learning. 下面对一些更广泛类型的注意力机制做一个摘要性的总结 1.4.2. Self-Attention 这个已经在我的Onenote中整理过了，大概看看就好。这里只讲了一些应用上的点， 自我注意，内部注意力，也就是自我内部关联的注意力关系获取； 1.4.3. Soft vs Hard Attention Image Caption《show, attend and tell》，CNN获取特征，LSTM解码器利用卷积功能来逐一生成单词。通过Attention 来学习权重，可视化如下： 根据注意力是访问整个图像还是访问图像的一个patch来定义hard和soft attention。 Soft Attention：就是普通的全图Attention，将权重放在图像的所有色块上，基本没啥区别 Pro: 模型平滑容易微分 Con：expensive when the source image is large Hard Attention：一次只处理一小块图像，其实就相当于用0/1去对图像区域进行硬编码，只对一部分的图像进行处理，但是这种方式的技术实现我还是没什么概念，后面可以专门研究一下。 Pro：推理计算需求比较小 Con：不可微分，需要用更复杂的技术来进行训练（例如variance reduction or reinforcement learning） 1.4.4. Global vs Loacal Attention Global实际上就和soft是类似的，而局部注意力机制更像是hard和soft之间的一个融合，对改进hard使其可以微分； the model first predicts a single aligned position for the current target word and a window centered around the source position is then used to compute a context vector. 后面提到了一些神经图灵机的内容就是一些基本的计算机制，实际上可能是启发LSTM设计擦除算法设计的根源。 1.5. Neural Turing Machines 1.5.1. Attention Mechanisms 可以将权重的看作一个神经图灵机的寻址权重：（基于位置或者基于内容的两种方式） Content-based addressing: 基于内容寻址的权重设置从输入行和存储行提取的键值向量之间的相似度来创建关注向量：权重的具体计算通过余弦相似度后进行softmax归一化来进行权重的分配。 另外通过β系数来放大或者减弱分布的焦点。 Interpolation 通过interpolation gate scalar $g_t$ 将生成的上下文向量和上一步生成的注意力权重进行混合 \r w^g_t = g_tw^c_t + (1-g_t)w_{t-1}\r Location-baesd addressing 基于位置的寻址，对注意力向量中不同位置的值进行求和，通过对允许的整数偏移位置中的权重来进行参数加权。这相当于是一个一维卷积来测试偏移量。 然后对注意力的分布进行锐化处理，使用γ参数 完整的注意力workflow为： 1.6. Pointer Network 解决的是输入输出都是顺序数据的问题。 1.7. Transformer Introduction Attention is all u need ：提出的重要的Transformer的这种架构，使得算法能够完全基于注意力机制，而不需要序列对齐的recurrent Network。 1.7.1. Key,Value and Query 这一块还是详细解读一下，这里说的太粗略了，没讲清楚。 Transformer的主要重要的架构在于multi-head和self-attention，Transformer将输入堪称一个key-value pairs，均为输入长度n。 \r Attention(Q,K,V)=softmax(\\frac{Q K^⊤} {\\sqrt{n}})V\r Key Value Query 到底都是些什么东西。 1.8. Encoder-Decoder and Taxonomy of Attention 基本的encoder-decoder是基于对序列处理的问题提出的，通常情况下针对的是输入输出都是序列的计算模型。下图a展示了典型的E-D机制，以及加入了self-attention的情况b。（文中提到了一些E-D机制的问题） Seq2Seq的RNN序列模型Encoder需要把之前的输入最终转化成单一的ht（定长），可能会造成序列信息的丢失，同时他只能平权的考虑输入，不能有所重点。同时对于时序对齐信息也会丢失，这对结构化特别重要 注意力机制，在实现上就是通过在体系架构中，嵌入一个额外的前馈神经网络，来进行学习额外的参数（作为Decoder的补充输入，作为序列和之前信息的补充），而且通常，这个前馈的神经网络是需要和encoder-decoder协同训练的，也就是需要和整体网络共同训练。 训练层面是否存在一些特殊的情况，对于一些特殊的Attention 模型，是否需要一些特殊的训练机制。这点如果看到的话，建议需要整理一下 在Survey中，对注意力机制基于多种标准进行了分类，具体的分类情况可以依下图所示，还有一些具体方法的实现。 对于几种分类方式，可以参考几个译文的解读，但是我觉得说的并不清楚，后续就分别针对各种方法进行分析吧。 BTW：在RNN等循环结构不能并行化处理的条件下，提出的类似AM的Transformer（Attention is all u need）结构，他的encoder和decoder由两个子层堆叠而来：Feed Forward Network 和 Multi-head self attention。 Position-wise FFN：获取输入的顺序，在encoder阶段，对于每一个token既生成content embedding也生成position encoding。 Multi-Head Self-Attention：在每个子层中使用self - attention来关联标记及其在相同输入序列中的位置，几个注意力层并行堆叠，对于相同的输入有不同的线性转换。这使得模型能够捕获输入的不同方面，提高表达能力。 1.9. Transformer and Self-Attention 参考论文以及参考资料1 AND 《Attention is all you need》 Self-Attention ： 下图这一段整的明明白白，把整个框架说的比较明白，对输入的embedding（分别做3次卷积，图像输入的情况），分成Query，Key，Value，然后如图进行后续的操作 图2就表示了在CV领域，为什么需要将输入做完卷积以后再成进去，而其中的scale由于图片和序列是不一致的，他们的size本来就是统一的（基本规范的数据集中），那么就可以省略掉这一步，从而直接进行softmax，相当于在预处理的时候已经进行了这样的归一操作。 self-attention 是 Transformer的基础，通过多个Self-Attention组成的Multi-head Attention 就是Transformer模型的基本结构。 Multi-head Attention 1.10. Reference 参考资料 Attention机制详解2：self-attention & Transformer origin document of ↑ Attention的数学原理 Survey: 《An Attentive Survey of Attention Models》 mendeley 论文翻译和解读1 :zap: 论文解读和翻译2 论文解读和翻译3 Transformer: 《Attention is all you need》Mendeley &OneNote © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 18:05:44 "},"Papers/Transformer.html":{"url":"Papers/Transformer.html","title":"P2:Transformer","keywords":"","body":"1. Transformer Survey1. Transformer Survey @aikenhong 2021 this post is used to write basic infomation about transformer. © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Papers/OpenWorldLearning.html":{"url":"Papers/OpenWorldLearning.html","title":"OpenWorldLearning","keywords":"","body":"1. Open World Learning1.1. Reference1.2. Conclusion1.3. Papers1.3.1. :zap:Open-world Learning and Application to Product Classification1.3.2. :zap:TOWOO1.3.3. Open World Compositional Zero-Shot Learning1.3.4. Open World Semi-Supervised Learning1.3.5. Self-Supervised Features Improve Open World Learning1.3.6. Unseen Class Discovery in Open-World Classification1. Open World Learning @AikenHong2021 OWL 分析现有的OWL特点，和当前自己的研究做一个区分，也汲取一下别人的研究的要点， 1.1. Reference arxiv @ self-supervised feature improve open-world learning arxiv @ open-world semi-supervised learning arxiv @ open-world learning without labels arxiv @ unseen class discovery in open-world classification arxiv @ Open-World Active Learning with Stacking Ensemble for Self-Driving Cars www @ open-world learning and application to product classification cvpr @ open world composition zero-shot learning cvpr @ Towards Open World Object Detection 1.2. Conclusion 1.3. Papers Mulit Open world Learning Definition 拒绝未见过的类的实例，逐步学习新的类扩展现有模型 1.3.1. :zap:Open-world Learning and Application to Product Classification 重点：该模型维护一组动态可见类，允许添加或删除新类，而无需重新训练模型。每个类由以小组训练示例表示，在测试中元分类器仅使用已维护的可见类，进行分类和拒绝。 基于metric进行判别和分类 实际上是一种prototype的方法，通过维护类别原型，使用metric的方法进行是否是已知类别的判断。 Ranker的作用是在每个已知类中抽取与一个测试样例的最近邻的k个已知类样例，然后将这些已知类的k个样例存入Meta-Classifier的Memory中。Meta-Classifier将测试样例与Memory中，经过Matching layer与Aggregation layer输出测试样例属于相应已知类的概率得分。 本文最大的新颖之处在于，在解决开集识别问题时，采用meta-learning的思想，训练集、测试集、验证机中的类别完全不相交。这样做的好处是模型具备增量学习的能力，当源源不断的unknown样例进行测试时，完全不必重新训练模型，提供了open-set classification一种新的模式。 1.3.2. :zap:TOWOO 整体思路类似，聚类方法，标记出感兴趣的类别，然后加入数据库 1）将未识别的对象，识别为unknown 2）在逐步接受相应的标签的时候逐步学习这些未知类别，而不会忘记旧的类别。 使用contrastive cluster和energe-base的方法来对新类进行分类，主要的方法是通过将不确定的类别识别为未知类别。 未知类别识别方法（energe-base） ... 1.3.3. Open World Compositional Zero-Shot Learning 假设搜索空间是先验已知的，也就是存在几种类别是已知的，但是我们训练集中是没有未知类别的，共享特征空间，通过类似A-softmax的方式做匹配分析，通过在已知类别中落入的位置来判断是我们认定的已知类别还是未知类别。 1.3.4. Open World Semi-Supervised Learning 开放世界半监督学习，使用一种同时分类和聚类数据的方法 ORCA： 为了解决这个问题，本文提出了ORCA，一种学习同时分类和聚类数据的方法。ORCA将未标记数据集中的例子分类到以前见过的类中，或者通过将相似的例子组合在一起形成一个新的类。ORCA的关键思想是引入基于不确定性的自适应margin，有效地规避由可见类和新类/簇之间的方差不平衡引起的偏差。本文使用图像分类领域的三个常用数据集（CIFAR-10, CIFAR-100，ImageNet） 进行实验验证，结果表明，ORCA在已知类上的性能优于半监督方法，在新类上也优于新类发现方法。 Method 实际上就是使用半监督SimClr的backbone然后通过设定好的位置类别数目的分类器去做训练，但是这里的损失防止对已知类的偏向性。可以参考文章中的损失 基于对比学习方法SimCLR进行与训练 已知类的分类头用于将未标记的例子分配给已知类，而激活附加的分类头允许ORCA发现新类别。我们假设新类的数量是已知的，并将其作为算法的输入，这是聚类和新类发现方法的典型假设。如果不知道新类的数量，这在现实环境中是经常发生的情况，可以从数据中估计出来。在这种情况下，如果头的数量太多，那么ORCA将不会分配任何例子给一些头，所以这些头将永远不会激活，因此ORCA将自动修剪类的数量。我们在实验中进一步解决了这个问题。 related 了解决这种开放世界的问题，目前有2种思路：(1) OOD检测：能够识别已知类的数据，并且能够将所有未知类的数据检测出来，标为\"unknown\"。这种方法很好的保证了系统鲁棒性，但是无法充分利用未知类数据进行业务扩展；(2) novel class discovery(零样本，领域自适应问题): 利用源域标记数据来学习更丰富的语义表示，然后将学到的知识迁移到目标域（包含新类别），对目标域数据进行聚类。这种方法不能准确识别出已知类，只是对目标域做了聚类。 1.3.5. Self-Supervised Features Improve Open World Learning 特征提取：使用自监督学习来做特征提取器的训练 将新类发现作为特征空间中的位置标签，我们根据检测到的样本属于哪一个空间来做检测 和我的想法还是蛮贴近的，总之也是把新类的标签放置到存储区中，赋予伪标签的过程，然后微调特征提取器，基于后续的数据添加分类器的权重 1.3.6. Unseen Class Discovery in Open-World Classification 通过对已知类别的学习，分析已知类别之间的距离差异； 本文的模型提出了一个contrasive模型，对实例属于同一类还是不同类进行分类，该子模型也可以作为聚类的距离函数. © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Papers/OpenMix.html":{"url":"Papers/OpenMix.html","title":"P1:OpenMix","keywords":"","body":"1. OpenMix: Reviving Known Knowledge for Discovering Novel Visual Categories in An Open World1.1. Intro1.2. Detail1.3. 异同点分析1. OpenMix: Reviving Known Knowledge for Discovering Novel Visual Categories in An Open World @Aiken 2021 究极万恶的撞车论文 1.1. Intro Motivation ：Tackle the problem of 发现无标注数据中与给定（已知）类别不相交的新类。 Related Research： 现有的方法通常1. 使用标记数据对模型进行预训练； 2. 无监督聚类在未标记的数据中识别新的类 作者认为label带来的essential knowledge在第二步中没有被充分学习利用到，这样模型就只能从第一步的现成知识中获益，而不能利用标记数据和未标记数据之间的潜在关系 Hypothesis： 有标记的类别和无标记的类别之间没有Overlap，这样导致在两个类别之间很难建立学习关系，（为啥我感觉这个说的都是屁话） Solution： Openmix：将标注的数据和未标注的数据同时混合起来得到一个联合标签的分布中，用两种方式来动态合成示例： 我们混合标记和未标记数据作为Training Img，混合了已知类别的先验生成的伪标签会比无监督情况下生成的伪标签跟家的可靠？防止在错误的伪标签前提下发生过拟合 在第一步的时候我们鼓励具有高类别置信度的无标记example作为可考虑的类别，然后我们将这些samples作为anchor，并将它们进一步的和无标注的samples整合，这使得我们能够对无标注数据产生更多的组合，并发现更精细的新类关系。 1.2. Detail 果然在混合的方式上和MixUp的策略进行比对了，就是diss了Mixup使用伪标签的情景可能会进一步的引入不确定性，导致算法的效果反向优化，就是再label和unlabeled数据上混用mixup，而不是单纯的对unlabel数据集进行混合。 首先将没有overlap的标签表现为联合标签分布再进行混合，也就是加长onehot，这样的标签的优越性在？对于unlabelled data引入了确定性，防止标签容易过拟合。也就是给伪标签加入了一个锚定，让他能够变化的更平滑 这尼玛这张图看了不久完事了，bibi一大堆啥的呢。主要分析一下三个损失函数代表的是什么意思。 对其中的$L_{ppl}$进行特殊的说明： 由于输入的是pair，所以添加的一个损失也就是分类是否属于同一类，二分类ce 使用的是cos similarity，通过threshold 来判断是否是同一类， 实际上应该也是一个预训练的模块，在实际进行的过程中由于是对无标注数据进行处理，讲道理是无法计算损失的，也没有开源代码。 1.3. 异同点分析 初步分析结果： 不使用无监督聚类的方法对新类进行发现，而是使用其他的策略 好像没有使用增量学习的方法进行class-incremental的增量处理，主要的motivation好像是Discovering，并没有Incremental的部分 新数据的组合方式是怎么样的这点好像值得研究一下 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Papers/OpenWorld_Object_Detector.html":{"url":"Papers/OpenWorld_Object_Detector.html","title":"P2:OpenWorld Object Detector","keywords":"","body":"1. Open World Object Detector1.1. 思路分析1.1.1. Motivation1.1.2. ENERGY BASED1.1.3. Alleviating Forgetting1.1.4. Workflow1. Open World Object Detector @Aiken 2021 框架撞车系列，主要看看这一篇论文中怎么解决如下的问题&#x1F447;，并从中借鉴和优化的我框架设计 [ ] 置信度的模块构成，相应的pool的构建 [ ] 新类的划分和新类原型的建立 [ ] Incremental Learning的思路和实现方式 1.1. 思路分析 1.1.1. Motivation 模型实现的主要的两个TASK： Open Set Learning ： 在没有明确监督的时候，将尚未引入的目标类别识别为未知 Incremental Learning：类别增量学习 实现这两个问题的主要思路： 自动标注：借鉴RPN的class-agnostic，以及检测和分类的显著性指标的差异，找到并自动标注NewClass 对比聚类：使用prototype feature来进行聚类，同时计算Distance损失 it seems like contain a unknown prototype. energy based：亥姆霍兹自由能公式？ 1.1.2. ENERGY BASED Feature：$F$, Label: $L$ , Energy:$E(F,l)$ 能量函数倾向于将已知的类别分类到低熵的分布上，然后我们可以根据特征在能量空间上的划分来区分新类和旧类。然后我们可以根据logits表达的softmax形式，找到输出和Gibbs distribution的相关性： \r p(l \\mid \\boldsymbol{f})=\\frac{\\exp \\left(\\frac{g_{l}(\\boldsymbol{f})}{T}\\right)}{\\sum_{i=1}^{\\mathrm{C}} \\exp \\left(\\frac{g_{i}(\\boldsymbol{f})}{T}\\right)}=\\frac{\\exp \\left(-\\frac{E(\\boldsymbol{f}, l)}{T}\\right)}{\\exp \\left(-\\frac{E(\\boldsymbol{f})}{T}\\right)}\r 通过这个相关性，我们对自由能进行一个定义，以logits的形式表达 \r E(f:g) = -T log\\sum_{i=1}^{C}exp(\\frac{g_i(f)}{T})\r g实际上表示特征最后输出的logits，通过能量的映射函数，我们将聚类转移到能量域上做，置信度较高的类别和未知的新类实际上有一个比较明显区分的分界线。 实际上我觉得就是类似熵的形式，在本文中将softmax的形式和gibis自由能做了一个对比，然后相当于对logits映射到了能量的维度去做特征的对比聚类，同时也能看出，在能量这个隐层空间中，在能级上能对已知类别和未知类别之间有一个明显的区分，所以在能级上进行划分是一个比较合理的空间映射形式。 1.1.3. Alleviating Forgetting 参数正则化方法：exemplar replay：动态扩张网络；元学习 增量学习中提到的一些贪婪的参数选择策略好像对SOTA的方法都有很大的优势；后续又有人发现存储少量的示例和replay的有效性在相关的Few-Shot Detect中式有效的。 本文采用相对简单的ORE方法来减缓灾难性遗忘的问题，也就是说存放了一组平衡的范例，在每个增量步骤后对模型进行微调，确保每个类最少有$N_{ex}$个示例出现在例子集中。 实际上说的就是每次增量学习之后都会进行数据集的混合然后朝着原本的方向进行一定的微调；好像也没有什么特别的把，具体的实现可能要参见代码。 1.1.4. Workflow 我认为是通过RPN和class-aware之间的插值直接直接标注的一个未知的类别，然后在后续直接让人类区标注感兴趣的样本，可能是从少到多的，并没有一个特定的POOL，原本的模型可能有预留的Unknown Class或者说是相应的预留输出节点，然后在获得新的数据标注之后，进行更新模型的训练，然后使用避免灾难性遗忘的策略去做，从而使得模型对新的类别存在认知，也不会忘记旧的类别的知识。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Papers/KnowledgeEvolution.html":{"url":"Papers/KnowledgeEvolution.html","title":"P3:KnowledgeEvolution","keywords":"","body":"1. Knowledge Evolution in Neural Networks1.1. Intro引子1.2. 理论与实现细节1.2.1. The Knowledge Evolution Training Approach1.2.2. Split-Networks1.2.3. Knowledge Evolution Intuition1.3. Code细节&使用情景1. Knowledge Evolution in Neural Networks @Aiken 2021.4.7 Article：只能当成OverView，技术细节写的很差；Mendeley； Code_PyTorch 1.1. Intro引子 Problem：如何在较小的数据集上训练神经网络，这到底是个小样本的方法还是个类别增量的方法？ Motivation： 考虑生物“基因”进化的方式，有一部分是“祖传”，另一部分是“适应”，通过对“祖传”的假设的不断学习进化，得到一个新的模型。 基因编码了从祖先到后代的遗传信息（知识），而基因传递将遗传信息从父母传递至其后代。虽然祖先并不一定具有更好的知识，但是遗传信息（知识）在几代人之间的发展将会促进后代更好的学习曲线。 Hypothesis： 拟合假设$H^{origin}$： 重置假设：$H^{later}$ TOBEUPDATE：将神经网络拆分成两个假设(子网络)：通过重新训练多代网络来进化$H^{origin}$ 中的知识，每一代都会扰乱$H^{later}$的内部权重来鼓励$H^{origin}$ 学习独立的表达形式。 将深度神经网络的知识封装在一个名为拟合假设的子网络H中，将拟合假设的知识从父母网络传递至其后代，即下一代神经网络。并反复重复此过程，在后代网络中证明了其性能的显著提升： Contribution： 提出了KELS（内核级卷积感知拆分），为CNN量身定做。虽然增加了训练时间，但是大大降低了推理成本，也减轻了较小数据集中的过拟合问题。 提出了KE，提升网络在较小数据集上的性能 KELS，训练时自动学习slim网络，支持CNN，降低推理成本 Related Work 与两种不同的训练方法作比较 DSD：在网络结构上与这种dense-sparse-dense 1.2. 理论与实现细节 上图展示的是 普通Fliter：3in 4out 修正后在ResNet中的Fliter：拆分成两部分假设，深蓝色的是拟合假设，浅灰色的是重置假设。 1.2.1. The Knowledge Evolution Training Approach L：layers_num；N：network；F：Fliter（Convolution Kernal） Z：Batch Norm；W（FC）：weight；B（FC）：bias；M：0-1 mask（binary） 首先从概念上将网络划分成两个子网的部分，$H^f$、$H^r$，对网络进行随机初始化，然后再e个epoch之后得到generation 1的Network（N1），也就能提取出对应的H. :star:Iteration（迭代到下一代） 基因的贡献直到对下一代网络进行初始化，后续的操作就是“适者生存的部分了” #LOOP 使用$H^f$重新初始化N：使用$H^f$中的F和W去初始化N2，剩下的部分（$H^r$）中的参数进行随机的初始化，初始化的形式可以表达成如下的公式，（随机的部分使用指定好的分布去随机） 重新e个epochs训练进化成N2。 \r F_l = M_lF_l + (1-M_l)F_l^r\r #END LOOP 1.2.2. Split-Networks 这个框架在实现的时候涉及到Fliter的拆分，所以这部分实际上是文章的核心技术难点。 使用两种分裂技术来支持KE： 这种玩意你不看代码谁知道在写什么 weight-level splitting：按照split-rate，使用0-1mask对每一层的参数进行随机的split。 kernel-level convolutional-aware splitting：代替了对每个单独的权重进行mask，我们直接对kernels做mask，如下图所示 1.2.3. Knowledge Evolution Intuition KE的结构和ResNet和Dropout进行对比，之间的异同，一些直观或者直觉上的理解。 1.3. Code细节&使用情景 这个方法实际上是针对的小样本？相对少样本？的使用情景，通过不断的部分继承和迭代，用DNA的方式传播到后续的网络结构中，感觉这个的使用场景还挺blur的，TOBECONTIUNE. 这种评估和消融实验的测试方式的选择！ © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Papers/EfficientNet.html":{"url":"Papers/EfficientNet.html","title":"B1:EfficientNet","keywords":"","body":"1. Efficient Net2. Efficient Net V12.1. Motivation and Method2.2. Experience Detail2.2.1. 实现中的问题：1. Efficient Net Desc: Backbone Finished?: Yes Tags: Paper URL1: https://arxiv.org/pdf/1905.11946.pdf URL2: https://arxiv.org/pdf/2104.00298.pdf 提出了一种模型缩放策略，如何更高效的平衡网络的深度、宽度、和图片分辨率 **1. Efficient Net: Rethinking Model Scaling for Convolutional Neural Networks EfficientNetV2: Smaller Models and Faster Training** @Aiken H 2021 find detail to code his 2. Efficient Net V1 除了提出了缩放策略以外，还使用神经架构搜索还建立了一个新的baseline network，得到了一系列模型。 平衡网络宽度、深度、分辨率至关重要，这种平衡可以通过简单的恒定比率缩放维度来实现，于是我们提出了一种简单有效的复合缩放方法。 复合缩放的物理意义：输入图像更大的话就需要更多层来增加感受野和更多通道，从而能在更大的图像上捕获更多细粒度的图案，而宽度和深度（对于表达能力来说很重要）之间也存在着一定的关系，“我们”是第一个对此进行了建模的。 从各个维度单独的进行缩放能发现都存在着增益瓶颈，如何去得到这么一个合适的等比缩放增益 2.1. Motivation and Method 一些直观上的motivation，以及假想 不同的缩放维度不是独立的 直观上，对于更高分辨率的图像我们应该增加网络深度。 这样更大的感受野可以帮助捕捉更大图像中包含的更多像素的相似特征 相应的，更高分辨率的图像也应该增加网路的深度以便再高分辨率图像中捕获具有更多像素的更细粒度的图案。 基于实验最终得到了这样的结果： depth: d = \\alpha^\\phi width: w = \\beta^\\phi resolution: r = \\gamma^\\phi s.t. \\alpha · \\beta^2 · \\gamma^2 \\approx 2 \\alpha \\geq 1, \\beta \\geq 1, \\gamma \\geq 1 求解方法： 固定φ，然后通过网格搜索得到最基本的模型 Efficient Net-B0 固定α、β、γ的值，使用不同的φ，得到相应的B1 -B7 2.2. Experience Detail github.surf github.surf EfficientNet网络结构图_LYS_1129的博客-CSDN博客_efficientnet网络结构 图解EfficientNet模型的完整细节 EfficientNet网络解析_bblingbbling的博客-CSDN博客_efficientnet网络结构 EfficientNet B0-B7 网络参数_繁华落尽，寻一世真情的博客-CSDN博客 从第三个连接中，我们可以整理出那些需要input的相关参数，然后输入网络中去建立该Model。 2.2.1. 实现中的问题： blockN stride和padding在各个重复组合层中间的变化（只有DW卷积改变Imageview）（堆叠的层不改变相应的HW），也是由第一个层去进行处理 channel，在各个组合层之间的变化（堆叠的层刚好不改变channel数目） © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 18:25:37 "},"Papers/Involution.html":{"url":"Papers/Involution.html","title":"B2:Involution","keywords":"","body":"1. Involution:Inverting the Inherence of Convolution for Visual Recognition1.1. Intro 引子1.2. 基本思想1.3. 要点分析1.3.1. 生成FeatureMap对应Size的Kernel1.3.2. 与Self-Attention的联系1.3.3. Mathematical1. Involution:Inverting the Inherence of Convolution for Visual Recognition @Aiken 2021-4-8 Ariticle ；Paper；:star:Code； ZHIHU 1.1. Intro 引子 提出了一种新的神经网络算子（operator或op）称为involution，它比convolution更轻量更高效，形式上比self-attention更加简洁，可以用在各种视觉任务的模型上取得精度和效率的双重提升。 通过involution的结构设计，我们能够以统一的视角来理解经典的卷积操作和近来流行的自注意力操作。 1.2. 基本思想 将传统Convolution Kernel 的两个基本特性： 空间不变性：在同个通道的HW上共享3*3的卷积系数，参数共享； 通道特异性：在每个通道上有特异的卷积核，最终使用1*1 like的方式来进行通道间的整合 反对称的修改成： 空间特异性： 对每个Feature有对应size $H·W·K·K·G | G G表示Involution操作的分组数，如果需要下采样，就需要接步长为2的平均池化层，最终可以得到，实际上是一个分组卷积的方式，也就是说，我们K个一组的共享一个Kernel。用G去切分C，最终组合起来 通道不变性：对每个通道之间共享这样的kernel，然后做简单的线性整合，对每个不同的channel有相同的处理方式。 传统的卷积基于邻域相关性的思想，同时旨在同一个channel中用单一的角度去分析特征，所以有空间不变性核通道特异性的这两个特征。 而Involution实际上更像是Self-Attention这种思路，通过Whole-Size的Kernel，执行一个特异性处理？ 1.3. 要点分析 这一部分主要介绍一些实现上的技术/理论要点： 1.3.1. 生成FeatureMap对应Size的Kernel 通用的公式如下，我们可以自定义对应的Kernel生成Function，这是算法的开放性和潜力所在。 \r \\mathbf{H}_{i,j} = \\phi(\\mathbf{X}_{\\Psi_{i,j}}) \\\\\r \\Psi_{i,j} 是邻域的一个index集合，\\mathbf{X}_{\\Psi_{i,j}}是包含i,j的邻域的一个patch\r 其中可能会包含一些线性变换和通道缩减之类的变换，一种简单的实例化可以由下图来理解。 对某个index，首先转化生成对应的$K^2$，对应的Value，然后通过加权整合得到最终的OutputValue， Channel 数的放射就又我们的对应生成的Kernel数去控制。 有点NIN那味了，反正就是嵌套，架构，用MLP得到Kernel，用Kernel进行降维和信息交互。 The Author Says:&#x1F447; 无论是convolution，self-attention还是新的involution都是message passing和feature aggregation的组合形式，尽管外表各异，本质上没有必要割裂开来看。 1.3.2. 与Self-Attention的联系 将Self-Attention的QKV展开成WX的形式，可以发现实际上Involution是Self-Attention的一个General的表达形式， self-attention中不同的head对应到involution中不同的group（在channel维度split） self-attention中每个pixel的attention map $QK^T$对应到involution中每个pixel的kernel 同时两者在操作后都会加一个线性变换和残差链接，这和Involution中的对应BottleNet也存在一致 Position encoding self-attention中的计算是loacation-agnostic的所以需要进行position-encoding，但是involution，生成的元素本身就是按照location排列的，所以不需要进行位置编码。 此外，Involution保留了CNN中locally的优先特性。： 因此，我们重新思考self-attention在backbone网络结构中有效的本质可能就是捕捉long-range and self-adaptive interactions，通俗点说是使用一个large and dynamic kernel，而这个kernel用query-key relation来构建则并不是必要的。另一方面，因为我们的involution kernel是单个pixel生成的，这个kernel不太适合扩展到全图来应用，但在一个相对较大的邻域内应用还是可行的），这同时也说明了CNN设计中的locallity依然是宝藏，因为即使用global self-attention，网络的浅层也很难真的利用到复杂的全局信息。 所以我们所采用的involution去除了self-attention中很多复杂的东西，比如我们仅使用单个pixel的特征向量生成involution kernel（而不是依靠pixel-to-pixel correspondence生成attention map），在生成kernel时隐式地编码了pixel的位置信息（丢弃了显式的position encoding），从而构建了一个非常干净高效的op。 1.3.3. Mathematical 画一下计算图来看看实际上是怎么运行的，这里最后的size变换还没弄清楚计算的规则 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Papers/Pooling.html":{"url":"Papers/Pooling.html","title":"B3:Pooling","keywords":"","body":"1. Pooling2. DownSampling：Pooling的全面调研2.1. 池化的根本目的（Motivation）2.2. 主流的池化方法2.2.1. Average Pooling 平均池化2.2.2. Max Pooling 最大值池化2.2.3. Mixed pooling2.2.4. L_p pooling2.2.5. Stochastic Pooling2.2.6. Spatial Pyramid Pooling （SPP）2.2.7. YOLO v3 变体2.2.8. SPP有效的原因分析2.2.9. Region of Interest Pooling （ROI Pooling）2.2.10. ROI Align的改进2.3. 新颖特殊的池化方法2.3.1. 中值池化2.3.2. 组合池化2.3.3. Multi-scale order-less Pooling MOP池化2.3.4. NetVLAD Pooling2.3.5. 双线性池化2.3.6. UnPooling上采样操作2.3.7. 光谱池化2.3.8. 基于排名的均值池化2.3.9. 基于权重的池化2.3.10. Edge-aware Pyramid Pooling1. Pooling Detail: survey Finished?: Yes Tags: Paper 2. DownSampling：Pooling的全面调研 @Aiken 2021 笔记摘录： 深度神经网络中的池化方法：全面调研（1989-2020） - 知乎 ；相同论文的简单中文Version 16页综述，共计67篇参考文献。网络千奇百怪，但基础元素却大致相同！本文全面调研了1989至2020年一些著名且有用的池化方法，并主要对20种池化方法进行了详细介绍（这些方法，你都知道么？） 注1：文末附【计算机视… 来自 https://zhuanlan.zhihu.com/p/341820742 原文：《Pooling Methods in Deep Neural Networks, a Review》 整合2 2.1. 池化的根本目的（Motivation） 卷积神经网络是DNN的一种特殊类型，它由几个卷积层组成，每个卷积层后都有一个激活函数和一个池化层。 池化层是重要的层，它对来自上一层的特征图执行下采样，并生成具有简化分辨率的新feature maps 。该层极大地减小了输入的空间尺寸。 它有两个主要目的。 首先是减少参数或权重的数量，从而减少计算成本。 第二是控制网络的过拟合。 池化可以增加网络对于平移（旋转，伸缩）的不变性，提升网络的泛化能力。 增大感受野； 降低优化难度和参数数目， 理想的池化方法应仅提取有用的信息，并丢弃无关的细节。 特征不变性、特征降维、在一定程度上防止过拟合，更方便优化 2.2. 主流的池化方法 2.2.1. Average Pooling 平均池化 没啥好说的，就是每个block取一个均值。如下图所示：更关注全局特征 2.2.2. Max Pooling 最大值池化 更关注重要的局部特征 image-20210219153154458 2.2.3. Mixed pooling 在max、average pooling中进行随机选择，来组合pooling 2.2.4. L_p pooling 作者声称这个泛化能力比Max Pooling要好，输入的平均值权重（也就是和分之一）来进行，算是推广的公式。 s_j = (\\\\frac{1}{|R_j|}\\\\sum_{i \\\\in R_j}{a_i^p})^{1/p} 2.2.5. Stochastic Pooling feature_map中的元素按照其概率值大小随机选择，元素被选中的概率与数值大小正相关，这就是正则化操作了。 image-20210219160011182 2.2.6. Spatial Pyramid Pooling （SPP） SPPNet在RCNN之后提出的，用于解决重复卷积计算和固定输出的问题，具体的方法是：在Feature_Map中通过Selective Search获得窗口然后输入CNN中。 这个池化方法实际上就是多个空间池化的组合，对不同的输出尺度采用不同的划窗大小和步长来确保输出的尺度相同，同时能够融合多种尺度特征，提供更丰富的语意信息，常用于： 多尺度训练 目标检测中的RPN 实际上也就是（全图pooling一次，全图分成22块Pooling，全图分成44块以后 做Pooling，然后就是固定尺寸的了，前面的输出是256-d 然后就是（4+16+1）* 256 最后的特征 image-20210219160238878 2.2.7. YOLO v3 变体 在YOLO v3中，有一个网络结构中的yolo-v3-spp比原本的准确率更高，具体的cfg如下： ### SPP ### [maxpool] stride=1 size=5 [route] layers=-2 [maxpool] stride=1 size=9 [route] layers=-4 [maxpool] stride=1 size=13 [route] layers=-1,-3,-5,-6 ### End SPP ### 这里的SPP是原本的SPPNet的变体，通过多个Kernel Size的maxpool 将最终得到的feature map进行concate，得到新的特征组合： 2.2.8. SPP有效的原因分析 从感受野角度来讲，之前计算感受野的时候可以明显发现，maxpool的操作对感受野的影响非常大，其中主要取决于kernel size大小。在SPP中，使用了kernel size非常大的maxpool会极大提高模型的感受野，笔者没有详细计算过darknet53这个backbone的感受野，在COCO上有效很可能是因为backbone的感受野还不够大。 第二个角度是从Attention的角度考虑，这一点启发自CSDN@小楞（链接在参考文献中），他在文章中这样讲： 出现检测效果提升的原因：通过spp模块实现局部特征和全局特征（所以空间金字塔池化结构的最大的池化核要尽可能的接近等于需要池化的featherMap的大小）的featherMap级别的融合，丰富最终特征图的表达能力，从而提高MAP。 Attention机制很多都是为了解决远距离依赖问题，通过使用kernel size接近特征图的size可以以比较小的计算代价解决这个问题。另外就是如果使用了SPP模块，就没有必要在SPP后继续使用其他空间注意力模块比如SK block，因为他们作用相似，可能会有一定冗余。 2.2.9. Region of Interest Pooling （ROI Pooling） 参考链接：原理以及代码实现；Some Detail 以及Align的改进；Best One 对于ROI pooling 的讲解首先要从目标检测的框架出发，帮助理解， 目标检测分为两步： region proposal：输入image，找到所有可能的object的位置（bounding box），也就是ROI，在这过程中可能用到滑窗和selective search。 final classification：确定上阶段的每个region proposal是否是目标类别，或者背景 这样的框架存在问题： 大量的ROI要进行计算，就很难实时监测，也无法做到E2E 使用ROI Pooling进行简化，输入和作用如下： 从多个具有卷积核池化的深度网络中获得固定大小的Feature-Map； 对不同尺寸的ROI进行处理，能得到统一的尺寸。 一个表示所有ROI的N*5的尺寸，N是数目，5维度分别是Index，左上角坐标，右下角坐标 具体实现的操作： 根据输入image，将ROI映射到feature map对应位置； 将映射后的区域划分为相同大小的sections（sections数量与输出的维度相同）； 对每个sections进行max pooling操作； 这样我们就可以从不同大小的方框得到固定大小的相应 的feature maps。值得一提的是，输出的feature maps的大小不取决于ROI和卷积feature maps大小。ROI pooling 最大的好处就在于极大地提高了处理速度。 下图大黑框是对应的ROI，输出最后的要求是2*2，基于下面的划分再进行maxpooling即可。 2.2.10. ROI Align的改进 ROI pooling在映射的时候出现小数，这是第一次量化，在每个roi中选取多少个采样点进行max pooling也会出现小数。这样的处理可能会丢失数据，降低了模型的精度 ROI Align并不需要对两步量化中产生的浮点数坐标的像素值都进行计算，而是设计了一套优雅的流程。如图2，其中虚线代表的是一个feature map，实线代表的是一个roi(在这个例子中，一个roi是分成了2*2个bins)，实心点代表的是采样点，每个bin中有4个采样点。我们通过双线性插值的方法根据采样点周围的四个点计算每一个采样点的值，然后对着四个采样点执行最大池化操作得到当前bin的像素值。 RoI Align做法：假定采样点数为4，即表示，对于每个2.97 x 2.97的bin，平分四份小矩形，每一份取其中心点位置，而中心点位置的像素，采用双线性插值法进行计算，这样就会得到四个小数坐标点的像素值。 实际上就是用双线性插值来取代了ROI Pooling的量化过程。 2.3. 新颖特殊的池化方法 这一部分的池化方法存在着一些特殊的特性，在实际需要的时候再进行仔细的研究，但是可以将大体的特征简单的描述一下，方便后续寻找。 2.3.1. 中值池化 与中值滤波特别类似，但是用的特别少，中值池化也具有学习边缘和纹理结构的特性，抗噪声能力比较强。 2.3.2. 组合池化 就是将max 和 average concate或者add起来。 2.3.3. Multi-scale order-less Pooling MOP池化 基于多尺度的池化方式，提升了卷积网络的不变性同时没有破坏卷积网络的可鉴别性，分布从全局与局部池化中提取特征，图示与说明如下： 2.3.4. NetVLAD Pooling NetVLAD是论文《NetVLAD: CNN Architecture for Weakly Supervised Place Recognition》提出的一个局部特征聚合的方法。 2.3.5. 双线性池化 Bilinear Pooling是在《Bilinear CNN Models for Fine-grained Visual Recognition》被提出的，主要用在细粒度分类网络中。双线性池化主要用于特征融合，对于同一个样本提取得到的特征x和特征y, 通过双线性池化来融合两个特征(外积)，进而提高模型分类的能力。 2.3.6. UnPooling上采样操作 1.在Pooling（一般是Max Pooling）时，保存最大值的位置。 2.中间经历若干网络层的运算。 3.上采样阶段，利用第1步保存的Max Location，重建下一层的feature map。 UnPooling不完全是Pooling的逆运算，Pooling之后的feature map，要经过若干运算，才会进行UnPooling操作；对于非Max Location的地方以零填充。然而这样并不能完全还原信息。 2.3.7. 光谱池化 图像池化不光发生在空间域，还可以通过DFT变换，在频域空间实现池化，一个使用光谱池化最大池化的例子如下： 2.3.8. 基于排名的均值池化 Rank-based Average Pooling 这种池化方式的好处事可以克服最大池化与均值池化方式的不足 S_j = \\\\frac{1}{t}\\\\sum_{i\\\\in R_{j,r_i 2.3.9. 基于权重的池化 2.3.10. Edge-aware Pyramid Pooling Survey_NIPS 中国预讲会.md © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Algorithms/HardTask.html":{"url":"Algorithms/HardTask.html","title":"B4:HardTask","keywords":"","body":"1. Trick：Hard Task1.1. 基本思路1.1.1. 对比Adaboost1.1.2. 具体实现1. Trick：Hard Task @Aiken 2020 思路来源于Meta-Tranfer-Learning，基本思路是在Meta-Learning的每一次Meta-Test的时候，会从预训练错误率比较高的Task中再次采样，增加那些task的训练次数。也就是难题多做的策略。 1.1. 基本思路 1.1.1. 对比Adaboost 这样的思路其实和AdaBoost的想法是有一定的异曲同工之妙的，或者说其实就是AdaBoost的思路： Adaboost 参考笔记，从该笔记中我们可以看到，AdaBoost的基本思路如下： Boosting算法的工作机制是首先从训练集用初始权重训练出一个弱学习器1，根据弱学习的学习误差率表现来更新训练样本的权重，使得之前弱学习器1学习误差率高的训练样本点的权重变高，使得这些误差率高的点在后面的弱学习器2中得到更多的重视。然后基于调整权重后的训练集来训练弱学习器2.，如此重复进行，直到弱学习器数达到事先指定的数目T，最终将这T个弱学习器通过集合策略进行整合，得到最终的强学习器. 和Meta-Transfer-Learning对比一下，我们可以发现，这个方法实际上就是讲Transfer Learning的与训练网络当成弱学习器1，然后通过弱学习器1的训练样本权重，来增大Hard-Task的配比（也就是增加任务的权重）完全一致。 1.1.2. 具体实现 实现上主要是，样本sample的过程，就是如何在进行参数选择后和原本的Dataloader，结合起来。在这里我们主要参考MTL中的方法，进行网络的构建处理。 第一部分：sampler构建，为了后续Dataloader中进行数据的采样，需要构建一个这样的sampler，关键在于index的对应关系，以及最后输出的是index的集合。 import torch import numpy as np # 注意的点，我们需要确定我们batch数目，cls数目和每次每个cls选出多少个数据per # 紧接着定义一个sample，sample输出的是对应原dataset中的数据的index， class CatagoriesSampler(): def __init__(self, label, n_batch, n_cls, n_per): self.n_batch = n_batch self.n_cls = n_cls self.n_per = n_per label = np.array(label) # 根据不同的label输入情况，我们可可能需要找到每个label对应的样本的index，将其整合在一起。如下（option） self.m_idx = [] for i in range(max(label)+1): idx = np.argwhere(label==i).reshape(-1) idx = torch.from_numpy(idx) self.m_idx.append(idx) def __len__(self): # 要注意一下这里数据的长度是根据我们要输出的batch数目决定的 return self.n_batch def __iter__(self): # 直接定义每次采样的时候的batch输出 for i_batch in range(self.n_batch): batch = [] classes = torch.randperm(len(self.m_idx))[:self.n_cls] for c in classes: # 随机选择出的类标签 l = self.m_idx[c] # 随机选择样本 random_pos = torch.randperm(len(l))[:self.n_per] batch.append(l[random_pos]) # stack t and reshape的作用&#x1F447; # stack 变成n_cls * n_per , t转置，reshape（-1）变成行向量 batch = torch.stack(batch).t().reshape(-1) yield batch 第二部分：直接调用部分 其实就是很简单的Dataloader中就有这个参数设置，只需要定义好sampler就没什么太大的问题了。 self.trainset = Dataset('train', self.args) self.train_sampler = CategoriesSampler( self.trainset.label,self.args.num_batch, self.args.way, self.args.shot+self.args.train_query) self.train_loader = DataLoader( dataset=self.trainset,batch_sampler=self.train_sampler, num_workers=8, pin_memory=True) # 关键的地方在于最后一样的batch_sampler，这个在pytorch的dataload文档中分析过，就是每次会按这个规则在这里采样数据出来，一起训练。 第三部分：Hard-Task的选取 以什么形式或者标准来对Hard-Task进行选择，以及构建这个label list，因为我们知道，很多时候dataloader是不输出index的。 本文作者tmd直接偷懒，直接用数据集的label，也就是根本就不是Hard-Task的处理 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Papers/Causal Analysis.html":{"url":"Papers/Causal Analysis.html","title":"Causal Analysis 因果分析","keywords":"","body":"1. Causal Analysis1.1. 现阶段机器学习存在的问题1. Causal Analysis @Aiken 2021.04.07 这篇文档目前就是一个motivation，暂时不去看综述，分析一下为什么我们需要Causal Analysis，后续进行系统性的学习。 1.1. 现阶段机器学习存在的问题 参考文章链接 受限于iid基本假设：现阶段的机器学习，严重受限于训练数据的分布情况，（因为我们把复杂的问题转化为i.i.d的分布，但是在现实应用场景下实际上很多时候并不是这个分布。 而现实的应用场景往往不满足这种独立同分布的假设，那么：「要在i.i.d.环境之外对对象进行很好的概括，不仅需要学习变量之间的统计关联，还需要学习一个潜在的因果模型。」 「当学习一个因果模型时，我们应该需要更少的例子来适应大多数知识，比如创造一个模块，这样这个模型可以在不需要进一步训练的情况下重用。」 当在外界的干预下改变一个问题的统计分布的时候，因果的模型仍然是稳健的，但是普通机器学习就并不是，所以用因果来解决机器学习泛化性能的是一个比较好的思路 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Papers/GANs.html":{"url":"Papers/GANs.html","title":"GANs 生成对抗网络","keywords":"","body":"1. `fGAN：对GAN理论的深度理解1.1. 基本理论体系和推演1.1.1. Fenchel Conjugate共轭1.1.2. F-Div GAN推导1.2. JS Div不是最佳的Div1.2.1. LSGAN最小二乘1.2.2. Wasserstein-GAN1. `fGAN：对GAN理论的深度理解 @Aiken 2021 onenote部分的拓展编写，到时候拷过去，整合在一起。 fGAN: 不只是JS-Div散度，我们可以将所有的散度都应用到GANs的框架中。该部分的阅读是对GAN的基本理论最重要的文章之一。 1.1. 基本理论体系和推演 首先给出fGAN中提出的基本理论：可以将所有的Div放入GANs的框架中，来做那个核心的关键演化判别指标： \r D_{f}(P||Q) = \\int_xq(x)f(\\frac{p(x)}{q(x)}dx)\r 上述公式将衡量P和Q两个分布之间的差距，公式中的$f$可以是很多不同的版本，但是要求满足如下的两个条件： 是一个凸函数；$f(\\frac{(x1+x2)}{2})\\leq \\frac{[f(x1)+f(x2)]}{2}$，需要注意国内外的凹凸相反 $f(1)=0$。 而我们知道$q(x)$是概率密度分布函数，实际上可以看成凸函数性质的推广，所以我们可以证得： \r D_{f}(P||Q) = \\int_xq(x)f(\\frac{p(x)}{q(x)}dx) \\geq\r f(\\int q(x) \\frac{p(x)}{q(x)} dx) = f(1) = 0\r 显然当我们取得合适的f，KL（$f(x) = xlog(x)$）; ReverseKL($-log(x)$)；chi square ($f(x) = (x-1)^2$)； 1.1.1. Fenchel Conjugate共轭 补充Fenchel共轭的知识来对后续的fGAN推导进行补充，定理内容如下： 每个凸函数都有一个对应的共轭函数读作$f^*(x)$ \r f^*(x) = \\max \\limits_{x\\in dom(f)} xt - f(x)\r t是给定的，对于所有的变量t， $xt-f(x)$对应了无数条直线： 举个例子$f(x)=xlog(x)$时，我们可以将对应的$f^*(x)$画出来。 实际上就是对给定的t，求$g(x)$共轭方程的最大值的过程，求个导，然后就可解得$x->t$然后带回就能得到共轭方程。 介绍共轭方程主要是为了和$f(x)$进行转化 \r f^{*}(t)=\\sup _{x \\in \\operatorname{dom}(f)}\\{x t-f(x)\\} \\quad \\Leftrightarrow \\quad f(x)=\\max _{t \\in \\operatorname{dom}\\left(f^{*}\\right)}\\left\\{x t-f^{*}(t)\\right\\}\r 1.1.2. F-Div GAN推导 将转化方程带入，利用简单的不等式转化，我们就能将之前的F-Div转换为一个类似GAN的式子： \r \\begin{aligned}\r D_{f}(P \\| Q) &=\\int_{x} q(x) f\\left(\\frac{p(x)}{q(x)}\\right) d x \\\\\r &=\\int_{x} q(x)\\left(\\max _{t \\in \\operatorname{dom}\\left(f^{*}\\right)}\\left\\{\\frac{p(x)}{q(x)} t-f^{*}(t)\\right\\}\\right) d x \\\\\r & \\geqslant \\int_{x} q(x)\\left(\\frac{p(x)}{q(x)} D(x)-f^{*}(D(x))\\right) d x \\\\\r &=\\int_{x} p(x) D(x) d x-\\int_{x} q(x) f^{*}(D(x)) d x \\\\\r & \\approx \\max _{D} \\int_{x} p(x) D(x) d x-\\int_{x} q(x) f^{*}(D(x)) d x\r \\end{aligned}\r 解释一下：第三行就是由于t是随便取值的；最后一行就是我们要求一个D使得式子最大，上界实际上就是第二行的式子。 这样我们就能推导出F-Div的变体： \r \\begin{aligned}\r D_{f}(P \\| Q) & \\approx \\max _{D} \\int_{x} p(x) D(x) d x-\\int_{x} q(x) f^{*}(D(x)) d x \\\\\r &=\\max _{D}\\left\\{E_{x \\sim P}[D(x)]-E_{x \\sim Q}\\left[f^{*}(D(x))\\right]\\right\\}\r \\end{aligned}\r 对于生成器来说，我们就是要找到一个PG使得： \r \\begin{aligned}\r G^{*} &=\\arg \\min _{G} D_{f}\\left(P_{\\text {data }} \\| P_{G}\\right) \\\\\r &=\\arg \\min _{G} \\max _{D}\\left\\{E_{x \\sim P_{\\text {data }}}[D(x)]-E_{x \\sim P_{G}}\\left[f^{*}(D(x))\\right]\\right\\} \\\\\r &=\\arg \\min _{G} \\max _{D} V(G, D)\r \\end{aligned}\r 这样我们的推导过程就结束了，然后我们也可以使用更多的Div Function，使用不同的Div距离直接选择对应的函数就可以了。 1.2. JS Div不是最佳的Div 由于分布的数据之间是没有重合的，使用JS Div的时候就很难衡量出他的距离，Equally Bad 为什么如果两个分布完全没有重合的话，那么这两个分布的 JS Div 会是一样的? 前面有提到，JS Div 是通过判别器计算出来的，而判别器的本质是二分类器，只要$PG$与$P{data}$完全没有重合，判别器就能 100%地鉴别出$PG(x)$与$P{data}(x)$ 的差异，因此二者的 JS Div 就是一样的。 1.2.1. LSGAN最小二乘 解决的就是没有重合的问题，解决思路如下：让判别器始终都不能100%的鉴别出差异，这样就能保证在没有重合的时候也能分辨出差异程度。 当我们的D太好的时候（能将数据完全分开）这种时候生成器就优化不了了，也是Equal Bad带来的最大问题。那么如果我们将最终的激活从sigmoid换成linear激活层，这样训练出来的D就会是一个线性的直线， 这样只有当完全重合的时候D才会是一个没有梯度的直线，但是这个也并没有真正的解决这个问题，而只是绕开了这个问题。 真正解决了这个核心问题的是下面的WGAN 1.2.2. Wasserstein-GAN 核心思想：用Wasserstrin距离（EM距离）取代JS距离 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Papers/MoCo_V3.html":{"url":"Papers/MoCo_V3.html","title":"P1:MoCo V3","keywords":"","body":"1. MoCo V3 An Empirical Study of Training Self-Supervised Visual Transformers1.1. Motivation1. MoCo V3 An Empirical Study of Training Self-Supervised Visual Transformers @Aiken 2021 恺明大神对自监督学习+transformer的实证研究，针对Transformer再自监督学习学习框架中的训练不稳定问题提出了Random Patch Projection的解决方案。 Article；Paper； 1.1. Motivation ViT的方法在自监督学习的任务中，精度下降的主要原因是由于算法的不稳定性，容易陷入局部的最优值，本文主要聚焦于采用视觉领域的自监督框架进行Transformer的训练，CNN的训练方法已经是一个比较明确约定俗称的方法，而Transformer的训练架构实际上还没有被完全的构建。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Papers/FSL.html":{"url":"Papers/FSL.html","title":"P2:FSL","keywords":"","body":"1. 确定突破口需要的调研1.1. 主要是limited labels & Few Samples & Data programing1.1.1. PART1 Limited Labels （base on LiFeiFei‘s reference）1.1.2. PART2 key words searching（such as few samples etc.）1.2. - end1.2.1. PART3 few-shot learning etc.（including one-shot learning)1. 确定突破口需要的调研 1.1. 主要是limited labels & Few Samples & Data programing Weakly supervised learningsemi-supervised in video fieldif we can recoding this work?多指标下降（LOSS的耦合或者循环的选择）、相关的CV最新论文等等会在后续关注元学习、浅层神经网络的概念等等 semi-supervised 1.1.1. PART1 Limited Labels （base on LiFeiFei‘s reference） in this part we may list the paper which is useful for my recoding. 还有一些其他重要的可能在对论文进行重新精读的时候要记得注意reference：就比如说在loss变换和决策树生成那一块。distant supervision(it's kind of early) can be another baseline for our method, we need to understand how this method work for that situation distant supervisor到底是什么机制可以去CSDN什么的看一下 Transfer Learning\\label propagation算法也是这一块重要的baselineBaseline：scene graph prediction with limited labels reference： ×Induction of decision treesif want download, try google it Pattern Learning for Relation Extraction with a Hierarchical Topic Modelmaybe we'll need this paper,when we try to recoding.nope.当我们写论文需要理论基础的时候可能需要， √Data Programming: Creating Large Training Sets, Quicklyit's important to see if this article have same idea with me? it's kind of learning paradigm,是一种构建数据集中，标注数据的范式，通过这样的method可以对多种labeling function进行整合，同时减少标注的误差和overlap情况的解决。后续我们实现方法的时候可以参考一下这个的数学理论，帮助在实际中进行应用。（本文中对这里的noise-aware的损失函数进行了应用，使其适应概率标签从而抑制噪声。）严重怀疑这是snorkel算法中的引文，直接引用过来 ×Knowledge-Based Weak Supervision for Information Extraction of Overlapping Relationsfigure out how can knowledge-based benefit weakly supervised learning ?nope. NIP method. 运用语言结构，类似于发的东西，来对文本进行补全。如果我们需要了解基础知识怎么使用，可以尝试参考。 ※Realistic Evaluation of DeepSemi-Supervised Learning AlgorithmsNIPS 2018深度半监督学习的现实性评估：公布了统一的重新实现和评估的平台（方式？），（针对于算法在生产现实之中的适用性发布的一个标准。）based on analysis of image algorithm：半监督的方法通过对未标注的数据中的结构范式进行学习，从而降低了对标注数据的需求，也就是说输入的数据是大部分未标注和少量标注数据，就可以逼近完全标记数据集的表现效果。[32,50,39]，这几个针对于图像情况的方法。分析后发现，他们评估算法的方式并不适用于将算法推广到实际的生产领域中，于是我们对于评估ssl算法的方式提出了一些新的看法。说的就是以前这些ssl在算法的效果上可能作弊的一些方面，如果使用这样统一的标准对算法进行评估的话，才能使得算法得到一个好的效果，此外他也提出了一些ssl在训练过程中的一些棉铃的问题：比如说假如我们把其他类别的数据，混入其中的话，那么所有这些ssl的算法的效果都会受到极大的影响。 ×Learning from labeled and unlabeled data with label propagation这是一个很重要的方法，但是没想到这个竟然这么早？（math or algorithm？）（2002）（最近读的另一篇论文好像就借鉴的这个思路）将数据从标记的高密度区域向未标记的数据区域进行传播，这一篇论文的话，主要存在一些数学推导，我建议从19的那一篇新的标签传播开始阅读，通过这篇来补全需要的数学基础，如果另一边已经讲述的很完备了就不需要这篇的内容了 1.1.2. PART2 key words searching（such as few samples etc.） limited labels on github： ※microsoft's work:github|paperi think it’ll be important one，we‘ll need to think carefully about this.seems like they have already make it great.思路上可以给我们启发：提出了一个针对few samples的通用框架（通过度度量传播来进行的label propagation方法），来解决无论是transfer、semi-supervised、few-shot这样解决的问题，并有了一个巨大的提升。将少量标记的label propagation到大量的未标注数据上，从而创建训练数据。主要贡献：用于传播的相似性度量从其他相关域转移时，这样的标签传播方法非常有效。这个算法框架可以细读一下，后续关照一下具体的思路和实现 ※The Limited Multi-Label Projection Layer:github|paperCVPR19LML projection Layer 是一种几何的K类预测，用来再多类别少样本的情况下取代softmax的一个映射函数，这一篇主要是数学理论，在最后实现的话，要进行一定的参考和学习。 ※Learning Classifiers for Target Domain with Limited or No LabelspaperICML2019从所有的训练数据中学习一个混杂（mixture）的“原型”，然后将原型撕裂成一个个part/part-type（用attention机制来实现）、 然后通过多个part的概率组合来表示一个new instance。（use MACNN）。（即将变成低维的概率向量组成的编码=低维视觉属性LDVA）到时候找个图把这些方法全都对比一下。md花样太多了，玩晕了。 Hand and Face Segmentation with Deep Convolutional Networks using Limited Labelled Data(论文还没出)github 一些奇奇怪怪的github项目github1 limited labels on google scholar： √Large Scale Sentiment Learning with Limited LabelsSIGKDD2017他是通过对tweet的表情数据进行标注，建立的数据集，使用了self-learning和co-training两种WSL的方法，来对未标注的数据进行标注两种方法的具体注解我已经放在pdf上了 ×Large-Scale Video Understanding with Limited Training Labels这尼玛是本综述的书，吓老子一跳 few samples on google scholar： ×Learning Convolutional nerual networks from few samples2013this paper use the method of pre-trained (transfer learning instead nowadays) to get a satisfatory result.这篇文章太早了，需要的话再重新说吧。先不看 ※※Few-Shot Learning with Graph Neural Networks（two-version）（2017）（2018ICLR）using graph network to implement semi-supervised. this research prove that the graph method perform well on 'relathinal' tasks.定义了一种图模型的网络框架来实现few-shot等few samples的任务，表明这样的图网络架构能够很好的实现关系这样的处理，也很容易在这样的情境下进行拓展，这也是一个框架设计的任务。但是我们能够从中学习一下图模型如何针对关系网络进行学习和训练的，以及探讨一下图网络的优势。这一篇文章也探讨了度量学习和元学习的一些东西，这一篇可以给一个高的阅读优先级。 data programing: 1.2. - end Label propagation: ※Active Frame Selection for Label Propagation in VideosECCV2012decide how many frames we'll need to mark by human for the best result .文章通过动态规划来选定视频中的k个frame，作为key frame，通过这几个frame的人工标记，能够最大的降低算法在label propagation中的标记误差，（其中num of k和误差的权衡还不是特别清楚）取代了以往这个key frame选择的随机性，带来更好的性能。此外这个方法还关注于帧数选择的动态性，由于视频的独立性，所以固定帧数的选择不一定是合适的，应该根据视频本身的特性来选择才是更好的。（但是不知道时空复杂度怎么说）值得一提的是，文中还提到了一些辅助人工标注的算法，这些算法有时间的话可以通过CSDN去调研一下。（防撞车） √Dynamic Label Propagation for Semi-Supervised Multi-class Multi-label ClassificationICCV2013是一个基于图的方法，和eccv2012一致的地方在于，都认为视频任务的标注任务中，动态规划的part是需要的，上一篇用动态规划来实现keyframe的选择，这篇文章这是完全的semi-supervised的任务，他用dynamic的办法，动态的对多标签和多类信心进行拟合，从而动态的去更新相似性的度量，使用KNN来保留数据的固有结构。 ※※Label Propagation via Teaching-to-Learn and Learning-to-Teach2016TNNLS一个迭代的label propagation方法，结合了一定self-learning 的机制，从dataset中迭代的选出易于分类的部分，然后通过不断的对这种易于标注的数据中去self-learning，从而提高分类器的性能，然后逐步的去针对模糊边界进行propagate。感觉是一个好方法intro中简要的对比介绍了这之前的一些label propagation方法，包括DLP。 based on the sota LPmethod，所以之前的一些可能可以不用看了， ※※※Learning to Propagate Labels: Transductive Propagation Network for Few-shot LearningICLR2019结合了meta-learning/label propagation/transductive inference的方法，细看细看，这一篇一定要细看。太强了兄弟。intro里面也包含了很多的东西。 1.2.1. PART3 few-shot learning etc.（including one-shot learning) 淦淦淦，这尼玛比的定义能不能统一一哈 Few-Shot Learning: √Prototypical Networks for Few-shot Learning2017\\NIPS思路上好像和19年的cvpr那片有点像，先学习一个overall 再通过度量空间对newdata进行适应性的分配和训练。通过intro，我认为更像是一个简单的embedding的办法，将sample聚集到embedding space的一个原型上，在对其进行近邻标签传播算法把。但是里面有一些数学推导，可能是关于距离的，在我们后续需要划分指标的时候可以来看看这篇到底说了啥。（原型网络的数学推导。） √Meta-Learning for Semi-Supervised Few-Shot Classification2018、ICLR正好是上面那片原型网络的升级方法，这也太巧了把。重开一个新的课题，设置环境成为一个wild的环境，存在干扰项，将未标注的data也混杂进原型的训练中。 ×Conditional Networks for Few-Shot Semantic Segmentation2018\\ICLRworkshop track貌似有点弟弟，没提出什么有用的东西 ※Few-Shot Object Detection via Feature Reweighting2019/ICCV在一个base class 的dataset上进行meta training，然后通过 reweighting 操作，adapt to novel classes。global原型，meta的场景学习策略，transfer的reweighting操作，以及在few-shot问题种加入了很多算法并没有考虑的localization问题。这篇论文看起来还行。 ※※Meta-Transfer Learning for Few-Shot Learning2019\\CVPR通过多次的meta学习，来找到参数相对于原DNN网络（普通的meta都是用的浅层网络）而言的scaling和shifting，感觉和上一篇reweighting方法存在一定的相似性。 同时我们也知道基本的meta-learning 方法和场景图应用的方法存在极大的相似性。 此外在训练策略上，采用了一个HTmini-batch的变体策略。（figure1有简要说明，结合后面的策略观看） ×Deep Learning Models for Few-shot and Metric Learning这一篇看不了 √Learning to Compare: Relation Network for Few-Shot Learning2018\\CVPRmeta-learning 中的query 和support 不要搞混了。（前面还有一步是通过embedding来学习一个合适的feature）感觉上是一个基础的meta-learning框架，通过训练过程中对metric distance的学习，得到一个模型框架，然后通过模型将support data在metric space中与query data进行distance的衡量，从中选择shortest one作为classification的指标。 ※Dynamic Few-Shot Visual Learning Without Forgetting2018\\CVPR为了使得模型在学习新的类别的时候，对旧的类别的识别能力依旧能保留下来，提出了两个策略，一个是基于attention 的分类权重生成器，二是对ConvNet进行重新设计，使其提取出feature的表征向量和分类权重向量之间的余弦相似性。？具体的还没看。但我认为主要努力的方向好像不是很对。 Few-Shot Human Motion Prediction via Meta-Learning2018\\CVPR是一种结合了MAML、MRN、Meta-Learning的策略，本质还是一个few-shot的工作，没有提到怎么把这样的工作适应到真实的应用上，这一篇论文非常需要机器详细的阅读，不然的话不知道他到底是怎么操作的。 最终我们可以提出一个framework，通过对弱监督方法的嵌入，使得标注的任务变成一个人机交互的loop，通过我们对算法的干预，他将从标签的概率预测变成一个确定的指标预测，然后执行self-learning的方法，让自己逐渐变得更好，设定一个drop out，可以计算一个算法的最终所求时间。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Papers/FSL0.html":{"url":"Papers/FSL0.html","title":"P3:FSL0","keywords":"","body":"1. Survey For Few-Shot-Learning1.1. Table of Contents1.2. Abstract1.3. Notation and Terminology1.4. Main Body1.4.1. Overview1.4.2. Data1.4.3. MODEL1.4.4. ALGORITHM1.4.5. Future Works1.5. Appendix1.5.1. Reference:1.5.2. Additional Vocabulary：1.6. FAQ1.6.1. 需要思考的点1.6.2. 但是这样的创新点在于更多的是算法的组合，有没有办法提出一个网络结构将这样的思路融合起来。！！！1. Survey For Few-Shot-Learning 1.1. Table of Contents 另一个综述文章：https://zhuanlan.zhihu.com/p/61215293 对该文中一些内容有一些补充，可以看看 FSL简介：https://blog.csdn.net/xhw205/article/details/79491649 GCN用于FSL：https://blog.csdn.net/qq_36022260/article/details/93753532 Abstract Notation and Terminology Main Body Overview Definition Relevant Learning Problems Core Issue Taxonomy Data Transforming Samples from Dtrain Transforming Samples from a Weakly Labeled or Unlabeled Data Set Transforming Samples from Similar Data Sets Summary MODEL Multitask Learning Embedding Learning Learning with External Memory Generative Modeling Summary ALGORITHM Refining Existing Parameters Refining Meta-Learned Parameter Discussion and Summary: Future Work Appendix Reference Additional Vocabulary Still In Puzzle 1.2. Abstract FSL的根本目的就是弥合人工智能和人类之间的鸿沟，从少量带有监督信息的示例中学习。像人类一样有很高的泛化能力。这也能解决在实际应用场景中，数据难以收集或者大型数据难以建立的情景。 FSL的核心问题是：经验风险最小化器不可靠；那么如何使用先验知识去解决这个问题？ 三个主要的角度： 数据：使用先验知识增强数据的监督经验 模型：使用先验知识来降低假设空间 算法：使用先验知识来改变搜索最佳假设（来进行搜索？) 现阶段针对FSL提出的一些相关的机器学习方法： meta-learning; embedding learning; generative modeling etc. 本文的主要工作： 基于FSL的原有设定，在现阶段的FSL发展上给出正式定义，同时阐明具体目标以及解决方式 通过具体示例列举和FSL的相关学习问题，比较了相关性和差异性，更好的区分问题 指出核心问题：经验风险最小化器不可靠，这提供了更系统有组织的改进FSL的方向。 经验风险最小化器&#x1F449;：基于ML中的错误分解来分析的 整理，更好的理解 未来方向 1.3. Notation and Terminology 一般基于参数方法（因为非参数方法需要大量数据），在假设空间中搜索最优假设，并基于基于标签的Loss Function 来衡量效果。 1.4. Main Body 1.4.1. Overview 2.1：具体定义&示例 2.2：相关问题和FSL的相关性和差异 2.3：核心问题 2.4:现有的方法如何处理这个问题 Definition 基本定义：FSL是一类机器学习（由E，T，P定义），其中E只包含有限数量的带有目标T监管信息的示例。 研究方法：通常使用N-way K-shot的分类研究方法：从少量类别中的少量样本回归出ML模型， ​ Training Set Contains：KN examples. Typical scenarios of FSL: Reducing data gathering effort and computational cost: “raw images of other classes or pre-trained models ” 似乎有点迁移学习的味道了，改善从已有的类似数据集过来的model？ Learning for rare cases Acting as a test bed for learning like human. 和普通的ML的应用最明显的区别就是E中prior knowledge的应用，将T和先验知识结合起来。（such as Bayesian Learning [35,76]） Attention：Zero-shot：要求E中需要包含其他模态的信息（比如属性，wordnet，word embedding之类的） Relevant Learning Problems WSL:Weakly supervised learning: 重点在于learns from E containing only Weak supervised（such as： 不完全，不精确，不准确，或者充满噪声的监督信息），WS 中信息不完全只有少样本这一类情况就是FSL了，在此基础上基于Oracle还是人工干预的方法，可以进一步细分为： Semi-supervised learning： 从E中的少量标记样本和大量未标记样本中学习。示例：文本和网页分类；其中包含Positive-unlabeled learning这种特殊问题，只包含positive label的问题：具体而言就是，只知道用户现在用户中标记的好友，而与其他未标记人之间的关系是未知的。 Active Learning： 文章：选择信息量最大的未标记数据区query an ordacle？ 个人理解：选择信息量最大（通常用不确定性大的数据表示）来让人标注，从而构建数据集，让算法能够通过较少的数据标注操作实现更好的效果。 WSL with incomplete supervision 仅仅包括分类和回归的内容，而FSL还包含RL问题；WSL使用unlabel data 对E进行扩充，而FSL更多的使用各种类型的prior knowledge来扩充E，包括pre-train model ，其他领域的监督数据，未标记数据等等。 Imbalance learning： 数据集的分布不均衡，比如一些y值很少用到的情况。IL从所有可能的y中Train&test，FSL基于少量案例train&test y，同时也可能基于一些先验知识来。 Transfer learning： transfers knowledge from the source domain/task &#x1F449; target domain/task, where training data is scarce.其中Domin adaptation，是一种TL：source/target tasks are the same but the source/target domains are different.举例说明就是：情感识别，一个基于电影评论，一个基于日用品评论。 Transfer Learning广泛的应用于FSL，[7,82,85]将先验知识从源任务转移到Few-shot task，从一些训练数据丰富的源域转移 Meta-learning：感觉正文中讲的是个狗屎，后续通过附录中的看看 Meta-learning methods can be used to deal with the FSL problem. the meta-learner is taken as prior knowledge to guide each specific FSL task. Core Issue 经验风险最小化 Machine Learning其实是一个经验风险最小化的模型 \r R(h)=\\int \\ell(h(x), y) d p(x, y)=\\mathbb{E}[\\ell(h(x), y)] \\\\\r \r R_{I}(h)=\\frac{1}{I} \\sum_{i=1}^{I} \\ell\\left(h\\left(x_{i}\\right), y_{i}\\right)\\\\\r \r \\mathbb{E}\\left[R\\left(h_{I}\\right)-R(\\hat{h})\\right]=\\underbrace{\\mathbb{E}\\left[R\\left(h^{*}\\right)-R(\\hat{h})\\right]}_{\\mathcal{E}_{\\mathrm{app}}(\\mathcal{H})}+\\underbrace{\\mathbb{E}\\left[R\\left(h_{I}\\right)-R\\left(h^{*}\\right)\\right]}_{\\mathcal{S}_{\\mathrm{est}}(\\mathcal{H}, I)}\r 上面这1 3的区别一个是在全空间上，另一个是在是我们的假设空间中，能取到的最优解。 总体误差可以基于最小预期风险和最小经验风险来表示，如等式3。期望实和训练集的随机选择有关的，the approximation error 衡量了假设空间中的函数能够接近最优假设的程度，the estimation error 衡量了，最小经验误差代替最小期望误差在假设空间内的影响。 data （which provides Dtrain）数据角度 model which determines H（embedding function，转换到假设空间） algorithm（searches for the optimal h）学习算法，下降方向 不可靠的经验风险最小化 如果数据足够大的话，通过少量样本计算出来的假设空间就可以逼近实际上的最优假设空间，也就能得到一个很好的近似，但是在FSL中，可用的样本数很少，所以可能没办法产生很好的逼近，在这种情况下，产生的经验风险最小化指标hl过拟合，这就是FSL中的核心问题。 Taxonomy 为了解决FSL问题中经验风险最小化工具中hl的问题，prior knowledge是至关重要的，利用先验知识来扩充信息量的不足，基于先验知识的类别和使用方式就能对FSL works进行分类。 Data：通过数据增强等方式，增加数据量，从而使得经验风险最小化因子能够更加的准确。 Model：用先验知识来约束假设空间，使得需要搜索的范围变小，那么基于较少的数据也能够得到一个较好的估计，（相比原来） Algorithm：使用先验知识，来搜索最优假设的参数，基于这些先验知识提供一个较好的initialization，或者guiding the searching steps 1.4.2. Data 通过手工指定规则来进行数据增强的方式例如：:arrow_double_down: 很大程度上取决于领域的知识也需要人工成本，此外，这样的方式在数据集间的泛化能力很差，一般都是针对性设计，而且这样的不变性，不可能由人工穷举出来，所以这样的方式不能完全解决FSL问题。 translation, flipping, shearing, scaling, reflection, cropping, rotation. Advance data augmentation: Transforming Samples from Dtrain :one: 对训练集的数据进行几何变化处理，生成其他的样本，构建一个更大的数据集。 :two: 从相似类中学习一组编码器（每个编码器代表一个类内可变性），将这些习得的变化量添加到样本中形成新的样本。 :three: 基于差异从其他类别中转移过来 :four: 从一个样本变成多个；连续属性子空间来添加属性变化 基本思路是一致的，通过变换，在原本数据的基础上，构建新的数据，只是有着不同的构建方式。详细的各种类型的构建可以看参考文献。 Transforming Samples from a Weakly Labeled or Unlabeled Data Set 基于弱标签或者无标签的数据来进行数据增强的情况，类似视频中有些事件之间变化比较大的情况，可以将这样的数据添加到训练集中来更清楚的预测。 :dagger:但是如何筛选哪些有需要的弱监督数据？ :zap: 基于训练数据训练一个svm进行筛选，然后将具有目标的示例添加进数据集 :zap: Label Propagation,直接使用未标记的数据集 :zap: 也有文章采取逐步从信息量最大的数据中筛选的做法 Transforming Samples from Similar Data Sets :tada: 汇总和改造相似的数据集，来扩充Few shot情况，基于样本之间的相似性度量来确立权重，典型的方法就是：使用GAN，生成器将Few-shot的训练集映射到大规模数据集，另一个生成器将大规模数据集的样本映射过来，从而训练出可以辅助样本迁移的模型。 Summary1 这些方法的使用取决于具体任务； :x: 缺点：通常是针对数据集量身定做的 :+1: 针对这个问题有人提出了AutoAugment :heavy_multiplication_x: 缺点：文本和音频的情况下就很难做这样的生成了 1.4.3. MODEL :fire: 如果仅仅基于简单的假设去考虑的话，那么可能在我们的假设空间中的最优和实际的最优(不足以模拟现实社会中的复杂问题)会有比较大的距离，但是如果考虑复杂多样的假设空间，那么标准的机器学习模型也是不可行的（数据量不足以优化到最优解），考虑使用先验知识，将复杂多样的假设空间H 约束到较小的情况下进行学习，这样的话经验风险最小化器将会更加的可靠，同时也降低了过拟合的可能性。 根据先验知识的类型，可以划分成如下几种FSL： Multitask Learning :fire: 多个相关任务协同训练，基于特定任务的信息和通用任务的信息来一起学习，其中利用某些/其他任务的大量数据（源任务），在训练过程中，通过学习到的参数来对只有Few-shot（target task）进行约束。基于训练中参数对target的约束方式可以分为 parameter sharing参数共享 160 61 95 12 基本的网络架构如下图 :zero: 有多种不同的架构，整体都是由共享层（参数是一致的）和特定于任务的层一起构建的，简单的描述一下如下： 初始共享然后分配到特定任务；2. 源任务（pre训练）训练共享层，目标任务训练目标层；3.分别单独学习再有共享的编码器嵌入成一体。 parameter tying参数绑定 45 151 85 :zap: 基本思路：鼓励不同任务之间的参数存在相似性。对参数进行正则化是一种流行的方法。 :one: 有的方法对成对参数之间的差异及逆行了惩罚，从而确保参数分布的相似性 :two: 有的方法通过针对源任务和目标任务设置不同的CNN，之间使用特殊的正则化术语对齐。 Embedding Learning 基于先验知识（同时可以额外使用Dtrain中的任务特定信息）构建样本的一个低维嵌入，这样便能得到一个较小的假设空间，同时相似的样本会紧密接近，而异类的样本更容易区分。 Key Components： 将测试，训练样本用embedding函数（f，g）嵌入。f，g可以统一，但是分离的时候可以受获更好的准确度 相似性度量在嵌入空间（一般都是维度更低的空间）进行， 可以根据embedding函数的参数是否随任务变化分类 针对任务的嵌入模型 仅仅使用来自该任务的信息来学习针对性的嵌入模型。 通用的嵌入模型（task-invariant） 使用有足够样本且具有各种输出的大规模数据集，学习通用的embedding function，然后直接用于Fewshot。Recently, more complicated embeddings are learned [70, 150] by a convolutional siamese net [20] 通常而言，task-invariant不会使用Few-shot的数据集来更新embedding function参数，但是，其中很多情景都会模拟few-shot 的情景来训练embedding从而确保对此类任务有更好的概括性能。 :zap: Mathching Nets meta-learning / resLSTM / AL /set-to-set :zap: Prototypical Networks ​ embedding(xtest)不与每个g(xi)对比，而是每一类别的训练数据都有一个”原型“（原型公式如下），与原型对比，减少计算量。有两种变体：应用到matching-net 和 semi-supervised-108（软分配未标注的样本用以增强Dtrain） \r c_{n}=\\frac{1}{K} \\sum_{i=1}^{K} g\\left(x_{i}\\right)c_{n}=\\frac{1}{K} \\sum_{i=1}^{K} g\\left(x_{i}\\right)\r :zap:Other Method ​ ARC：利用attention+LSTM将xtest的不同区域和原型进行比较，然后将比较结果作为中间嵌入，在使用biLSTM（双向LSTM）进行最终嵌入； ​ Relation Net 使用CNN将Xtest和Xi拼接在一起，再使用另一个CNN输出相似度得分。 ​ GNN：利用GNN使用临近节点的信息 ​ SNAIL简单神经注意力学习器（RL通常看重时间信息）：temporal convolution +Attention，聚合临近步长和通过Attention选择特定时间步长的信息。 混合嵌入模型，可以编码 task-specific 和 task-invariant 的信息 虽然task-invariant可以再迁移的时候减少计算成本，但是针对一些特殊的少样本情况，他是无法直接适应的，比如说原本就是小概率事件（异常），这种情况下，基于Dtrain训练的先验知识来adapt通用的embedding模型，从而组成一个混合的结构，如下图所示。 ​ Learnet从多个meta-training set中学习meta-learner，并将训练实例映射成网络中的参数（convolutional Siamese net），这样f的参数就会随着输入改变。还有一些针对其的改进 TADAM：将类别原型平均化到嵌入中，并使用meta-learned 映射成圆形网络的参数 DCCN：使用固定的滤波器，并从Dtrain中学习组合系数。 Learning with External Memory 基于Dtrain 训练一个Embedding function，提取出 key-value的知识，存储在外部存储器中，对于新样本（test），用Embedding&相似度函数查询最相似的slots，用这些slots的组合来表示样本，然后用简单的分类器（like softmax）进行分类预测。由于对M操作成本高，所以M通常尺寸较小。当M未满时，可以讲新样本写如空闲的存储插槽。 key-value的表征，也就是memory中的定义在这个方法中至关重要，它决定了键值对对test的表征水平。根据存储器的功能，将这类方法分成两种类型： :one:Refining Representations: MANN：meta-learns embedding f，将同类的样本映射到同一个value，同一类的样本一起在内存中优化类表示。可以看成ProtoNet中精致的类原型。 当且仅当M不能很好的表征x的时候更新M。 The Abstract Memory： 使用两个M，一个基于大量数据训练出的固定键值对，另一个从固定键值对对少量类进行精炼提取。为此有的方法会注意保留M中的FS。 few-shot在M中很容易被其他samples的值表征从而取代，为了解决这个问题，提出的此算法&#x1F447; lifelong memory：通过删除oldest slot来update M，同时给所有slot的期限置为0，当新样本在经过M后输出的表征与实际输出匹配的时候，就合并，而不更新M。（但是还是没有真正的解决这个问题） :two:Refining Parameters: MetaNet、MN-Net： 对特定任务的数据进行fast 学习，而通用任务slow更新，然后结合memory的机制。（参数化学习 Generative Modeling 借助先验知识，从x的分布中估计先验p(x；$\\theta$ )的分布，从而估计和p(x|y)和p(y)，基于这样的先验数学模型进行后续的计算。而先验估计过程中通常是从别的数据集获悉的先验分布中，基于某个潜在的参数z迁移过来的如下式，这样就能基于既有的后验分布，约束H假设空间。 \r x \\sim \\int p(x | z ; \\theta) p(z ; y) d z\r 通常在识别，生成，反转，重建中有较常见的应用 Decomposable Components： 基于人类的认知，将数据分解成组件级别，在进行后续的识别和重组；利用类间的通用性； Groupwise Shared Prior： 新的FS类别，先通过无监督学习分组，共享组内的类别先验，然后基于组内的先验对其进行建模。 Parameters of Inference Networks：网络参数推理 \r p(z | x ; \\theta, \\gamma)=\\frac{p(x, z ; \\theta, y)}{p(x ; y)}=\\frac{p(x | z ; \\theta) p(z ; \\gamma)}{\\int p(x | z ; \\theta) p(z ; \\gamma) d z}\r 为了找到最优的$\\theta$ ，必须最大化以上的后验概率： 基于数据对其进行求解，inference network能够高效的迁移到新任务，但是inference network 需要大量的参数，所以通常需要在辅助的大规模数据集训练后才使用。很多经典的推理网络都可以在FSL上应用，比如VAE（可变自动编码器），autoregressive model，GAN，VAE+GAN Summary2 详细的优缺点，参考文章 存在相似任务或者辅助任务：多任务学习 ​ 包含足够的各种类别的大规模数据集：embedding方法 存在可用的内存网络：在内存顶部训练一个简单的模型（分类器），可以简单的用于FSL，主要是要精心设计更新规则。 除了FSL还想要执行生成和重构的任务的时候：generative modeling 1.4.4. ALGORITHM 算法层面的改进指的是在最优空间H搜索H*的策略，最基础的有SGD。:x:在FSL的情况下，数据会使得更新次数不够多，同时也没法基于交叉验证找到合适的补偿之类的。:arrows_counterclockwise:本节中的方法用先验知识来影响$\\theta$ ，具体体现为：:one:良好的初值；:two:直接学习优化器以输出搜索步骤；​ :zap:基于先验知识对策略的影响，对算法进行分类 Refining Existing Parameters :jack_o_lantern:基本思想：从相关任务中预训练模型的$\\theta$0作为一个良好的初始化，然后基于训练集的几次训练来adapt。 Fine-Tuning Existing Parameter by Regularization： 如何解决overfit的问题是此类预训练算法设计关键：其中一种方式就是依赖正则化操作来adapt参数。 正则化的方式主要有以下几种： | Method | Analysis | | ------------------------------------------- | ------------------------------------------------------------ | | Early-stopping | 监视训练过程，性能没有提高则停止学习 | | Selectively updating $\\theta$ | 根据具体问题，选择需要的部分来更新参数，不更新所有参数 | | Updating related parts of $\\theta$ together | 聚类$\\theta$，然后共同更新每个组，BP更新$\\theta$ | | Using a model regression network | 捕获任务无关的transformation，基于function进行embedding的映射？ | | | | Aggregating a Set of Parameters： 聚合相关模型：不贴切的比如眼口鼻到脸；具体使用上，unlabeled/similar label dataset,的pretrain model参数到FSL参数的适应。 unlabeled dataset: 把相似样本分组聚类，然后adapt similar dataset: 替换相似类别中的特征，重新使用已训练的分类器，然后对新类调整分类阈值。 Fine-Tuning Existing Parameter with New Parameters： 仅仅对模型迁徙可能没办法对FSL完全编码，所以我们在对参数进行adapt的时候加入一个新的参数，然后再Dtrain中同时adapt现存参数和learn新参数 Refining Meta-Learned Parameter 本节中细化meta-learned的参数学习：$\\theta$再过程中是持续优化的，不是固定的。 Model-Agnostic Meta-Learning（MAML）通过梯度下降来元学习 $ \\theta$ ,基于该参数，得到任务特定参数$\\phi~s$,更新公式类似如下形式$\\phi{s}=\\theta{0}-\\alpha \\nabla{\\theta{0}} \\mathcal{L}{\\mathrm{train}}^{s}\\left(\\theta{0}\\right) . $ 其中$L^s train$ 是训练样本的损失和， $\\alpha $ 是步长，该参数$\\phi~s$,对于样本的顺序不受影响，此外元学习中基本的参数更新公式如下$\\theta{0} \\leftarrow \\theta{0}-\\beta \\nabla{\\theta{0}} \\sum{T{s} \\sim P(T)} \\mathcal{L}{\\text {test }}^{s}\\left(\\theta{0}\\right)$ ，其中测试误差是整个过程中损失的和。通过元学习将参数转移。 最近针对MAML提出了主要再以下三个方面的改进： :zap:合并特定任务的信息：MAML为所有任务提供相同的初始化，但是这样忽视了特异性，所以，从一个好的初始化参数的子集中为新任务选择初值 :zap:使用meta-learned $\\theta$的不确定性去建模：结合AL :zap:改进refining过程：对$T~s$使用正则化？ Learning the Optimizer 不使用梯度下降，学习一种可以直接输出更新的优化器，无需调整步长$\\alpha$ 和搜索方向。 LSTM+Meta-Learner？ Discussion and Summary: 通过对现有参数进行微调，从而减少H需要的搜索量： 使用现有$\\theta$作为初始化：牺牲一些精度换取速度 另外两种策略都是依赖于元学习，元学习可以让参数和指定任务更为接近，还有一种直接充当优化器。 1.4.5. Future Works 在未来的FSL中使用多模态的prior knowledge SOTA网络架构的使用来改进data，algorithm，model； AutoML在FSL任务中的应用 meta-learning中动态学习中，如何避免catastrophic forgetting 在各领域中的应用：CV，bot，NLP，Acoustic signal process，etc :zap:Theories： FSL使用先验知识来弥补缺少监管信息的情况； FSL很多时候和domain adaptation 有关系 FSL的收敛性研究还没有完全了解 1.5. Appendix 1.5.1. Reference: 之后整理一些可能需要阅读的reference 只关注小样本的概念学习和经验学习的Another FSL survey: J. Shu, Z. Xu, and D Meng. 2018. Small sample learning in big data era. arXiv preprint arXiv:1808.04572 (2018). FS-RL，在仅给出少量状态和动作对组成的轨迹的情况下找到一种策略： [3,33] Bayesian Learning : [35,76] 1.5.2. Additional Vocabulary： 序号 希腊字母 Markdoown 序号 希腊字母 Markdoown 1 α \\alpha 19 β \\beta 2 γ \\gamma 20 δ \\delta 3 Γ \\Gamma 21 Δ \\Delta 4 ε \\varepsilon 22 ϵ \\epsilon 5 ζ \\zeta 23 η \\eta 6 Θ \\Theta 24 ι \\iota 7 θ \\theta 25 κ \\kappa 8 Λ \\Lambda 26 λ \\lambda 9 μ \\mu 27 ν \\nu 10 ξ \\xi 28 ο \\omicron 11 Π \\Pi 29 ρ \\rho 12 π \\pi 30 τ \\tau 13 Σ \\Sigma 31 Φ \\Phi 14 σ \\sigma 32 ϕ \\phi 15 Υ \\Upsilon 33 Ψ \\Psi 16 υ \\upsilon 34 ψ \\psi 17 Ω \\Omega 35 ω \\omega 18 φ \\varphi 36 Ξ \\Xi 术语或生词: empirical risk minimizer ：经验风险最小化器 ultimate goal ：最终目的 To name a few： 举几个例子 autonomous driving car：自动驾驶汽车 tackled：解决 paradigm：范式 ethic：道德 taxonomy：分类 the pros and cons of different approaches：不同方法的利弊 with respect to：关于 the approximation error：逼近误差 the estimation error：估计误差 alleviate：缓和，减轻 aggregation：聚集 simultaneously：同时，兼 penalized：受惩罚的 hybrid:混合的 interleaved：交错的 denominator：分母 注意区分： sufficient：足够 terminology：术语 refine：提炼 提纯 leverage：利用 latent：潜在的 1.6. FAQ [x] Testing Set需要在N-way上进行吗？应该是要的 [x] AL的query or oracle 是啥意思 [ ] According to whether the oracle or human intervention is leveraged, this can be further classified into the following 此处 oracle到底是什么意思 [x] Semi-Supervised 又和FSL有什么区别呢 [x] Imbalance Learning确实不是很理解 [x] Generative Modeling的具体要素不是很懂 [x] Core Issue中的三个h的关系还有点疑惑 app：在最优的情况下，能搜索到的最优解和实际最优解之间的差距 est：实际的假设空间中的最优解和基于少量样本的经验得到的假设空间中的最优解之间的距离。 [ ] Parameters of Inference Networks，不知道怎么理解，后续要补充 -- 1.6.1. 需要思考的点 [x] Few-shot-learning & meta learning的问题设置，就是多类中都有足量样本，然后随机的从多类中选取few-way和few-shot的data模拟多种meta环境（fewshot和fewway），单次训练都是小样本的情况，进行学习，在这种环境下学习到，一个模式，然后从而减少数据量的要求。（这样就哪里减少了数据量啊，我就没懂了，） [ ] 那么假如说没有多类动作（怎么构造多类动作）：不会，我们可以在网上爬取，或者自己拍摄，因为只需要少量有标注的数据即可，也就是positive数据可以比较容易获得。 [ ] 那么我们在构造增量的时候，也是考虑边际效益，然后当数据量达到一定规模的时候可以采用直接训练分类器的分类器，来对效果进行分类 [ ] Few-shot-learning中，训练集和测试集，标签已知和未知到底怎么弄，从代码中以及定义中分析的话怎么感觉是两个意思。我们需要的应该不能用到那个。 [ ] few-shot-learning应该指的是，新类只有很少的样本，但是旧类还是有大量标注样本的情况这个我们要好好分析。1.6.2. 但是这样的创新点在于更多的是算法的组合，有没有办法提出一个网络结构将这样的思路融合起来。！！！ © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Papers/SS_OD_SoftTeacher.html":{"url":"Papers/SS_OD_SoftTeacher.html","title":"P4:SS OD SoftTeacher","keywords":"","body":"1. E2E Semi-Supervised Object Detection with Soft Teacher1.1. Abstrast and Intro1.1.1. Multi-Stage1.1.2. End to End1.2. Related works1.3. Methodology1.3.1. Framework1.3.2. Soft Teacher1.3.3. Box Jittering1.3.4. Experiment1. E2E Semi-Supervised Object Detection with Soft Teacher @ Article: ICML from Microsoft & Huazhong Keda @ Code: Github @ Noteby: Aikenhong @ Time: 20210914 1.1. Abstrast and Intro in the session we will using describe the main idea of this article. 这篇文章的重点在于Soft Teacher，也就是用pseudo label做为弱标注，逐步提高伪标签的可靠性。 不同于多阶段的方法，端到端的方法再训练中逐步的提升伪标签的质量从而再去benifit目标检测的质量。 这样E2E的框架主要依赖于两部分技术: soft teacher: 每个未标记边界框的分类损失由教师网络产生的分类分数进行加权 box jitter 窗口抖动: 选择可靠的伪框来学习框回归 在目标检测上获得SOTA的效果; 1.1.1. Multi-Stage 在半监督的情况下，关注的主要是基于伪标签的方法，是目前的SOTA，以往的方法采用多阶段的方式。 使用标记数据训练初始检测器 未标记数据的伪标记，同时基于伪标签进行重新训练 局限：初始少量标注的局限，初始的检测器的伪标签质量 1.1.2. End to End Soft Teacher基本思路：对未标记的图像进行标记，然后通过标记的几个伪标签训练检测器. 具体而言： 采样标注和未标注图片形成Batch 双模型：检测（student）、标记（teacher） EMA：T模型是S模型的EMA 这种方式避免了多阶段方案实现上的复杂，同时实现了飞轮效应==S、T相互加强; 此外Soft Teacher直接对学生模型生成的所有候选框进行评估，而不是使用伪框来为这些候选框进行分类回归。 这样能使用更多的直接监督信息 具体而言： 使用高阈值来分割前景，确保不会错误的将背景分类成前景，确保正伪标签的高精度； 使用可靠性度量来加权背景候选的损失； 教师模型产生的检测分数可以很好的作为可靠性度量 Box Jitter为了更可靠的训练学生网络的本地分支，指的是： 我们对前景框候选进行多次抖动 根据教师模型的位置分支对这些候选进行回归 将回归框的方差作为可靠性度量 可靠性高的用来训练 1.2. Related works Semi-Supervised Learning in Image Classification & object detection consistency based pesudo-label based new idea：使用弱数据增强生成伪标签和强增强来学习检测模型，区分两部分工作 Object Detection Based on Faster R-CNN to compare with other method 1.3. Methodology 可以从下面的图中看出基础的实现逻辑： 1.3.1. Framework 训练（Loss）是基于Batch进行，对于标记数据和未标记数据的损失处理时分开的， 对于未标记数据，我们需要通过教师模型来得到一个softlabel，包括分类和回归两个任务，然后得到最终的损失值。 L = L_s + \\alpha L_u 两者都要通过各自的图像数量进行归一化，以标注数据为例 L_s = \\frac{1}{N_l}\\sum_{i=1}^{N_l}(L_{cls}(I_l^i)+(L_{reg}(I_l^i)) 如何启动教师模型： 随机初始化学生模型和教师模型，后续通过学生模型的EMA来进行教师模型的更新。 目标检测的伪标签定义： 教师模型检测后NMS消除冗余，然后使用阈值来抑制非前景的候选； 获取高质量的伪标签： 对教师模型的伪标记使用弱增强，学生模型训练使用强增强 1.3.2. Soft Teacher 检测器的性能取决于伪标签的质量，如果在前景分数上使用较高的阈值过滤掉大部分学生生成的低置信度候选框可以得到更好的结果，当阈值设置为0.9时性能最佳，但是召回率迅速下降。 一般方法：使用学生生成的候选框和教师生成的候选框的IoU来分配前景和背景，可能会损坏性能。 软教师：我们评估学生生成的候选框作为真实背景的可靠性，用于衡量背景分类损失； $b^{fg}i$、$b^{bg}_i$分别是分配为前景的框和分配为背景的框，具有可靠权重的伪标记图像的分类损失定义为： \\mathcal{L}_{u}^{\\mathrm{cls}}=\\frac{1}{N_{b}^{\\mathrm{fg}}} \\sum_{i=1}^{N_{b}^{\\mathrm{fg}}} l_{\\mathrm{cls}}\\left(b_{i}^{\\mathrm{fg}}, \\mathcal{G}_{\\mathrm{cls}}\\right)+\\sum_{j=1}^{N_{b}^{\\mathrm{b}_{b}}} w_{j} l_{\\mathrm{cls}}\\left(b_{j}^{\\mathrm{bg}}, \\mathcal{G}_{\\mathrm{cls}}\\right) w_j = \\frac{\\gamma_j}{\\sum_{k=1}^{N_b^{bg}}\\gamma_k} $\\mathcal{G}{cls}$表示用于分类（教师生成的）伪框集，$l_{cls}()$是框分类损失，$r_j$是第j个背景的可靠性分数； 我们通过教师模型产生的背景分数可以很好的代替可靠性： 使用教师模型（BG-T）通过检测头来获取样本的背景分数 还研究了：学生模型，学生模型和学生模型之间的差异 1.3.3. Box Jittering 图三b可以看到，候选框的定义准确率和前景分数不是一个正相关的关系，他不一定能提供准确的定位信息。 需要更好的候选框，在教师生成的候选框bi上做抖动采样，将抖动框输入教师模型获得调整后的框 \\hat{b_i} = refine(jitter(b_i)). 抖动$N{jittle}$次后得到${\\hat{b}{i,j}}$集合，然后将可靠性定义为box回归方差： \\overline{\\sigma}_i = \\frac{1}{4}\\sum_{k=1}^4\\hat{\\sigma}_k 其中： \\hat{\\sigma}_k = \\frac{\\sigma_k}{0.5(h(b_i)) + w(b_i)} 较小的框回归方差表示较高的本地可靠性，但是大量的计算也是不可忍受的，所以我们一般只计算前景分数大于0.5的框的可靠性 回归方差计算： \\mathcal{L}_{u}^{\\mathrm{rcg}}=\\frac{1}{N_{b}^{\\mathrm{fg}}} \\sum_{i=1}^{N_{b}^{\\mathrm{f}_{8}}} l_{\\mathrm{reg}}\\left(b_{i}^{\\mathrm{fg}}, \\mathcal{G}_{\\mathrm{reg}}\\right) \\mathcal{L}_{u}=\\frac{1}{N_{u}} \\sum_{i=1}^{N_{u}}\\left(\\mathcal{L}_{u}^{\\mathrm{cls}}\\left(I_{u}^{i}, \\mathcal{G}_{\\mathrm{cls}}^{i}\\right)+\\mathcal{L}_{u}^{\\mathrm{rcg}}\\left(I_{u}^{i}, \\mathcal{G}_{\\mathrm{rcg}}^{i}\\right)\\right) 1.3.4. Experiment 实验细节 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Papers/RL.html":{"url":"Papers/RL.html","title":"RL强化学习","keywords":"","body":"1. 强化学习2. Chapter1 模型基础2.1. Theory理论基础3. Chapter2 马尔可夫决策过程（MDP）3.1. 马尔可夫性简化3.2. MDP的价值函数和贝尔曼方程3.3. 状态价值函数和动作价值函数的递推关系3.4. 最优价值函数4. Chapter3 动态规划（DP）求解4.1. 策略评估求解预测问题4.2. 策略迭代求解控制问题4.3. 价值迭代求解控制问题4.4. 异步动态规划算法5. Chapter 4 用蒙特卡罗法求解5.1. Monto-Calo 求解5.2. MC求解预测问题（策略评估）5.3. MC求解控制问题（策略迭代）6. Chapter5 用时序差分法（TD）求解6.1. TD预测问题求解6.2. n步时序差分6.3. TD（$\\lambda$）6.4. TD控制问题求解1. 强化学习 Created by: Aiken H Detail: survey Finished?: No Tags: Paper URL1: https://www.cnblogs.com/pinard/category/1254674.html URL2: https://github.com/ljpzzz/machinelearning URL3: https://datawhalechina.github.io/easy-rl/#/ 2. Chapter1 模型基础 强化学习（一）模型基础 强化学习是介于监督和无监督学习之间的，强化学习没有输出值，但是有reward： 同时这个reward是事后给出的，而不是及时回馈的。而无监督学习是只有数据特征，同时数据之间是独立的，没有前后依赖的关系。 2.1. Theory理论基础 简化模型介绍： 上面的大脑代表我们的算法执行个体，我们可以操作个体来做决策，即选择一个合适的动作（Action）At。下面的地球代表我们要研究的环境,它有自己的状态模型，我们选择了动作At后，环境的状态(State)会变，我们会发现环境状态已经变为St+1,同时我们得到了我们采取动作At的延时奖励(Reward)Rt+1。然后个体可以继续选择下一个合适的动作，然后环境的状态又会变，又有新的奖励值。。。这就是强化学习的思路。 强化学习的模型关键要素： 环境的状态S：t时刻环境的状态$S_t$是它环境状态集中的某一个状态 个体的动作A：个体在某个时刻可能做出的动作集合 环境的奖励R：个体在某个时刻对应状态下做出的动作$A_t$得到的奖励会在t+1时刻得到 个体的策略$\\pi$：个体根据当前的环境选择采取动作的策略分布（函数），一般表示为一个条件概率分布的形式，概率大的动作被个体选择的概率显然更高 \\pi(a|s)= P(A_t = a | S_t = s) 在策略$\\pi$和状态s采行动后的价值$v_\\pi(s)$：一般是一个期望函数，因为我们不能每次只能选择当前的reward最大的策略，而是需要考虑大局，所以我们要有一个综合的（当前和后续）的延时奖励。 v_\\pi(s) = \\mathbb{E}(R_{t+1} + \\gamma R_{t+2} + \\gamma ^2 R_{t+3} + ... |S_t = s) 奖励衰减因子$\\gamma$：也就是上式的权重，极端值考虑贪婪和一致等同，范围在[0,1] 环境的状态转移模型：也就是环境从s经过a后转化下一个状态的状态机，也可以表示为一个概率模型$P_{ss^‘}^a$ (s→s' , a) 探索率$\\epsilon$：主要用于训练迭代中，我们一般选择当前价值最大的动作，但是为了搜索空间的完备，我们会用$\\epsilon$的概率去选择非最大价值的动作，来提升训练的鲁棒性 SUMMARY：主要介绍了强化学习模型的workflow以及其中需要考虑的8个主要参数和函数架构。最主要的机制还是Policy和reward设计这一块 3. Chapter2 马尔可夫决策过程（MDP） 强化学习（二）马尔科夫决策过程(MDP) Easy-RL 在这里可能需要补充一下马尔可夫链的相关理论知识，先粗略的看完这部分再说 3.1. 马尔可夫性简化 环境的真实转化状态可能和之前的多个时刻相关，这样会导致建模困难，于是我们对环境的状态转移模型进行马尔可夫性假设。也就是： 转化到下一个状态s'只和当前的状态s相关，与之前的状态无关 同样的我们对Policy、价值函数也做了同样的马尔可夫性假设来简化。 其中：$G_t$代表收获（return），是从某一个状态开始采样直到终止状态时所有奖励的有衰减的和。 1.\\ P_{ss'}^a = \\mathbb{E}(S_{t+1} = s'|S_t=s,A_t=a) 2. \\ \\pi(a|s) = P(A_t = a | S_t = s) 3. \\ v_\\pi(s) =\\mathbb{E}_\\pi(G_t|S_t =s) = \\mathbb{E}(R_{t+1} + \\gamma R_{t+2} + \\gamma ^2 R_{t+3} + ... |S_t = s) SUMMARY：由于环境的复杂时序关系，我们需要进行相应的马尔可夫性的假设，让下一个时刻的状态或者预测值只和当前时刻有关，从而简化并假设出模型 3.2. MDP的价值函数和贝尔曼方程 在上述价值表达式的基础上，加入考虑动作a带来的价值影响，我们就可以得到下面的动作价值函数： q_{\\pi}(s, a)=\\mathbb{E}_{\\pi}\\left(G_{t} \\mid S_{t}=s, A_{t}=a\\right)=\\mathbb{E}_{\\pi}\\left(R_{t+1}+\\gamma R_{t+2}+\\gamma^{2} R_{t+3}+\\ldots \\mid S_{t}=s, A_{t}=a\\right) 我们可以通过价值函数的公式得到价值函数的递推关系（贝尔曼方程）： \\begin{aligned} v_{\\pi}(s) &=\\mathbb{E}{\\pi}\\left(R{t+1}+\\gamma R_{t+2}+\\gamma^{2} R_{t+3}+\\ldots \\mid S_{t}=s\\right) \\\\ &=\\mathbb{E}{\\pi}\\left(R{t+1}+\\gamma\\left(R_{t+2}+\\gamma R_{t+3}+\\ldots\\right) \\mid S_{t}=s\\right) \\\\ &=\\mathbb{E}{\\pi}\\left(R{t+1}+\\gamma G_{t+1} \\mid S_{t}=s\\right) \\\\ &=\\mathbb{E}{\\pi}\\left(R{t+1}+\\gamma v_{\\pi}\\left(S_{t+1}\\right) \\mid S_{t}=s\\right) \\end{aligned} 一个状态的价值由该状态的奖励以及后续状态价值按照一定衰减比例联合而成，同样的有： q_{\\pi}(s, a)=\\mathbb{E}_{\\pi}\\left(R_{t+1}+\\gamma q_{\\pi}\\left(S_{t+1}, A_{t+1}\\right) \\mid S_{t}=s, A_{t}=a\\right) SUMMARY：基于马尔可夫假设之后，我们可以将价值函数（动作、状态）表示一个递推的形式，这个递推的形式也被叫做贝尔曼方程。 3.3. 状态价值函数和动作价值函数的递推关系 基于状态价值函数的定义以及动作价值函数的定义，我们很容易得到两个价值函数之间的转化关系： 状态价值函数是动作价值函数对于所有可能动作对于policy的期望。 利用贝尔曼方程，我们也能反推得状态价值函数来表示动作价值函数： 当前的reward和可能转移到所有后续状态的价值函数的加权和 v_\\pi(s) = \\sum_{a\\in A} \\pi({a|s}) q_\\pi(s,a) q_\\pi(s,a) = R_s^a + \\gamma \\sum _ {s'\\in S} P_{ss'}^a v_\\pi(s') 将上述两个式子互相结合起来，我们可以得到如下的简化（变量）算式（只包含一种价值函数） \\begin{gathered}v_{\\pi}(s)=\\sum_{a \\in A} \\pi(a \\mid s)\\left(R_{s}^{a}+\\gamma \\sum_{J \\in S} P_{s s^{\\prime}}^{a} v_{\\pi}\\left(s^{\\prime}\\right)\\right) \\\\q_{\\pi}(s, a)=R_{s}^{a}+\\gamma \\sum_{s^{\\prime} \\in S} P_{s s^{\\prime}}^{a} \\sum_{a^{\\prime} \\in A} \\pi\\left(a^{\\prime} \\mid s^{\\prime}\\right) q_{\\pi}\\left(s^{\\prime}, a^{\\prime}\\right)\\end{gathered} 3.4. 最优价值函数 这一部分看原文，结合相应的例子一起看，后续可能需要看EasyRL中的markov的相关解读来进行深入的理解和计算的分析。 解决一个强化学习的问题意味着要找一个最有的policy（策略），让Argent在和环境交互的过程中获得比其他所有策略都更多的收获，找到这个策略，也就意味着我们解决了这样一个强化学习的问题。 求解最优策略→ 求解最优的价值函数，使得（动作、状态）价值函数获取到最大值的策略就是最优策略。 对于最优策略我们将动作函数定义为： \\pi_{*}(a \\mid s)=\\left\\{\\begin{array}{ll}1 & \\text { if } a=\\arg \\max _{a \\in A} q_{*}(s, a) \\\\0 & \\text { else }\\end{array}\\right. 有： v_*(s) = \\max_a q_*(s,a)\\\\q_{*}(s, a)=R_{s}^{a}+\\gamma \\sum_{s^{\\prime} \\in S} P_{s s}^{a} v_{*}\\left(s^{\\prime}\\right) 这样我们就可以最终得到： \\begin{gathered}v_{*}(s)=\\max _{a}\\left(R_{s}^{a}+\\gamma \\sum_{g^{\\prime} \\in S} P_{s s^{\\prime}}^{a} v_{*}\\left(s^{\\prime}\\right)\\right) \\\\q_{*}(s, a)=R_{s}^{a}+\\gamma \\sum_{s^{\\prime} \\in S} P_{s s^{\\prime}}^{a} \\max _{a^{\\prime}} q_{*}\\left(s^{\\prime}, a^{\\prime}\\right)\\end{gathered} 4. Chapter3 动态规划（DP）求解 强化学习（三）用动态规划（DP）求解 用动态规划来求解强化学习是自然的 关键的两点： 问题的最优解可以由递归的最优解来得到 子问题状态间的转移 从上面推出的贝尔曼方程，这个递推公式实际上就是DP求解的状态转移等式，然后相应的Value什么的也和DP求解过程的需求是一一对应的。 关键的方程，通过这种递推公式，我们可以通过上一个迭代周期的状态价值去计算当前迭代周期状态S的状态价值，这也就是动态规划的一个求解的自然过程。 基于贝克曼方程推导出来，推导过程已经在上面了 v_{\\pi}(s)=\\sum_{a \\in A} \\pi(a \\mid s)\\left(R_{s}^{a}+\\gamma \\sum_{J \\in S} P_{s s^{\\prime}}^{a} v_{\\pi}\\left(s^{\\prime}\\right)\\right) 已知条件：状态集S, 动作集A, 模型状态转化概率矩阵P, 即时奖励R，衰减因子γ, 给定策略π 4.1. 策略评估求解预测问题 策略评估：求解给定策略的状态价值函数的问题，即强化学习的预测问题。 求解思路： 从任何一个状态价值函数开始，按照给定的策略，结合关键的贝尔曼递推期望方程，状态转移，reward，更新状态价值函数，直至最终收敛。 具体而言： 假设第k轮我们已经计算出了所有的状态的状态价值，然后再k+1轮的时候利用k轮的值通过贝尔曼方程来进行更新。 v_{k+1}(s)=\\sum_{a \\in A} \\pi(a \\mid s)\\left(R_{s}^{a}+\\gamma \\sum_{s' \\in S} P_{s s^{\\prime}}^{a} v_{\\pi}\\left(s^{\\prime}\\right)\\right) 具体案例上面的网站中去看：（很容易理解） 4.2. 策略迭代求解控制问题 控制问题：需要同时求解状态价值函数和策略 策略迭代：从一个初始任意的策略状态，不断地迭代，调整我们的策略，从而得到一个最优的策略。 求解思路：贪婪法 具体而言： 个体在某个状态下选择的行为，是其能够达到后续所有可能的状态中，状态价值最大的那个状态， 策略迭代过程的演示：逐步的迭代策略和相应的价值函数，最终使得两者同时收敛 4.3. 价值迭代求解控制问题 和上述的策略迭代的问题一样，如果我们使用贪婪的策略去及时调整策略，而不是等到收敛了才调整策略的话，就能很快的减少迭代次数，这样我们状态价值的更新方法也会不太一样，也能更快的收敛 v_{k+1}(s)=\\max_{a \\in A} \\left(R_{s}^{a}+\\gamma \\sum_{s' \\in S} P_{s s^{\\prime}}^{a} v_{\\pi}\\left(s^{\\prime}\\right)\\right) 4.4. 异步动态规划算法 在前几节我们讲的都是同步动态规划算法，即每轮迭代我会计算出所有的状态价值并保存起来，在下一轮中，我们使用这些保存起来的状态价值来计算新一轮的状态价值。 另一种动态规划求解是异步动态规划算法，在这些算法里，每一次迭代并不对所有状态的价值进行更新，而是依据一定的原则有选择性的更新部分状态的价值，这类算法有自己的一些独特优势，当然有额会有一些额外的代价。 常见的异步动态规划算法有三种： 第一种是原位动态规划 (in-place dynamic programming)， 此时我们不会另外保存一份上一轮计算出的状态价值。而是即时计算即时更新。这样可以减少保存的状态价值的数量，节约内存。代价是收敛速度可能稍慢。 第二种是优先级动态规划 (prioritised sweeping)：该算法对每一个状态进行优先级分级，优先级越高的状态其状态价值优先得到更新。通常使用贝尔曼误差来评估状态的优先级，贝尔曼误差即新状态价值与前次计算得到的状态价值差的绝对值。这样可以加快收敛速度，代价是需要维护一个优先级队列。 第三种是实时动态规划 (real-time dynamic programming)：实时动态规划直接使用个体与环境交互产生的实际经历来更新状态价值，对于那些个体实际经历过的状态进行价值更新。这样个体经常访问过的状态将得到较高频次的价值更新，而与个体关系不密切、个体较少访问到的状态其价值得到更新的机会就较少。收敛速度可能稍慢。 SUMMARY 动态规划是我们讲到的第一个系统求解强化学习预测和控制问题的方法。它的算法思路比较简单，主要就是利用贝尔曼方程来迭代更新状态价值，用贪婪法之类的方法迭代更新最优策略。 动态规划的缺点：实际上是一种遍历的方式 动态规划算法使用全宽度（full-width）的回溯机制来进行状态价值的更新，也就是说，无论是同步还是异步动态规划，在每一次回溯更新某一个状态的价值时，都要回溯到该状态的所有可能的后续状态，并利用贝尔曼方程更新该状态的价值。这种全宽度的价值更新方式对于状态数较少的强化学习问题还是比较有效的，但是当问题规模很大的时候，动态规划算法将会因贝尔曼维度灾难而无法使用。因此我们还需要寻找其他的针对复杂问题的强化学习问题求解方法。 5. Chapter 4 用蒙特卡罗法求解 强化学习（四）用蒙特卡罗法（MC）求解 ❓ 由 1. DP方法的全回溯机制（完全遍历）带来的过度的计算复杂度，对于复杂问题的求解困难 2. 很多时候对于状态转化模型P的未知 DP中问题预测和控制问题的定义是在P已知的情况下定义的，这种称之为：基于模型的强化学习问题 而一般性预测和控制，也就是在状态转化概率矩阵P未知的情况下求解1. 状态价值函数 和2. 1+最优策略的问题 我们需要考虑其他的方法，而不能使用DP方法来求解这样的RL问题——Monto-Calo是一种可行的方法 已知条件：状态集S, 动作集A, 即时奖励R，衰减因子γ，探索率ε 5.1. Monto-Calo 求解 基于采样的思路：蒙特卡罗法通过采样若干经历完整的状态序列(episode)来估计状态的真实价值。 经历完整就是这个序列必须是达到终点的。比如下棋问题分出输赢，驾车问题成功到达终点或者失败。 有了很多组这样经历完整的状态序列，我们就可以来近似的估计状态价值，进而求解预测和控制问题了。 关键公式回顾： v_\\pi(s) = \\mathbb{E}(R_{t+1} + \\gamma R_{t+2} + \\gamma ^2 R_{t+3} + ... |S_t = s) 5.2. MC求解预测问题（策略评估） 思路：求解某个s的状态价值：对所有采样到的状态序列中，出现该状态之后的收获再取平均值来近似求解。 G_t = R_{t+1} + \\gamma R_{t+1} + ...+ \\gamma ^{T-t+1}R_T \\\\ V_\\pi (s) \\approx average(G_t), s.t. S_t = s 一个状态在一个状态序列中多次出现的处理 主要有两种解决方式： First Visit： 只统计第一次出现的来进行均值的计算 Every Visit：每一次出现都加入均值的计算，这种方式更适合样本量少的情况，但是计算量要更大一些。 累进更新平均值（Incremental mean） 如果我们将每个状态序列的值都记录下来在最后进行更新的话，会耗费大量的存储空间，所以我们使用累计更新均值的方法来进行不同轮次之间的迭代。 换言之：统计当前的均值和状态遍历到的次数。 \\mu_k = \\frac{1}{k} \\sum_{j=1}^{k}x_j = \\frac{1}{k}(x_k+\\sum_{j=1}^{k-1}x_j) = \\frac{1}{k}(x_k+(k-1)\\mu_{k-1}) = \\mu_{k-1} + \\frac{1}{k}(x_k-\\mu_{k-1}) 然后我们就可以将状态价值公式的更新过程修改成： N(S_t) = N(S_t)+1\\\\ V(S_t) = V(S_t) + \\frac{1}{N(S_t)}(G_t-V(S_t)) 这种情况下的存储空间（内存消耗）就是固定的了。 对海量数据做分布式迭代的时候$N(S_t)$计算不确定的情况 V(S_t) = V(S_t) + \\alpha(G_t-V(S_t)) 动作价值函数也是类似的方法。 5.3. MC求解控制问题（策略迭代） 和策略迭代的方式也是类似的，也是先做策略评估，然后通过一定的方法（比如贪婪策略）更新策略。 和DP相比的不同有如下几点： 策略评估的方法不同 MC优化最优动作价值函数而不是状态价值函数 DP一般使用贪婪法，MC使用$\\epsilon$-贪婪法 $\\epsilon$-贪婪法： 一般设置一个较小的值，然后用1-$\\epsilon$来选择最大行为价值的行为，然后剩下的就随机在m个可行行为中随机选择 \\pi(a \\mid s)=\\left\\{\\begin{array}{ll}\\epsilon / m+1-\\epsilon & \\text { if } a^{*}=\\arg \\max _{a \\in A} Q(s, a) \\\\\\epsilon / m & \\text { else }\\end{array}\\right. 为了使得算法收敛；$\\epsilon$会逐渐减小，并趋于0。 这样会得到一个和动态规划类似的图 具体的算法流程： 在这里总结下蒙特卡罗法求解强化学习控制问题的算法流程，这里的算法是在线(on-policy)版本的,相对的算法还有离线(off-policy)版本的。在线和离线的区别我们在后续的文章里面会讲。同时这里我们用的是every-visit,即个状态序列中每次出现的相同状态，都会计算对应的收获值。 输入：状态集S, 动作集A, 即时奖励R，衰减因子γ, 探索率ϵ　 输出：最优的动作价值函数q∗和最优策略π∗　 初始化所有的动作价值Q(s,a)=0， 状态次数N(s,a)=0，采样次数k=0，随机初始化一个策略π　 k=k+1, 基于策略π进行第k次蒙特卡罗采样，得到一个完整的状态序列:S1,A1,R2,S2,A2,...St,At,Rt+1,...RT,ST 对于该状态序列里出现的每一状态行为对(St,At)，计算其收获Gt, 更新其计数N(s,a)和行为价值函数Q(s,a)： G_t = R_{t+1} + \\gamma R_{t+1} + ...+ \\gamma ^{T-t+1}R_T \\\\N(S_t,A_t) = N(S_t,A_t)+1\\\\ Q(S_t,A_t) = Q(S_t,A_t) + \\frac{1}{N(S_t,A_t)}(G_t-Q(S_t,A_t)) 基于新计算出的动作价值，更新当前的ϵ−贪婪策略： \\epsilon = \\frac{1}{k}\\\\\\pi(a \\mid s)=\\left\\{\\begin{array}{ll}\\epsilon / m+1-\\epsilon & \\text { if } a^{*}=\\arg \\max _{a \\in A} Q(s, a) \\\\\\epsilon / m & \\text { else }\\end{array}\\right. 如果所有的Q(s,a)收敛，则对应的所有Q(s,a)即为最优的动作价值函数q∗。对应的策略π(a|s)即为最优策略π∗。否则转到第二步。 SUMMARY:实际上MC方法就是一个简单的采样渐进求平均的方法，在不断的迭代过程中找到相应的槿近似值。 6. Chapter5 用时序差分法（TD）求解 强化学习（五）用时序差分法（TD）求解 蒙特卡洛法虽然灵活，不需要环境转化概率模型，但是也有限制：所有的采样序列都需要是完整的状态序列，如果没有完整的状态序列，就不能使用Monto-Calo了。 在不完整的状态序列的情况下，可以使用时序差分算法（Temporal-Difference，TD），这也是一种不基于模型的算法（也就是没有环境转移的情况下） 关键公式回顾： 蒙特卡洛：G_t = R_{t+1} + \\gamma R_{t+1} + ...+ \\gamma ^{T-t+1}R_T \\\\ 贝尔曼（TD）：v_{\\pi}(s) = =\\mathbb{E}{\\pi}\\left(R_{t+1}+\\gamma v_{\\pi}\\left(S_{t+1}\\right) \\mid S_{t}=s\\right) 由于如果使用G的公式的话，我们需要有T时刻的R来进行计算分析， 为了简化这个过程，我们使用贝尔曼的递推式来进行时序差分的分析（实际上是同个等式） 也就是： 使用$R{t+1} + \\gamma v(S{t+1})$（也称为TD目标值） 来代替收获$Gt$，同时令$R{t+1} + \\gamma v(S_{t+1}) - V(S_t)$称为TD误差，用TD目标值来代替收获G的过程称为引导。这样的话我们只需要两个连续的状态和对应的奖励，就可以尝试求解强化学习的问题了。 6.1. TD预测问题求解 预测问题的求解思路大体上是类似的，但是和MC有两个主要的不同点: 一个是$G_t$收获的表达式不同 G(t) = R_{t+1} + \\gamma v(S_{t+1}) 二是迭代的系数稍微有些不同，因为没有完整的序列，所以就没有对应的次数N，所以就用一个[0,1]的系数来代替 V\\left(S_{t}\\right)=V\\left(S_{t}\\right)+\\alpha\\left(G_{t}-V\\left(S_{t}\\right)\\right) 具体的例子请参考相应的链接，这里写的特别的清楚！GO TO URL 从例子中我们可以看到MC和TD主要的几点区别： 时序差分法在知道结果之前就可以学习，也可以在没有结果时学习，还可以在持续进行的环境中学习，而蒙特卡罗法则要等到最后结果才能学习，时序差分法可以更快速灵活的更新状态的价值估计，这在某些情况下有着非常重要的实际意义。‘ 时序差分法在更新状态价值时使用的是TD 目标值，即基于即时奖励和下一状态的预估价值来替代当前状态在状态序列结束时可能得到的收获，是当前状态价值的有偏估计，而蒙特卡罗法则使用实际的收获来更新状态价值，是某一策略下状态价值的无偏估计，这一点蒙特卡罗法占优。 虽然时序差分法得到的价值是有偏估计，但是其方差却比蒙特卡罗法得到的方差要低，且对初始值敏感，通常比蒙特卡罗法更加高效。 所以后续的主流的强化学习方法都是基于时序差分的，后面的文章也会主要基于时序差分来拓展讨论。 SUMMARY: 实际上TD和对应的DP最大的区别就在于G(t)的计算，从这里可以体现出DP主要依靠的是当前值再所有出现的序列中的状态值的平均，而TD可以依靠其他变量进行递推的这点优势。 6.2. n步时序差分 前面我们的递推式只考虑了一步差分来进行近似，但是实际上我们可以将差分式子变形，变成二次差分项 G_t^{(2)} = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 V(S_{t+1}) 也可以一次类推到n步的差分项，当n趋于无穷的时候，实际上就等价于MC方法了。 6.3. TD（$\\lambda$） n步时序差分选择多少步数是一个超参数调优的过程，为了再不增加计算复杂度的时候综合考虑所有步数的预测，引入一个新的[0,1]的参数λ，定义λ-收获是n从1到∞所有步的收获*权重的和，每一步的权重带有一定的比例，如下： G_t^\\lambda = (1-\\lambda)\\sum_{n=1}^\\infin \\lambda^{n-1}G_t^{(n)} 因此我们就能得到TD（λ）的迭代公式：Q也是类似的，就不重新写一次了 V(S_t) = V(S_t)+\\alpha(G_t^\\lambda - V(S_t)) 权重衰减的原因如下，随着n增大，权重成集合级数衰减，在T时刻把所有剩余的权重给最终状态，这样可以使得权重嘉禾为1，里当前越远权重越小。 从前向来看TD(λ)， 一个状态的价值V(St)由Gt得到，而Gt又间接由所有后续状态价值计算得到，因此可以认为更新一个状态的价值需要知道所有后续状态的价值。也就是说，必须要经历完整的状态序列获得包括终止状态的每一个状态的即时奖励才能更新当前状态的价值。这和蒙特卡罗法的要求一样，因此TD(λ)有着和蒙特卡罗法一样的劣势。当λ=0 时,就是第二节讲到的普通的时序差分法，当λ=1 时,就是蒙特卡罗法。 从反向来看TD(λ)，它可以分析我们状态对后续状态的影响。比如老鼠在依次连续接受了3 次响铃和1 次亮灯信号后遭到了电击，那么在分析遭电击的原因时，到底是响铃的因素较重要还是亮灯的因素更重要呢？如果把老鼠遭到电击的原因认为是之前接受了较多次数的响铃，则称这种归因为频率启发(frequency heuristic) 式；而把电击归因于最近少数几次状态的影响，则称为就近启发(recency heuristic) 式。 如果给每一个状态引入一个数值：效用(eligibility, E) 来表示该状态对后续状态的影响，就可以同时利用到上述两个启发。而所有状态的效用值总称为效用迹(eligibility traces,ES)。定义为： \\begin{gathered}E_{0}(s)=0 \\\\E_{t}(s)=\\gamma \\lambda E_{t-1}(s)+1\\left(S_{t}=s\\right)=\\left\\{\\begin{array}{ll}0 & t 可以看到一个状态要是重复出现的话都会让效用迹增加，不然的话就会一直衰减。 这样最终TD（λ）的股票公式就可以更新为：（反向公式这应该是） \\begin{gathered}\\delta_{t}=R_{t+1}+\\gamma v\\left(S_{t+1}\\right)-V\\left(S_{t}\\right) \\\\V\\left(S_{t}\\right)=V\\left(S_{t}\\right)+\\alpha \\delta_{t} E_{t}(s)\\end{gathered} 然后可以看出这两个公式是存在一致性的。 6.4. TD控制问题求解 实际上还是使用同样的ε-贪婪进行策略和价值迭代。 在线控制最常见的是SARSA算法 离线控制比在线控制多了一个策略，用贪婪发来更新价值函数，用一样的来进行动作选择，最常见的是Q-Learning算法。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Papers/Reward_is_enough.html":{"url":"Papers/Reward_is_enough.html","title":"P1:Reward Is Enough","keywords":"","body":"1. Reward is enough1.1. 对reward构建AGI的可行性的分析和探讨1. Reward is enough Desc: RL Finished?: Yes Tags: Paper 通用人工智能，是否能通过强化学习的奖励机制就实现 实现AGI，强化学习就够了？Sutton、Silver师徒联手：奖励机制足够实现各种目标 1.1. 对reward构建AGI的可行性的分析和探讨 这篇文章实际上没有给出一个很好的方案通过reward来实现各种AGI的设计，但是给出了在每一种场景下的AGI的reward设计的设想把。和对用reward进行设计的可行性分析。 同时分析了：感知、社交、语言、泛化、模仿，这几个方面 类似地，如果人工智能体的经验流足够丰富，那么单一目标（例如电池寿命或生存）可能隐含地需要实现同样广泛的子目标的能力，因此奖励最大化应该足以产生一种通用人工智能。 这不久回到了最基础的问题，没有这种长线以及大量数据交互以及全面场景的经验流，来支撑这样一个AGI的学习，所以这不也是在现阶段上纸上谈兵嘛？ 对这篇论文我的总结是，我不推荐详细阅读，我觉得收益有限，太理想化，其实和强化学习本身的假设也没有太多新东西，我们可以假设强化学习能带来一个AGI，但是对应的约束和限制确实是有点多了。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "},"Papers/DouZero.html":{"url":"Papers/DouZero.html","title":"P2:DouZero","keywords":"","body":"1. DouZero：Mastering DouDizhu with Self-Play Deep Reinforcement Learning1.1. 算法的设计和思路1.2. 蒙特卡洛方法存在的问题1.3. 蒙特卡洛方法在该任务上存在的优势1.4. Reference1. DouZero：Mastering DouDizhu with Self-Play Deep Reinforcement Learning Desc: GAME, RL Finished?: Yes Tags: Paper URL1: https://arxiv.org/abs/2106.06135 URL2: https://github.com/kwai/DouZero URL3: https://github.com/datamllab/rlcard-showdown） 使用蒙特卡洛方法进行自我对弈不断更新预测模型的方法，这实际上也是普通人对于强化学习如何在self-play中实现自我更新的最基础的想法把： 自我对弈（记录动作序列）- 用最终的胜负（价值）更新网络。 1.1. 算法的设计和思路 算法的目标是学习一个价值网路。网络的输入是当前状态和一个动作，输出是在当前状态做这个动作的期望收益（比如胜率）。简单来说，价值网络在每一步计算出哪种牌型赢的概率最大，然后选择最有可能赢的牌型。蒙特卡罗方法不断重复以下步骤来优化价值网络： 用价值网络生成一场对局 记录下该对局中所有的状态、动作和最后的收益（胜率） 将每一对状态和动作作为网络输入，收益作为网络输出，用梯度下降对价值网络进行一次更新 其实，所谓的蒙特卡罗方法就是一种随机模拟，即通过不断的重复实验来估计真实价值。、 如下图所示，斗零采用一个价值神经网络，其输入是状态和动作，输出是价值。首先，过去的出牌用 LSTM 神经网络进行编码。然后 LSTM 的输出以及其他的表征被送入了 6 层全连接网络，最后输出价值。 系统训练的主要瓶颈在于模拟数据的生成，因为每一步出牌都要对神经网络做一次前向传播。斗零采用多演员（actor）的架构，在单个 GPU 服务器上，用了 45 个演员同时产生数据，最终数据被汇集到一个中央训练器进行训练。比较有趣的是，斗零并不需要太多的计算资源，仅仅需要一个普通的四卡 GPU 服务器就能达到不错的效果。这可以让大多数实验室轻松基于作者的代码做更多的尝试。 该方法的设计和实现上听起来都挺简单的，可以找个时间自己测试一下，玩一玩这个东西，对于我来说，看看他们怎么用这个lstm去进行历史编码的，以及在对transformer了解后，看看如何用transformer去替代这样的lstm是我这边的研究重点。 1.2. 蒙特卡洛方法存在的问题 蒙特卡罗方法在强化学习领域中被大多数研究者忽视。学界普遍认为蒙特卡罗方法存在两个缺点： 蒙特卡罗方法不能处理不完整的状态序列 蒙特卡罗方法有很大的方差，导致采样效率很低。 但是斗地主中，可以产生转正的状态序列，同时很容易通过并行来采集大量的样本降低方差，主要是实现上简单，但是可能也是需要大量的数据把。 1.3. 蒙特卡洛方法在该任务上存在的优势 很容易对动作进行编码。斗地主的动作与动作之前是有内在联系的。以三带一为例：如果智能体打出 KKK 带 3，并因为带牌带得好得到了奖励，那么其他的牌型的价值，例如 JJJ 带 3，也能得到一定的提高。这是由于神经网络对相似的输入会预测出相似的输出。动作编码对处理斗地主庞大而复杂的动作空间非常有帮助。智能体即使没有见过某个动作，也能通过其他动作对价值作出估计。 不受过度估计（over-estimation）的影响。最常用的基于价值的强化学习方法是 DQN。但众所周知，DQN 会受过度估计的影响，即 DQN 会倾向于将价值估计得偏高，并且这个问题在动作空间很大时会尤为明显。不同于 DQN，蒙特卡罗方法直接估计价值，因此不受过度估计影响。这一点在斗地主庞大的动作空间中非常适用。 蒙特卡罗方法在稀疏奖励的情况下可能具备一定优势。在斗地主中，奖励是稀疏的，玩家需要打完整场游戏才能知道输赢。DQN 的方法通过下一个状态的价值估计当前状态的价值。这意味着奖励需要一点一点地从最后一个状态向前传播，这可能导致 DQN 更慢收敛。与之相反，蒙特卡罗方法直接预测最后一个状态的奖励，不受稀疏奖励的影响。 1.4. Reference 快手开源斗地主AI，入选ICML，能否干得过「冠军」柯洁？ DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning GitHub - kwai/DouZero: [ICML 2021] DouZero: Mastering DouDizhu with Self-Play Deep Reinforcement Learning | 斗地主AI © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Papers/MobaAI_Tencent.html":{"url":"Papers/MobaAI_Tencent.html","title":"P3:MobaAI Tencent","keywords":"","body":"1. 腾讯绝悟1.1. Introduction and Related Research.1.1.1. Neural Network Architecture Include1.1.2. Contributions1.2. Framework Design1.3. System Design1.4. Module Detail1.4.1. AI-Server1.4.2. Dispatch Module1.4.3. Memory Pool1.4.4. RL Learner1.5. Algorithm Design1.5.1. 网络架构1.5.2. Dual-clip PPO1. 腾讯绝悟 Created by: Aiken H Desc: GAME, RL Finished?: Yes Tags: Paper 《Master Complex Control in MOBA Games with Deep Reinforcement Learning》 论文阅读笔记 @Aiken H 2021.06 1.1. Introduction and Related Research. MOBA游戏的复杂度和状态空间都远比以前的围棋之类的运动更大，所以难度会更大一些 早一些的游戏ai使用的是（2015） Deep Q-Network 通过 supervised learning and self-play 结合的训练策略在围棋上击败了专业人类，而最近更多的使用了DRL（Deep Reinforcement Learning）的方法在近几年被进一步的应用。 1.1.1. Neural Network Architecture Include 1.1.2. Contributions the encoding of Multi-modal inputs 多模态输入 the decoupling of inter-correlations in controls 控制内关联解码 exploration pruning mechanism 剪枝设置 Action mask for efficient exploration ❓效率 attack attention(for target selection) Attention机制做目标选择 LSTM for learning skill combos LSTM 机制做技能释放和链接 Optimize by multi-label proximal policy algorithm(improved PPO) dual-clip PPO 帮助训练的收敛 present a systematic and thorough study develop a deep reinforcement learning framework which provides scalable and off-policy training we develop an actor-critic neural network 跳转上面的网络架构 1.2. Framework Design (S.O.A.P,$\\gamma$,$\\tau$,$\\rho_0$) to denote infinite-horizon ： 使用元组去模拟整个动态强化的过程,过程主要的是最大化累计reward S 状态空间 O 观察状态空间 A 动作空间 $\\rho_0$ 初始状态分布 $\\gamma$ 折扣系数 目标MAX：$\\mathbb{E}[\\sum_{t = 0}^{T} \\gamma^t \\tau(s_t,\\alpha_t)]$ $\\tau: S \\times A \\rightarrow \\mathbb{R}$ 奖励函数 $\\pi： O \\times A \\rightarrow [0,1]$ 策略 $P:S\\times A \\rightarrow S$ 状态转移分布 SUMMARY: This Part is about the basic rule of the RL setting. 1.3. System Design The whole system and workflow design will be shown on this part 由于MOBA游戏复杂的Agent（Players和Characters） 会带来高方差的随机梯度，所以再这种模型的训练中，我们可能会需要一个大的Batach Size来防止Invariant Shift的这种现象，同时并加速训练的有效和收敛性。于是我们设计了一个规模可变，弱耦合的网络架构。 模型整体由四个部分组成：RL-Learner、AI-Server、Dispatch-Module（调度）、Memory-Pool（记忆池） AI-Server:：与环境进行交互模拟（self-play） RL Learning：核心学习网络 Memory Pool：数据存储，为RL提供训练和搜索的实例 Dispatch：数据的收集，压缩，传输 模块之间相互解耦，可以灵活配置， 1.4. Module Detail 1.4.1. AI-Server 传统策略：提供了游戏环境和AI模型之间的交互逻辑，通过相互镜像的策略来进行self-play，从而生成episodes. 对手策略：基于游戏状态中提取的特征使用玻尔兹曼搜索，预测英雄行文（基于softmax的分布采样，发送给CPU执行），返回reward和下一个state CPU版本的FeatherCNN，转换到LOCAL上进行inference 1.4.2. Dispatch Module 和多个AI-Service绑定，是一个收集数据样本的服务器，主要包括：奖励，特征，动作概率等 将这些数据压缩和打包，然后发到内存池中 1.4.3. Memory Pool 服务器：内部实现为用于数据存储的内存高效循环队列 支持不同长度的样本，以及基于生成时间的数据采样 1.4.4. RL Learner 分布式训练环境，为了使用Big Batch，使用多个RL Learner并行的从Memory Pool 获取数据，然后通过ring allreduce算法来集成梯度 通过共享内存（而不是socket）和pool来进行数据交换，从而减少IO需求 P2P的在策略更新和AI service进行快速同步 SUMMARY: 经验生成和参数学习是分离的，以及Memory和Dispath的架构，能够使得算法能够很容易的拓展到百万歌CPU内核和数千个GPU。 1.5. Algorithm Design An Actor-Critic Network 用来建模游戏中的动作依赖关系 1.5.1. 网络架构 由下图说明了网络的状态和动作，为了有效的训练这个网络，提出了一些新颖的策略：目标注意力机制（选择目标）；LSTM用来学习技能combo，和动作选择；控制依赖解耦来建立一个PPO；（先验引入）基于游戏知识的剪枝（Action mask）；优化PPO成dual-clipped PPO 保证大批次和大偏差的收敛性 对图像、Unit、GameInfo分别提取特征后整合成固定长度的Feature，通过LSTM（考虑时间维度的表征）得到最终的表征，然后通过FC对特征进行分类解码（也可以说是预测把），同时基于状态编码的注意力机制来整合出对象预测， 目标注意力：p(t|a) = Softmax(FC(h_{LSTM}·h_{key}^T) p(t|a)是units上的注意力分布，维度是状态中的单元数。 为了解决多标签策略网络中，同一个动作不同标签之间的关联显示建模困难的问题，独立处理一个动作中的每个标签解耦他们的相互关联。 原始的PPO objective：E:有限批次的经验平均值，其余的参见上面的对照表 \\max_{\\theta} \\hat{\\mathbb{E}}_{s\\sim \\pi_{\\theta_{old}}}[\\frac{\\pi_{\\theta}(a_t|s_t)}{\\pi_{\\theta_{old}}(a_t|s_t)}]\\hat{A_t} 参数解耦之后可以看到： \\max_{\\theta}\\sum_{i=0}^{N_a-1} \\hat{\\mathbb{E}}_{s\\sim \\pi_{\\theta_{old}}}[\\frac{\\pi_{\\theta}(a_t^i|s_t)}{\\pi_{\\theta_{old}}(a_t^i|s_t)}]\\hat{A_t} 有两个优点：简化策略的结构（不考虑相关性）；增加策略的多样性，为了多样性，我们开始的训练过程中，随机了初始化agent的位置。 缺点：进一步增加的策略训练的复杂度，所以通过action mask来进行简化，在最终输出层来合并动作元素之间的相关性，从而修建需要的策略搜索空间， 1.5.2. Dual-clip PPO 令$\\taut(\\theta) = [\\frac{\\pi{\\theta}(at|s_t)}{\\pi{\\theta_{old}}(a_t|s_t)}]$,由于这个值可能会很大，导致过大的策略偏差，为了缓解这个问题，我们引入 L^{CLIP}(\\theta)\\hat{\\mathbb{E}}_t[\\min(\\tau_t(\\theta)\\hat{A_t},clip(\\tau_t(\\theta),1-\\epsilon,1+\\epsilon)\\hat{A_t})] 来惩罚政策的极端变化，但是另一种情况下的极端值也会带来无界偏差，所以还有另一端的优化,其中c>1是一个下线常数 \\hat{\\mathbb{E}_t}[\\max(\\min(\\tau_t(\\theta)\\hat{A_t},clip(\\tau_t(\\theta),1-\\epsilon,1+\\epsilon)\\hat{A_t}),c\\hat{A_t})] © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:35 "},"Papers/NIPS中国预讲会.html":{"url":"Papers/NIPS中国预讲会.html","title":"NIPS中国预讲会","keywords":"","body":"1. NIPS 中国预讲会1.1. Long-Tailed Classicification by Keeping the Good and Removing the Bad Momentum Causal Effect1.2. 3D视觉部分的启发1.3. self-supervised and transfer1. NIPS 中国预讲会 1.1. Long-Tailed Classicification by Keeping the Good and Removing the Bad Momentum Causal Effect re-sampling 、re-weighted（这些方法都需要提前预知分布，就和人类的本能比较接近了）， 问题一般是对于头部的过拟合，对尾巴的欠拟合 two-stage re-balancing 基于优化器的动量调整 长尾数据分布本身带来的优化偏折项。 可以被广泛的应用于各种不同的数据集 1.2. 3D视觉部分的启发 光度法3维重建 1.3. self-supervised and transfer MOCO: 无监督的的预训练+fine-tune在很多地方超过有监督了。 （主要是潜力方面） ImageNet-1k linear evaluation：用特征直接接简单的线性来进行分类，来评估本身的特征提取效果。 SimCLR 简化版的MOCO，还有一些其他的发现，data-augmentation 这些trick用在MOCO上甚至效果更高了比SimCLR NIPS： BYOL：moco需要很大的负样本，这个方法不需要负样本，但是设计了一个不对称的设计， SwaV：Deep clustering + contrastive learning InfoMin：Pascal 上做 和对Augmentation的仔细研究 PIC：将2stage->1stage（不用做对比了） After NIPs： higher accuracy better understand 为什么不需要负样本，而不会坍缩 hekaiming ：孪生网络的工作。 © AikenHong all right reserved，powered by Gitbook该文件修订时间： 2021-09-26 00:08:36 "}}